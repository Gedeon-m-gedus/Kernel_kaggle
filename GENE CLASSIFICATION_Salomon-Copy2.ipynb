{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxopt\n",
    "np.random.seed(54321)\n",
    "\n",
    "import ipdb\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 165 ms\n"
     ]
    }
   ],
   "source": [
    "seq = ['seq_'+str(i) for i in range(100)]\n",
    "X_train=pd.read_csv('./data/Xtr_mat100.csv', sep=' ', names = seq) #we use this dataset to train our model\n",
    "X_test=pd.read_csv('./data/Xte_mat100.csv', sep=' ', names = seq) #we will use this data set later to validate our model\n",
    "\n",
    "Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 880 µs\n"
     ]
    }
   ],
   "source": [
    "# X_train=pd.read_csv('./data/train_data_preprocessing1.csv', sep=',') #we use this dataset to train our model\n",
    "# Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "# X_test=pd.read_csv('./data/test_data_preprocessing1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 640 µs\n"
     ]
    }
   ],
   "source": [
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_0</th>\n",
       "      <th>seq_1</th>\n",
       "      <th>seq_2</th>\n",
       "      <th>seq_3</th>\n",
       "      <th>seq_4</th>\n",
       "      <th>seq_5</th>\n",
       "      <th>seq_6</th>\n",
       "      <th>seq_7</th>\n",
       "      <th>seq_8</th>\n",
       "      <th>seq_9</th>\n",
       "      <th>seq_10</th>\n",
       "      <th>seq_11</th>\n",
       "      <th>seq_12</th>\n",
       "      <th>seq_13</th>\n",
       "      <th>seq_14</th>\n",
       "      <th>seq_15</th>\n",
       "      <th>seq_16</th>\n",
       "      <th>seq_17</th>\n",
       "      <th>seq_18</th>\n",
       "      <th>seq_19</th>\n",
       "      <th>seq_20</th>\n",
       "      <th>seq_21</th>\n",
       "      <th>seq_22</th>\n",
       "      <th>seq_23</th>\n",
       "      <th>seq_24</th>\n",
       "      <th>seq_25</th>\n",
       "      <th>seq_26</th>\n",
       "      <th>seq_27</th>\n",
       "      <th>seq_28</th>\n",
       "      <th>seq_29</th>\n",
       "      <th>seq_30</th>\n",
       "      <th>seq_31</th>\n",
       "      <th>seq_32</th>\n",
       "      <th>seq_33</th>\n",
       "      <th>seq_34</th>\n",
       "      <th>seq_35</th>\n",
       "      <th>seq_36</th>\n",
       "      <th>seq_37</th>\n",
       "      <th>seq_38</th>\n",
       "      <th>seq_39</th>\n",
       "      <th>...</th>\n",
       "      <th>seq_60</th>\n",
       "      <th>seq_61</th>\n",
       "      <th>seq_62</th>\n",
       "      <th>seq_63</th>\n",
       "      <th>seq_64</th>\n",
       "      <th>seq_65</th>\n",
       "      <th>seq_66</th>\n",
       "      <th>seq_67</th>\n",
       "      <th>seq_68</th>\n",
       "      <th>seq_69</th>\n",
       "      <th>seq_70</th>\n",
       "      <th>seq_71</th>\n",
       "      <th>seq_72</th>\n",
       "      <th>seq_73</th>\n",
       "      <th>seq_74</th>\n",
       "      <th>seq_75</th>\n",
       "      <th>seq_76</th>\n",
       "      <th>seq_77</th>\n",
       "      <th>seq_78</th>\n",
       "      <th>seq_79</th>\n",
       "      <th>seq_80</th>\n",
       "      <th>seq_81</th>\n",
       "      <th>seq_82</th>\n",
       "      <th>seq_83</th>\n",
       "      <th>seq_84</th>\n",
       "      <th>seq_85</th>\n",
       "      <th>seq_86</th>\n",
       "      <th>seq_87</th>\n",
       "      <th>seq_88</th>\n",
       "      <th>seq_89</th>\n",
       "      <th>seq_90</th>\n",
       "      <th>seq_91</th>\n",
       "      <th>seq_92</th>\n",
       "      <th>seq_93</th>\n",
       "      <th>seq_94</th>\n",
       "      <th>seq_95</th>\n",
       "      <th>seq_96</th>\n",
       "      <th>seq_97</th>\n",
       "      <th>seq_98</th>\n",
       "      <th>seq_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.032609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.01087</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         seq_0     seq_1    seq_2  ...    seq_97   seq_98    seq_99\n",
       "1995  0.000000  0.021739  0.01087  ...  0.032609  0.01087  0.010870\n",
       "1996  0.010870  0.032609  0.00000  ...  0.000000  0.00000  0.010870\n",
       "1997  0.000000  0.000000  0.00000  ...  0.010870  0.01087  0.032609\n",
       "1998  0.021739  0.032609  0.00000  ...  0.010870  0.00000  0.000000\n",
       "1999  0.000000  0.010870  0.00000  ...  0.021739  0.00000  0.010870\n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 216 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_train dataset is: (2000, 100)\n",
      "The shape of the Y_train dataset is: (2000, 2)\n",
      "time: 1.64 ms\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the X_train dataset is:',X_train.shape)\n",
    "print('The shape of the Y_train dataset is:',Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 361 µs\n"
     ]
    }
   ],
   "source": [
    "# X_train['len'] = X_train.seq.apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   1  CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   2  GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   3  GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   4  GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.17 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 709 µs\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "Alphabet_dict = dict(zip(string.ascii_uppercase, range(1,27)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 277 ms\n"
     ]
    }
   ],
   "source": [
    "#  X_train['seq_1'] = X_train.seq.apply(lambda x : (' '.join(map(str, list(x))))[0])\n",
    "for i in range(0, 101, 1):\n",
    "    X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :Alphabet_dict[x[i]])\n",
    "    X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :Alphabet_dict[x[i]])\n",
    "    \n",
    "#     X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :Alphabet_dict[x[i]])\n",
    "#     X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :Alphabet_dict[x[i]]\n",
    "\n",
    "#     X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :x[i:i+3])\n",
    "#     X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :x[i:i+3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "      <th>seq_0</th>\n",
       "      <th>seq_1</th>\n",
       "      <th>seq_2</th>\n",
       "      <th>seq_3</th>\n",
       "      <th>seq_4</th>\n",
       "      <th>seq_5</th>\n",
       "      <th>seq_6</th>\n",
       "      <th>seq_7</th>\n",
       "      <th>seq_8</th>\n",
       "      <th>seq_9</th>\n",
       "      <th>seq_10</th>\n",
       "      <th>seq_11</th>\n",
       "      <th>seq_12</th>\n",
       "      <th>seq_13</th>\n",
       "      <th>seq_14</th>\n",
       "      <th>seq_15</th>\n",
       "      <th>seq_16</th>\n",
       "      <th>seq_17</th>\n",
       "      <th>seq_18</th>\n",
       "      <th>seq_19</th>\n",
       "      <th>seq_20</th>\n",
       "      <th>seq_21</th>\n",
       "      <th>seq_22</th>\n",
       "      <th>seq_23</th>\n",
       "      <th>seq_24</th>\n",
       "      <th>seq_25</th>\n",
       "      <th>seq_26</th>\n",
       "      <th>seq_27</th>\n",
       "      <th>seq_28</th>\n",
       "      <th>seq_29</th>\n",
       "      <th>seq_30</th>\n",
       "      <th>seq_31</th>\n",
       "      <th>seq_32</th>\n",
       "      <th>seq_33</th>\n",
       "      <th>seq_34</th>\n",
       "      <th>seq_35</th>\n",
       "      <th>seq_36</th>\n",
       "      <th>seq_37</th>\n",
       "      <th>...</th>\n",
       "      <th>seq_61</th>\n",
       "      <th>seq_62</th>\n",
       "      <th>seq_63</th>\n",
       "      <th>seq_64</th>\n",
       "      <th>seq_65</th>\n",
       "      <th>seq_66</th>\n",
       "      <th>seq_67</th>\n",
       "      <th>seq_68</th>\n",
       "      <th>seq_69</th>\n",
       "      <th>seq_70</th>\n",
       "      <th>seq_71</th>\n",
       "      <th>seq_72</th>\n",
       "      <th>seq_73</th>\n",
       "      <th>seq_74</th>\n",
       "      <th>seq_75</th>\n",
       "      <th>seq_76</th>\n",
       "      <th>seq_77</th>\n",
       "      <th>seq_78</th>\n",
       "      <th>seq_79</th>\n",
       "      <th>seq_80</th>\n",
       "      <th>seq_81</th>\n",
       "      <th>seq_82</th>\n",
       "      <th>seq_83</th>\n",
       "      <th>seq_84</th>\n",
       "      <th>seq_85</th>\n",
       "      <th>seq_86</th>\n",
       "      <th>seq_87</th>\n",
       "      <th>seq_88</th>\n",
       "      <th>seq_89</th>\n",
       "      <th>seq_90</th>\n",
       "      <th>seq_91</th>\n",
       "      <th>seq_92</th>\n",
       "      <th>seq_93</th>\n",
       "      <th>seq_94</th>\n",
       "      <th>seq_95</th>\n",
       "      <th>seq_96</th>\n",
       "      <th>seq_97</th>\n",
       "      <th>seq_98</th>\n",
       "      <th>seq_99</th>\n",
       "      <th>seq_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq  ...  seq_99  seq_100\n",
       "0   0  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...  ...       1        7\n",
       "1   1  CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...  ...       7        7\n",
       "2   2  GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...  ...       7       20\n",
       "3   3  GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...  ...       1        1\n",
       "4   4  GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...  ...       3        3\n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about counting number of different caracters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 520 µs\n"
     ]
    }
   ],
   "source": [
    "# A, C, G, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test=pd.read_csv('./data/Xte.csv', sep=',')\n",
    "\n",
    "def spectrum_kernal(X_train, y, X_test, n=3, encoder=4, one_hot = True, normalise = False):\n",
    "    \n",
    "    d = {'A': 0.3, 'C':0.4, 'G':0.5, 'T':0.6}\n",
    "    \n",
    "    for i in range(0, 101-n+1, 1):\n",
    "        X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :x[i:i+n])\n",
    "        X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :x[i:i+n])\n",
    "        \n",
    "        X_train['seq_'+str(i)] = X_train['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        X_test['seq_'+str(i)] = X_test['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        \n",
    "        \n",
    "        \n",
    "    X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "    X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "    y = Y_train.Bound\n",
    "    \n",
    "#     print(f'Train: \\n{X.tail()}\\n -----------------------\\n')\n",
    "#     print(f'Test: \\n {X_t.tail()}')\n",
    "\n",
    "    if one_hot:\n",
    "        onehot_encoder = OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore')\n",
    "\n",
    "        X_cross = X.values\n",
    "        X_t = X_t.values\n",
    "        \n",
    "        enc = onehot_encoder.fit(X)\n",
    "        X_cross = enc.transform(X)\n",
    "        X_t_enc = enc.transform(X_t)\n",
    "        \n",
    "    elif normalise:\n",
    "        scaler = MinMaxScaler()#MinMaxScaler() # StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        \n",
    "        X_cross = scaler.transform(X)\n",
    "        X_t_enc = scaler.transform(X_t)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        X_cross = X.values\n",
    "        X_t_enc = X_t.values\n",
    "    \n",
    "    y_cross = y.values\n",
    "    \n",
    "    return X_cross, y_cross, X_t_enc\n",
    "\n",
    "X_cross, y_cross, X_t_enc = spectrum_kernal(X_train, Y_train, X_test, n=5, encoder=3, one_hot = True, normalise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 35014)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.85 ms\n"
     ]
    }
   ],
   "source": [
    "X_cross.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 35014)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.6 ms\n"
     ]
    }
   ],
   "source": [
    "X_t_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 426 µs\n"
     ]
    }
   ],
   "source": [
    "# X_train.seq.apply(lambda x : np.unique(x[:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.88 ms\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "X_t = X_test\n",
    "y = Y_train.Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.76 ms\n"
     ]
    }
   ],
   "source": [
    "# class LogisticRegressionBinary():\n",
    "#     def __init__(self, lr=0.1, num_iter=100000, batch_size=1, verbose=False):\n",
    "#         self.lr = lr\n",
    "#         self.num_iter = num_iter\n",
    "#         self.batch_size = batch_size\n",
    "#         self.verbose = verbose\n",
    "    \n",
    "#     def __add_intercept(self, X):\n",
    "#         intercept = np.ones((X.shape[0], 1))\n",
    "#         return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "#     def __sigmoid_func(self, z):\n",
    "#         return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "#     def __loss(self, h, y):\n",
    "#         return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "#     def fit(self, X, y):\n",
    "#         y = self.trans_y(y)\n",
    "#         X = self.__add_intercept(X)\n",
    "#         self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "#         for i in range(self.num_iter):\n",
    "#             z = np.dot(X, self.theta)\n",
    "#             h = self.__sigmoid_func(z)\n",
    "                        \n",
    "#             rand = np.random.choice(y.size, self.batch_size).squeeze()\n",
    "#             gradient = np.dot(X[rand].T, (h[rand] - y[rand]))/y.size   \n",
    "        \n",
    "#             self.theta -= self.lr * gradient\n",
    "#             #print('theta and grad',self.theta.shape ,  gradient.shape )\n",
    "#             if(self.verbose == True and i % 100 == 0):\n",
    "#                 z = np.dot(X, self.theta)\n",
    "#                 h = self.__sigmoid(z)\n",
    "#                 print(f'loss: {self.__loss(h, y)} \\t')\n",
    "    \n",
    "#     def predict_probability(self, X):\n",
    "#         X = self.__add_intercept(X)\n",
    "    \n",
    "#         return self.__sigmoid_func(np.dot(X, self.theta))\n",
    "    \n",
    "#     def predict(self, X, threshold=.5):\n",
    "#           return np.where(self.predict_probability(X) >= 0.5, 1, 0)\n",
    "        \n",
    "          \n",
    "#     def Accuracy_check(self,X,y):\n",
    "#         return np.mean(self.predict(X)==y)\n",
    "    \n",
    "#     def trans_y(self, y):\n",
    "#         if isinstance(y, pd.Series):\n",
    "#             y = y.values\n",
    "#         if isinstance(y, list):\n",
    "#             y = np.array(y)\n",
    "#         return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 436 ms\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression (RR)\n",
    "\n",
    "class solveRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "            \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        A = (X.T.dot(X)) + np.eye(p)*lam*n\n",
    "        b = X.T.dot(y)\n",
    "        \n",
    "        self.beta = np.linalg.solve(A, b)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Weighted Ridge Regression (WRR)\n",
    "class solveWRR():\n",
    "    def __init__(self, X, y, w, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.w = w\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        w = self.w\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == len(w) == n)\n",
    "\n",
    "        y1 = np.sqrt(w) * y\n",
    "        X1 = (np.sqrt(w) * X.T).T\n",
    "        \n",
    "        # Hint:\n",
    "        # Find y1 and X1 such that:\n",
    "        \n",
    "        self.beta = solveRR(X1, y1, lam).fit()\n",
    "                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Logistic Ridge Regression (LRR)\n",
    "class solveLRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "    \n",
    "        lam = self.lam \n",
    "        max_iter = 50\n",
    "        eps = 1e-3\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialize\n",
    "        self.beta = np.zeros(p)\n",
    "\n",
    "        # Hint: Use IRLS\n",
    "        for i in range(max_iter):\n",
    "            beta_old = self.beta\n",
    "            f = X.dot(beta_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*f)\n",
    "            self.beta = solveWRR(X, z, w, 2*lam).fit()\n",
    "            # Break condition (achieved convergence)\n",
    "            #if np.sum((beta-beta_old)**2) < eps:\n",
    "            #    break                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 193 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "### Functions for you to fill in ###\n",
    "\n",
    "def polynomial_kernel(X, Y, c, p):\n",
    "    \"\"\"\n",
    "        Compute the polynomial kernel between two matrices X and Y::\n",
    "            K(x, y) = (<x, y> + c)^p\n",
    "        for each pair of rows x in X and y in Y.\n",
    "\n",
    "        Args:\n",
    "            X - (n, d) NumPy array (n datapoints each with d features)\n",
    "            Y - (m, d) NumPy array (m datapoints each with d features)\n",
    "            c - a coefficient to trade off high-order and low-order terms (scalar)\n",
    "            p - the degree of the polynomial kernel\n",
    "\n",
    "        Returns:\n",
    "            kernel_matrix - (n, m) Numpy array containing the kernel matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError\n",
    "    kernel_matrix = (X.dot(Y.T) + c)**p\n",
    "    \n",
    "    return kernel_matrix\n",
    "\n",
    "\n",
    "def rbf_kernel_2(X, Y, gamma):\n",
    "    \"\"\"\n",
    "        Compute the Gaussian RBF kernel between two matrices X and Y::\n",
    "            K(x, y) = exp(-gamma ||x-y||^2)\n",
    "        for each pair of rows x in X and y in Y.\n",
    "\n",
    "        Args:\n",
    "            X - (n, d) NumPy array (n datapoints each with d features)\n",
    "            Y - (m, d) NumPy array (m datapoints each with d features)\n",
    "            gamma - the gamma parameter of gaussian function (scalar)\n",
    "\n",
    "        Returns:\n",
    "            kernel_matrix - (n, m) Numpy array containing the kernel matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError\n",
    "    n, d = X.shape\n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    kernel_matrix = X**2 @ np.ones((d,m)) + np.ones((n,d)) @ Y.T**2 - 2*(X @ Y.T)\n",
    "    kernel_matrix = np.exp(-gamma*kernel_matrix)\n",
    "    \n",
    "    return kernel_matrix\n",
    "\n",
    "\n",
    "def rbf_kernel_element_wise(x, y, sigma=1):\n",
    "    '''\n",
    "    returns the RBF (Gaussian) kernel k(x, y)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    x and y are p-dimensional vectors \n",
    "    '''\n",
    "    K = np.exp(- np.sum((x - y)**2) / (2 * sigma ** 2))\n",
    "    return K\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis=-1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis=-1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    '''\n",
    "    Returns the median of ||Xi-Xj||\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    X: (n, p) matrix\n",
    "    '''\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "# def laplace(X1, X2, alpha=10):\n",
    "#     return np.exp(-alpha*np.abs(X1-X2))\n",
    "\n",
    "# def polynomial(X1, X2, d=2):\n",
    "#     return (X1.dot(X2.T) +1)**d\n",
    "\n",
    "def linear_kernel(X1, X2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the linear kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return X1.dot(X2.T)\n",
    "\n",
    "def quadratic_kernel(X1, X2, power=2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the quadratic kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return (1 + linear_kernel(X1, X2))**power\n",
    "\n",
    "def rbf_poly_kernel(X1, X2, sigma=10, d=2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis=-1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis=-1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    \n",
    "    return K+(X1.dot(X2.T) +1)**d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 68.8 ms\n"
     ]
    }
   ],
   "source": [
    "class ksolveRR_2():\n",
    "    def __init__(self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.sigma = sigma\n",
    "        self.kernel = kernel\n",
    "        self.sample_weights = sample_weights\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        if self.sample_weights is not None:\n",
    "            self.X *= self.sample_weights[:, None]\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "        A = self.kernel(X, X, self.sigma)+n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46.8 ms\n"
     ]
    }
   ],
   "source": [
    "class ksolveRR():\n",
    "    def __init__(self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.sigma = sigma\n",
    "        self.kernel = kernel\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "        if self.sigma is None:\n",
    "            self.sigma = sigma_from_median(X)\n",
    "            \n",
    "        A = self.kernel(X, X, self.sigma)+n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 75.8 ms\n"
     ]
    }
   ],
   "source": [
    "import ipdb\n",
    "# Logistic Ridge Regression (LRR)\n",
    "class ksolveLRR():\n",
    "    def __init__(self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        K = self.kernel(X, X, self.sigma)\n",
    "\n",
    "        # Initialize\n",
    "        alpha = np.zeros(n)\n",
    "        \n",
    "        # Hint: Use IRLS\n",
    "        for n_iter in range(self.max_iter):\n",
    "            alpha_old = alpha\n",
    "            f = K.dot(alpha_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*(f))\n",
    "            \n",
    "            alpha = ksolveRR_2(X, y, lam = 2*self.lam, \\\n",
    "                               sigma=self.sigma, sample_weights = w).fit().alpha\n",
    "            \n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < self.tol:\n",
    "                break  \n",
    "                \n",
    "                \n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 270 ms\n"
     ]
    }
   ],
   "source": [
    "# You don't need to look at this, this is just to adapt our matrices\n",
    "# to the solver being used\n",
    "solver='cvxopt'\n",
    "\n",
    "import cvxopt\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    #cvxopt.solvers.options['show_progress'] = False\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = cvxopt_qp\n",
    "\n",
    "def quadprog_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "    qp_G = .5 * (P + P.T)   # make sure P is symmetric\n",
    "    qp_a = -q\n",
    "    if A is not None:\n",
    "        qp_C = -np.vstack([A, G]).T\n",
    "        qp_b = -np.hstack([b, h])\n",
    "        meq = A.shape[0]\n",
    "    else:  # no equality constraint\n",
    "        qp_C = - G.T\n",
    "        qp_b = - h\n",
    "        meq = 0\n",
    "    return quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)[0]\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices)\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = {'quadprog': quadprog_solve_qp, 'cvxopt': cvxopt_qp}[solver]\n",
    "\n",
    "def svm_dual_soft_to_qp_kernel(K, y, C=1):\n",
    "    n = K.shape[0]\n",
    "    assert (len(y) == n)\n",
    "        \n",
    "    # Dual formulation, soft margin\n",
    "    P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "    # As a regularization, we add epsilon * identity to P\n",
    "    eps = 1e-12\n",
    "    P += eps * np.eye(n)\n",
    "    q = - np.ones(n)\n",
    "    G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "    h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "    A = y[np.newaxis, :]\n",
    "    A = A.astype('float')\n",
    "    b = np.array([0.])\n",
    "    return P, q, G, h, A, b\n",
    "\n",
    "# SVM primal soft\n",
    "class KernelSVM():\n",
    "    def __init__(self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.lam = lam        \n",
    "        self.sigma = sigma\n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        C = self.C\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        K = self.kernel(X, X, self.sigma)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = solve_qp(*svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        \n",
    "       # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha>self.tol), (self.C - self.alpha > self.tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha*y)\n",
    "        self.bias =  self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "#         y_pred = self.kernel(X, self.X_).dot(self.alphas* seld.y_)\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where((K_x.dot(self.alpha * self.y) +  self.bias) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.26 ms\n"
     ]
    }
   ],
   "source": [
    "# # Logistic Ridge Regression (LRR)\n",
    "# class perceptron():\n",
    "#     def __init__(self, X, y, iteration=100):\n",
    "#         self.theta = np.zeros(len(X))\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.iteration = iteration\n",
    "#         self.theta_0 = 0\n",
    "    \n",
    "#     def fit(self):\n",
    "        \n",
    "#         X = self.X\n",
    "#         y = self.y\n",
    "        \n",
    "#         n, p = X.shape\n",
    "#         assert (len(y) == n)\n",
    "        \n",
    "#         for it in range(self.iteration):\n",
    "#             for i in range(len(y)):\n",
    "#                 if y[i]*(np.dot(self.theta, X[i]) + self.theta_0)<= 0 :\n",
    "#                     self.theta = self.theta + (np.dot(y[i], X[i]))\n",
    "#                     self.theta_0 += y[i]\n",
    "    \n",
    "        \n",
    "#     def predict(self, X, threshold):\n",
    "#         return np.where(X.dot(self.self.theta)+self.theta_0 >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "#     def Accuracy_check(self,X, y, threshold=.5):\n",
    "#         return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import TransformerM\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.02 ms\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = CountVectorizer(max_features=2000)\n",
    "# vectorizer.fit_transform(X[:10])\n",
    "# # vectorizer.get_feature_names()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.85 ms\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=5)\n",
    "# onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "# # X_cross = X.values\n",
    "# # X_t = X_t.values\n",
    "\n",
    "# y_cross = y.values\n",
    "\n",
    "# # vectorizer = TfidfVectorizer()\n",
    "# # X_cross = vectorizer.fit_transform(X)\n",
    "\n",
    "# # X_cross = onehot_encoder.fit_transform(X.values[:, :101])\n",
    "# # X_t_enc = onehot_encoder.fit_transform(X_t.values[:, :101])\n",
    "\n",
    "# # X_cross = onehot_encoder.fit_transform(X)\n",
    "# # X_t_enc = onehot_encoder.fit_transform(X_t)\n",
    "\n",
    "\n",
    "# X_cross = X.values\n",
    "# X_t_enc = X_t.values\n",
    "\n",
    "\n",
    "# # scaler = MinMaxScaler()#MinMaxScaler() # StandardScaler()\n",
    "# # scaler.fit(X_cross)\n",
    "\n",
    "# # X_cross = scaler.transform(X_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.1 ms\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.64 ms\n"
     ]
    }
   ],
   "source": [
    "# def feature_selector(X):\n",
    "#     #sel = VarianceThreshold()\n",
    "#     sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "#     sel.fit_transform(X)\n",
    "#     return X\n",
    "# def best_feature_selector(X,y,num_features=50):\n",
    "#     #print(X.shape)\n",
    "#     features = SelectKBest(chi2, k=num_features).fit(X, y)\n",
    "#     #print(X_new.shape)\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test=pd.read_csv('./data/Xte.csv', sep=',')\n",
    "\n",
    "def spectrum_kernal(X_train, y, X_test, n=3, encoder=4, one_hot = True, normalise = False):\n",
    "    \n",
    "#     d = {'A': 0.3, 'C':0.4, 'G':0.5, 'T':0.6}\n",
    "    d = {'A': 0, 'C':1, 'G':2, 'T':3}\n",
    "    \n",
    "    for i in range(0, 101-n+1, 1):\n",
    "        X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :x[i:i+n])\n",
    "        X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :x[i:i+n])\n",
    "        \n",
    "        X_train['seq_'+str(i)] = X_train['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        X_test['seq_'+str(i)] = X_test['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        \n",
    "        \n",
    "        \n",
    "    X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "    X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "    y = Y_train.Bound\n",
    "    \n",
    "#     print(f'Train: \\n{X.tail()}\\n -----------------------\\n')\n",
    "#     print(f'Test: \\n {X_t.tail()}')\n",
    "\n",
    "    if one_hot:\n",
    "        onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "        X_cross = X.values\n",
    "        X_t = X_t.values\n",
    "\n",
    "        X_cross = onehot_encoder.fit_transform(X)\n",
    "        X_t_enc = onehot_encoder.fit_transform(X_t)\n",
    "        \n",
    "    elif normalise:\n",
    "        scaler = MinMaxScaler()#MinMaxScaler() # StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        \n",
    "        X_cross = scaler.transform(X)\n",
    "        X_t_enc = scaler.transform(X_t)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        X_cross = X.values\n",
    "        X_t_enc = X_t.values\n",
    "    \n",
    "    y_cross = y.values\n",
    "    \n",
    "    return X_cross, y_cross, X_t_enc\n",
    "\n",
    "# X_cross, y_cross, X_t_enc = spectrum_kernal(X_train, Y_train, X_test, n=5, encoder=3, one_hot = False, normalise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.25 ms\n"
     ]
    }
   ],
   "source": [
    "6e+0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e484ca7d581249539b44b509fb150b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-29 12:29:35,453]\u001b[0m Finished trial#0 with value: 0.501 with parameters: {'sigma': 2.5117487569789962, 'lam': 8.97705206983928e-09, 'n': 1}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:29:43,247]\u001b[0m Finished trial#1 with value: 0.501 with parameters: {'sigma': 1.6331781570105437, 'lam': 2.331616262809628e-14, 'n': 1}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:29:57,774]\u001b[0m Finished trial#2 with value: 0.647 with parameters: {'sigma': 4.85920780004171, 'lam': 1.4795582273806023e-16, 'n': 3}. Best is trial#2 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:30:13,254]\u001b[0m Finished trial#3 with value: 0.501 with parameters: {'sigma': 2.2025122456427426, 'lam': 0.0004434785281327629, 'n': 3}. Best is trial#2 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:30:19,902]\u001b[0m Finished trial#4 with value: 0.501 with parameters: {'sigma': 1.2344411301632003, 'lam': 2.2297690089106766e-05, 'n': 1}. Best is trial#2 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:30:33,455]\u001b[0m Finished trial#5 with value: 0.501 with parameters: {'sigma': 1.3781007855742438, 'lam': 1.3525411609057587e-15, 'n': 3}. Best is trial#2 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:30:46,898]\u001b[0m Finished trial#6 with value: 0.501 with parameters: {'sigma': 2.775286702515141, 'lam': 9.01811744555797e-18, 'n': 3}. Best is trial#2 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:30:55,165]\u001b[0m Finished trial#7 with value: 0.501 with parameters: {'sigma': 2.320339271254792, 'lam': 0.015726708162688615, 'n': 2}. Best is trial#2 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:31:02,648]\u001b[0m Finished trial#8 with value: 0.501 with parameters: {'sigma': 3.0698896172968935, 'lam': 4.6788129920593565e-17, 'n': 1}. Best is trial#2 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:31:10,278]\u001b[0m Finished trial#9 with value: 0.501 with parameters: {'sigma': 5.221673957448471, 'lam': 0.19470845603434772, 'n': 1}. Best is trial#2 with value: 0.647.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:31:18,828]\u001b[0m Finished trial#10 with value: 0.653 with parameters: {'sigma': 5.684559769970499, 'lam': 2.39234105621091e-11, 'n': 2}. Best is trial#10 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:31:28,177]\u001b[0m Finished trial#11 with value: 0.6555000000000001 with parameters: {'sigma': 5.523894715838783, 'lam': 5.308877070103443e-12, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:31:36,529]\u001b[0m Finished trial#12 with value: 0.501 with parameters: {'sigma': 3.794691530809447, 'lam': 1.6331434969332994e-12, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:31:46,001]\u001b[0m Finished trial#13 with value: 0.651 with parameters: {'sigma': 5.794295601837367, 'lam': 6.614734070835416e-10, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:31:55,843]\u001b[0m Finished trial#14 with value: 0.5894999999999999 with parameters: {'sigma': 4.141508746518128, 'lam': 1.86627592731343e-11, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:32:06,028]\u001b[0m Finished trial#15 with value: 0.651 with parameters: {'sigma': 5.98315031476568, 'lam': 1.4871807939038366e-08, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:32:14,516]\u001b[0m Finished trial#16 with value: 0.5915 with parameters: {'sigma': 4.145858338305185, 'lam': 2.284096556399892e-13, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:32:23,308]\u001b[0m Finished trial#17 with value: 0.501 with parameters: {'sigma': 3.45372200716266, 'lam': 2.0137586274178334e-06, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:32:31,211]\u001b[0m Finished trial#18 with value: 0.653 with parameters: {'sigma': 4.790305548465556, 'lam': 1.6725606087394204e-10, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:32:44,544]\u001b[0m Finished trial#19 with value: 0.6485000000000001 with parameters: {'sigma': 4.662789011456637, 'lam': 2.878739784108085e-07, 'n': 3}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:32:52,788]\u001b[0m Finished trial#20 with value: 0.501 with parameters: {'sigma': 1.7484391502179508, 'lam': 3.56277012755638e-10, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:33:02,207]\u001b[0m Finished trial#21 with value: 0.6505 with parameters: {'sigma': 5.991381033053325, 'lam': 5.282569120169581e-11, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:33:11,265]\u001b[0m Finished trial#22 with value: 0.6529999999999999 with parameters: {'sigma': 5.217206292594714, 'lam': 1.379223362642488e-12, 'n': 2}. Best is trial#11 with value: 0.6555000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:33:20,186]\u001b[0m Finished trial#23 with value: 0.659 with parameters: {'sigma': 4.492910167762835, 'lam': 7.0139521751953716e-15, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:33:28,860]\u001b[0m Finished trial#24 with value: 0.501 with parameters: {'sigma': 3.4231048541393556, 'lam': 4.208282621463659e-15, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:33:37,555]\u001b[0m Finished trial#25 with value: 0.6569999999999999 with parameters: {'sigma': 4.622812339943818, 'lam': 2.1963322419485447e-13, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:33:45,165]\u001b[0m Finished trial#26 with value: 0.653 with parameters: {'sigma': 4.345123042325059, 'lam': 8.280485619242918e-14, 'n': 1}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:34:00,051]\u001b[0m Finished trial#27 with value: 0.501 with parameters: {'sigma': 3.7852483618743697, 'lam': 1.7191451965760999e-18, 'n': 3}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:34:08,657]\u001b[0m Finished trial#28 with value: 0.501 with parameters: {'sigma': 3.1724358701032562, 'lam': 5.189929286813708e-16, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:34:16,731]\u001b[0m Finished trial#29 with value: 0.501 with parameters: {'sigma': 2.6960100209081665, 'lam': 3.2345149164049974e-08, 'n': 1}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:34:26,490]\u001b[0m Finished trial#30 with value: 0.655 with parameters: {'sigma': 5.407399355326913, 'lam': 3.80179229152196e-12, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:34:34,441]\u001b[0m Finished trial#31 with value: 0.6529999999999999 with parameters: {'sigma': 5.035885851091984, 'lam': 1.6177633069123694e-12, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:34:43,504]\u001b[0m Finished trial#32 with value: 0.6555000000000001 with parameters: {'sigma': 5.519977748953009, 'lam': 1.42441386424534e-14, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:34:51,503]\u001b[0m Finished trial#33 with value: 0.6555000000000001 with parameters: {'sigma': 4.462377265322884, 'lam': 1.784889933634983e-14, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:35:01,321]\u001b[0m Finished trial#34 with value: 0.657 with parameters: {'sigma': 4.478579648602229, 'lam': 1.3525744650511563e-13, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:35:12,040]\u001b[0m Finished trial#35 with value: 0.6535 with parameters: {'sigma': 4.366372836376067, 'lam': 5.88434535949978e-14, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:35:26,642]\u001b[0m Finished trial#36 with value: 0.501 with parameters: {'sigma': 3.8116830106691304, 'lam': 2.088196198454188e-16, 'n': 3}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:35:34,560]\u001b[0m Finished trial#37 with value: 0.501 with parameters: {'sigma': 1.8762834208436072, 'lam': 2.344171513727565e-15, 'n': 1}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:35:42,792]\u001b[0m Finished trial#38 with value: 0.653 with parameters: {'sigma': 4.7907361447039225, 'lam': 4.326270182060002e-18, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:35:57,358]\u001b[0m Finished trial#39 with value: 0.501 with parameters: {'sigma': 3.4978394409167533, 'lam': 4.849512610207393e-17, 'n': 3}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:36:06,068]\u001b[0m Finished trial#40 with value: 0.501 with parameters: {'sigma': 2.9878038421987463, 'lam': 9.591766257140457e-15, 'n': 2}. Best is trial#23 with value: 0.659.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:36:15,485]\u001b[0m Finished trial#41 with value: 0.6599999999999999 with parameters: {'sigma': 4.493858628498527, 'lam': 2.403218096061519e-14, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:36:23,963]\u001b[0m Finished trial#42 with value: 0.509 with parameters: {'sigma': 3.9785578626780786, 'lam': 2.4081230016593355e-13, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:36:32,804]\u001b[0m Finished trial#43 with value: 0.658 with parameters: {'sigma': 4.551661892497656, 'lam': 9.844092649788724e-16, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:36:41,230]\u001b[0m Finished trial#44 with value: 0.501 with parameters: {'sigma': 1.0732505193816613, 'lam': 2.9093794863816676e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:36:50,194]\u001b[0m Finished trial#45 with value: 0.654 with parameters: {'sigma': 5.000766815796448, 'lam': 5.10793064189968e-16, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:36:59,613]\u001b[0m Finished trial#46 with value: 0.6584999999999999 with parameters: {'sigma': 4.531333738432753, 'lam': 4.565716758777452e-13, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:37:06,309]\u001b[0m Finished trial#47 with value: 0.6184999999999999 with parameters: {'sigma': 3.7153536089667503, 'lam': 2.56927528081324e-15, 'n': 1}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:37:13,857]\u001b[0m Finished trial#48 with value: 0.6485 with parameters: {'sigma': 4.318811247584609, 'lam': 5.986995243698105e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:37:22,377]\u001b[0m Finished trial#49 with value: 0.557 with parameters: {'sigma': 4.085039318831042, 'lam': 5.467096825466105e-13, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:37:31,360]\u001b[0m Finished trial#50 with value: 0.501 with parameters: {'sigma': 3.266999240987839, 'lam': 7.793299058951485e-12, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:37:39,313]\u001b[0m Finished trial#51 with value: 0.6569999999999999 with parameters: {'sigma': 4.624192541173763, 'lam': 1.2101224895858786e-13, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:37:48,245]\u001b[0m Finished trial#52 with value: 0.6525 with parameters: {'sigma': 5.135515322884643, 'lam': 5.3419683839264474e-14, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:37:56,622]\u001b[0m Finished trial#53 with value: 0.6569999999999999 with parameters: {'sigma': 4.6158499289262656, 'lam': 2.060445859485054e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:38:05,268]\u001b[0m Finished trial#54 with value: 0.5740000000000001 with parameters: {'sigma': 4.110275901962529, 'lam': 6.477021767205439e-16, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:38:14,609]\u001b[0m Finished trial#55 with value: 0.651 with parameters: {'sigma': 5.789949447254694, 'lam': 6.449965929134762e-11, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:38:22,779]\u001b[0m Finished trial#56 with value: 0.501 with parameters: {'sigma': 3.615217696249144, 'lam': 1.1771391965327643e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:38:30,773]\u001b[0m Finished trial#57 with value: 0.654 with parameters: {'sigma': 4.879647116495255, 'lam': 3.365582840700979e-14, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:38:39,814]\u001b[0m Finished trial#58 with value: 0.5065 with parameters: {'sigma': 3.9662393604244532, 'lam': 5.505615053781523e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:38:48,814]\u001b[0m Finished trial#59 with value: 0.501 with parameters: {'sigma': 2.9634876329355886, 'lam': 3.220049356745564e-16, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:39:03,119]\u001b[0m Finished trial#60 with value: 0.6515000000000001 with parameters: {'sigma': 5.366219094093196, 'lam': 3.2512142083192423e-13, 'n': 3}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:39:12,444]\u001b[0m Finished trial#61 with value: 0.6575 with parameters: {'sigma': 4.560685788125671, 'lam': 1.5878621279475128e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:39:22,457]\u001b[0m Finished trial#62 with value: 0.659 with parameters: {'sigma': 4.605189698239455, 'lam': 1.5497968859167323e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:39:32,105]\u001b[0m Finished trial#63 with value: 0.655 with parameters: {'sigma': 4.406433775978452, 'lam': 1.6389761822403623e-16, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:39:40,611]\u001b[0m Finished trial#64 with value: 0.642 with parameters: {'sigma': 4.260419377200301, 'lam': 1.1451067435926362e-14, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:39:50,108]\u001b[0m Finished trial#65 with value: 0.654 with parameters: {'sigma': 4.854398820624273, 'lam': 8.497016817778228e-16, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:39:59,189]\u001b[0m Finished trial#66 with value: 0.651 with parameters: {'sigma': 5.983553919965181, 'lam': 9.836625787725126e-13, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:40:07,770]\u001b[0m Finished trial#67 with value: 0.501 with parameters: {'sigma': 3.844894748804038, 'lam': 2.123929391215483e-18, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:40:16,671]\u001b[0m Finished trial#68 with value: 0.6545 with parameters: {'sigma': 5.27474032859449, 'lam': 3.7507669274768754e-09, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:40:24,528]\u001b[0m Finished trial#69 with value: 0.501 with parameters: {'sigma': 3.314261950861305, 'lam': 2.993349464170407e-14, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:40:33,511]\u001b[0m Finished trial#70 with value: 0.658 with parameters: {'sigma': 4.6092560389197335, 'lam': 1.8111184991442787e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:40:41,570]\u001b[0m Finished trial#71 with value: 0.6595 with parameters: {'sigma': 4.546691807701059, 'lam': 3.5369956682333134e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:40:50,803]\u001b[0m Finished trial#72 with value: 0.654 with parameters: {'sigma': 4.977764159508568, 'lam': 1.2436357855457699e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:41:00,434]\u001b[0m Finished trial#73 with value: 0.6535000000000001 with parameters: {'sigma': 5.643675357331252, 'lam': 9.788648472048865e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:41:08,430]\u001b[0m Finished trial#74 with value: 0.658 with parameters: {'sigma': 4.591804525091998, 'lam': 1.3767560504221062e-18, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:41:16,973]\u001b[0m Finished trial#75 with value: 0.609 with parameters: {'sigma': 4.174345525742804, 'lam': 1.7662740983799917e-18, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:41:26,059]\u001b[0m Finished trial#76 with value: 0.6575 with parameters: {'sigma': 4.696833147305216, 'lam': 1.0293084465916262e-18, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:41:34,341]\u001b[0m Finished trial#77 with value: 0.5075000000000001 with parameters: {'sigma': 3.9721923251405884, 'lam': 2.0202654354123178e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:41:44,183]\u001b[0m Finished trial#78 with value: 0.501 with parameters: {'sigma': 2.0795490845055844, 'lam': 0.000737361713729758, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:41:52,502]\u001b[0m Finished trial#79 with value: 0.501 with parameters: {'sigma': 3.6075515486585137, 'lam': 4.875564962852795e-18, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:42:01,028]\u001b[0m Finished trial#80 with value: 0.501 with parameters: {'sigma': 1.484954490870698, 'lam': 7.86109437785844e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:42:09,922]\u001b[0m Finished trial#81 with value: 0.6599999999999999 with parameters: {'sigma': 4.544973415075386, 'lam': 1.2409538551520603e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:42:18,360]\u001b[0m Finished trial#82 with value: 0.651 with parameters: {'sigma': 5.105746171504093, 'lam': 2.351691946938753e-16, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:42:28,063]\u001b[0m Finished trial#83 with value: 0.6455 with parameters: {'sigma': 4.3043917327673435, 'lam': 7.478099822018009e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:42:37,712]\u001b[0m Finished trial#84 with value: 0.659 with parameters: {'sigma': 4.492902875961836, 'lam': 1.0813923221089368e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:42:46,103]\u001b[0m Finished trial#85 with value: 0.653 with parameters: {'sigma': 4.902137411194346, 'lam': 1.062431246568822e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:42:56,034]\u001b[0m Finished trial#86 with value: 0.655 with parameters: {'sigma': 5.470334025255201, 'lam': 7.556304080164081e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:43:05,036]\u001b[0m Finished trial#87 with value: 0.5475000000000001 with parameters: {'sigma': 4.069710693075247, 'lam': 1.1486918571920715e-16, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:43:13,625]\u001b[0m Finished trial#88 with value: 0.6529999999999999 with parameters: {'sigma': 5.214410609800558, 'lam': 6.13045981472466e-18, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:43:23,346]\u001b[0m Finished trial#89 with value: 0.658 with parameters: {'sigma': 4.443007234071015, 'lam': 2.900105962538621e-17, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:43:31,552]\u001b[0m Finished trial#90 with value: 0.501 with parameters: {'sigma': 3.8565696194750982, 'lam': 2.293921732899615e-14, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:43:40,448]\u001b[0m Finished trial#91 with value: 0.6575 with parameters: {'sigma': 4.6981029634588385, 'lam': 3.148435852483205e-15, 'n': 2}. Best is trial#41 with value: 0.6599999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:43:48,789]\u001b[0m Finished trial#92 with value: 0.6605 with parameters: {'sigma': 4.540440023335143, 'lam': 3.3915545501902797e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:43:57,601]\u001b[0m Finished trial#93 with value: 0.642 with parameters: {'sigma': 4.270454804085777, 'lam': 3.7641330648552693e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:44:06,579]\u001b[0m Finished trial#94 with value: 0.6545 with parameters: {'sigma': 4.768500494236236, 'lam': 3.858042210444832e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:44:16,135]\u001b[0m Finished trial#95 with value: 0.6529999999999999 with parameters: {'sigma': 4.374548761913048, 'lam': 4.4774625118984215e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:44:24,148]\u001b[0m Finished trial#96 with value: 0.657 with parameters: {'sigma': 4.479801894625364, 'lam': 1.6219532721036425e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:44:32,703]\u001b[0m Finished trial#97 with value: 0.6085 with parameters: {'sigma': 4.167395308163336, 'lam': 3.4582847995903706e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:44:42,219]\u001b[0m Finished trial#98 with value: 0.6519999999999999 with parameters: {'sigma': 5.074209858856798, 'lam': 7.504712650097919e-14, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:44:51,565]\u001b[0m Finished trial#99 with value: 0.5035 with parameters: {'sigma': 3.946214409309941, 'lam': 4.952115405357407e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:45:01,081]\u001b[0m Finished trial#100 with value: 0.501 with parameters: {'sigma': 3.7071236221534907, 'lam': 1.9826488938210127e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:45:10,177]\u001b[0m Finished trial#101 with value: 0.656 with parameters: {'sigma': 4.465385836204336, 'lam': 1.0326960501195402e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:45:19,271]\u001b[0m Finished trial#102 with value: 0.6535 with parameters: {'sigma': 4.814241714522136, 'lam': 2.3120612250216043e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:45:27,470]\u001b[0m Finished trial#103 with value: 0.657 with parameters: {'sigma': 4.478639008986402, 'lam': 1.0210968105849385e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:45:36,709]\u001b[0m Finished trial#104 with value: 0.6575 with parameters: {'sigma': 4.694499120109669, 'lam': 3.333823530989079e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:45:45,388]\u001b[0m Finished trial#105 with value: 0.632 with parameters: {'sigma': 4.208779162030335, 'lam': 1.5701967315826094e-14, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:45:53,928]\u001b[0m Finished trial#106 with value: 0.6555 with parameters: {'sigma': 4.94603319818871, 'lam': 1.0446291625457674e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:46:02,519]\u001b[0m Finished trial#107 with value: 0.6529999999999999 with parameters: {'sigma': 5.21852103982626, 'lam': 2.6380960871169756e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:46:11,026]\u001b[0m Finished trial#108 with value: 0.657 with parameters: {'sigma': 4.587673486711901, 'lam': 7.488304619253089e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:46:18,948]\u001b[0m Finished trial#109 with value: 0.514 with parameters: {'sigma': 4.003164330497417, 'lam': 1.4059976416610115e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:46:27,099]\u001b[0m Finished trial#110 with value: 0.6540000000000001 with parameters: {'sigma': 5.544495706781013, 'lam': 5.48281428356779e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:46:35,025]\u001b[0m Finished trial#111 with value: 0.658 with parameters: {'sigma': 4.584468743824337, 'lam': 7.974925046524336e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:46:43,917]\u001b[0m Finished trial#112 with value: 0.657 with parameters: {'sigma': 4.66750587954585, 'lam': 8.686996116502164e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:46:52,002]\u001b[0m Finished trial#113 with value: 0.6505000000000001 with parameters: {'sigma': 4.332372073597185, 'lam': 3.917603960233075e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:47:01,947]\u001b[0m Finished trial#114 with value: 0.6545 with parameters: {'sigma': 4.981595870272801, 'lam': 5.054687725427031e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:47:12,221]\u001b[0m Finished trial#115 with value: 0.501 with parameters: {'sigma': 4.160469611863134, 'lam': 0.9651435323120656, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:47:21,069]\u001b[0m Finished trial#116 with value: 0.657 with parameters: {'sigma': 4.479277389119828, 'lam': 1.64148127122486e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:47:30,935]\u001b[0m Finished trial#117 with value: 0.656 with parameters: {'sigma': 5.3725033234964625, 'lam': 1.5224268003507177e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:47:39,538]\u001b[0m Finished trial#118 with value: 0.654 with parameters: {'sigma': 4.867399034991769, 'lam': 2.2266920309417647e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:47:48,285]\u001b[0m Finished trial#119 with value: 0.6485 with parameters: {'sigma': 4.319408229456358, 'lam': 2.9854519713190364e-14, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:47:56,537]\u001b[0m Finished trial#120 with value: 0.6525000000000001 with parameters: {'sigma': 5.735871050725499, 'lam': 1.4808435360939798e-13, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:48:04,874]\u001b[0m Finished trial#121 with value: 0.659 with parameters: {'sigma': 4.5080436085910165, 'lam': 5.792736123866006e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:48:13,417]\u001b[0m Finished trial#122 with value: 0.657 with parameters: {'sigma': 4.619709060577784, 'lam': 4.928347030242265e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:48:21,783]\u001b[0m Finished trial#123 with value: 0.565 with parameters: {'sigma': 4.095496361721225, 'lam': 1.0984037146105382e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:48:31,046]\u001b[0m Finished trial#124 with value: 0.653 with parameters: {'sigma': 5.05680034144114, 'lam': 6.802577361260937e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:48:39,334]\u001b[0m Finished trial#125 with value: 0.501 with parameters: {'sigma': 2.450035069482271, 'lam': 3.0174721704446954e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:48:48,201]\u001b[0m Finished trial#126 with value: 0.6535 with parameters: {'sigma': 4.7842103155373685, 'lam': 9.189252203058003e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:48:57,166]\u001b[0m Finished trial#127 with value: 0.658 with parameters: {'sigma': 4.5015294936368155, 'lam': 1.824386357222135e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:49:05,778]\u001b[0m Finished trial#128 with value: 0.6370000000000001 with parameters: {'sigma': 4.2294575287422225, 'lam': 8.543998760770785e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:49:14,587]\u001b[0m Finished trial#129 with value: 0.5015 with parameters: {'sigma': 3.908833314126044, 'lam': 3.6662032159776855e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:49:23,508]\u001b[0m Finished trial#130 with value: 0.6545 with parameters: {'sigma': 4.390430667295244, 'lam': 1.8771891676170293e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:49:31,781]\u001b[0m Finished trial#131 with value: 0.6575 with parameters: {'sigma': 4.555109156787824, 'lam': 1.1508112172762635e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:49:40,249]\u001b[0m Finished trial#132 with value: 0.655 with parameters: {'sigma': 4.770529764116809, 'lam': 1.787356593359395e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:49:49,082]\u001b[0m Finished trial#133 with value: 0.657 with parameters: {'sigma': 4.632781070312497, 'lam': 6.101465953655333e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:49:57,977]\u001b[0m Finished trial#134 with value: 0.659 with parameters: {'sigma': 4.432645867445376, 'lam': 4.007901364002803e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:50:06,661]\u001b[0m Finished trial#135 with value: 0.55 with parameters: {'sigma': 4.0711895267333835, 'lam': 1.863512880470485e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:50:15,564]\u001b[0m Finished trial#136 with value: 0.6545 with parameters: {'sigma': 5.230296590253688, 'lam': 3.9322013852669265e-18, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:50:23,962]\u001b[0m Finished trial#137 with value: 0.6365000000000001 with parameters: {'sigma': 4.24228814237488, 'lam': 4.590668584803549e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:50:32,425]\u001b[0m Finished trial#138 with value: 0.659 with parameters: {'sigma': 4.422110279859127, 'lam': 9.296252576319028e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:50:41,342]\u001b[0m Finished trial#139 with value: 0.6545 with parameters: {'sigma': 4.400544684206889, 'lam': 8.776746469110128e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:50:49,031]\u001b[0m Finished trial#140 with value: 0.654 with parameters: {'sigma': 4.88044355098839, 'lam': 1.7860968889101345e-14, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:50:57,483]\u001b[0m Finished trial#141 with value: 0.6599999999999999 with parameters: {'sigma': 4.493918976898027, 'lam': 3.7051677421207344e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:51:06,283]\u001b[0m Finished trial#142 with value: 0.6545 with parameters: {'sigma': 4.400595537916561, 'lam': 2.8184728187963995e-17, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:51:15,919]\u001b[0m Finished trial#143 with value: 0.6529999999999999 with parameters: {'sigma': 5.027883642333087, 'lam': 3.164110425892933e-16, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:51:25,467]\u001b[0m Finished trial#144 with value: 0.654 with parameters: {'sigma': 4.780058248319486, 'lam': 1.3767560093782357e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:51:32,397]\u001b[0m Finished trial#145 with value: 0.501 with parameters: {'sigma': 3.732285824539125, 'lam': 4.682561418722705e-15, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:51:38,654]\u001b[0m Finished trial#146 with value: 0.6595 with parameters: {'sigma': 4.600906500842056, 'lam': 5.151583551937224e-14, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:51:44,616]\u001b[0m Finished trial#147 with value: 0.6325 with parameters: {'sigma': 4.206633640329859, 'lam': 3.3246402589951794e-14, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:51:50,400]\u001b[0m Finished trial#148 with value: 0.658 with parameters: {'sigma': 4.4861193955439385, 'lam': 9.79202916019861e-14, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:51:56,599]\u001b[0m Finished trial#149 with value: 0.657 with parameters: {'sigma': 4.7282722614133625, 'lam': 8.538158725438589e-13, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 12:52:02,273]\u001b[0m Finished trial#150 with value: 0.525 with parameters: {'sigma': 4.033091201325787, 'lam': 3.2732693155558813e-13, 'n': 2}. Best is trial#92 with value: 0.6605.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X_train_ = pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train_ = pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test_ = pd.read_csv('./data/Xte.csv', sep=',')\n",
    "\n",
    "\n",
    "def objective_sgd(trial):\n",
    "    \n",
    "    \n",
    "#     c  = trial.suggest_loguniform('c', 1e-20, 2e1)\n",
    "    sigma  = trial.suggest_loguniform('sigma', 1e-0, 6e+0) # trial.suggest_float('sigma', 1e-5, 1e-3, log=True)\n",
    "#     kenel = trial.suggest_categorical('kenel', [rbf_kernel, quadratic_kernel])\n",
    "    lam = trial.suggest_loguniform('lam', 1e-18, 1e-0)\n",
    "#     tol = trial.suggest_loguniform('tol', 1e-7, 1e-0)\n",
    "    \n",
    "#     normalise = trial.suggest_categorical('normalise', [False , True])\n",
    "    \n",
    "    n = trial.suggest_int('n', 1, 3)\n",
    "    \n",
    "    \n",
    "#     model = trial.suggest_categorical('models', [ksolveRR , ksolveRR_2, ksolveLRR, KernelSVM])\n",
    "    \n",
    "    # ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "    # ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "    # ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "    # KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "    \n",
    "#     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "#               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM'} \n",
    "#     \n",
    "    kenel = rbf_kernel\n",
    "    models = {ksolveRR : 'k Ridge Reg'} \n",
    "      \n",
    "#     accuracy = []\n",
    "#     for model in models:\n",
    "#     ipdb.set_trace()\n",
    "    \n",
    "#     X_train=pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "#     Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "#     X_test=pd.read_csv('./data/Xte.csv', sep=',')\n",
    "    X_cross, y_cross, X_t_enc = spectrum_kernal(X_train_, Y_train_, X_test_, n=n, encoder=4, one_hot = True, normalise = False)\n",
    "    \n",
    "    for model in models:\n",
    "        accuracy = []\n",
    "        for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "            X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "            X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "\n",
    "\n",
    "    #             ipdb.set_trace()\n",
    "            if models[model] == 'weigh Ridge Reg':\n",
    "                sample_weights = np.random.rand(len(y_train))\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "\n",
    "            elif models[model] == 'k Logistic Ridge Reg':\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kenel)\n",
    "            elif models[model] == 'k Ridge Reg':\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, kernel = kenel)\n",
    "            else:\n",
    "                model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kenel)\n",
    "\n",
    "            model_curr.fit()\n",
    "            accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "    #             print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "\n",
    "    #         print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')\n",
    "\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective_sgd, n_trials=500, show_progress_bar=True)\n",
    "\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kenel = rbf_kernel\n",
    "#     models = {ksolveRR: 'k Ridge Reg'} \n",
    "# Accuracy: 0.624\n",
    "# Best hyperparameters: {'sigma': 0.5676751743446526, 'lam': 5.181586550863371e-06}\n",
    "# time: 973 µs\n",
    "\n",
    "#------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented data\n",
    "\n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-20, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-20, 1e-1)\n",
    "\n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Augmented data)\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: 0.6555\n",
    "    # Best hyperparameters: {'sigma': 4.065620491225982, 'lam': 0.013374107290659768}\n",
    "    # time: 49min 21s\n",
    "    #----\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.6575 # 0.6575000000000001\n",
    "    # Best hyperparameters: {'sigma': 4.119788517147901, 'lam': 1.2752298700618223e-14}, {'sigma': 4.063158315715049, 'lam': 8.30834772639223e-05}\n",
    "    # time: 32min 57s\n",
    "\n",
    "    \n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-3, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "\n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Non-Augmented data)\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: 0.6555\n",
    "    # Best hyperparameters: {'sigma': 4.069738272304652, 'lam': 0.053817561640154984}\n",
    "    # time: 48min 12s\n",
    "    #----\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.6575000000000001\n",
    "    # Best hyperparameters: {'sigma': 4.001185698777986, 'lam': 1.9770379950513775e-10}\n",
    "    # time: 29min 58s\n",
    "    \n",
    "\n",
    "\n",
    "# Original data\n",
    "\n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-3, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "  \n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Non-Augmented data standardize)\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.612\n",
    "    # Best hyperparameters: {'sigma': 2.8925324917718167, 'lam': 1.2575244169567934e-08}\n",
    "    # time: 28min 33s \n",
    "    #----\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: EROOR LinearAlg\n",
    "    # Best hyperparameters: \n",
    "    # time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy fold 0: 0.5975\n",
      "accurracy fold 1: 0.6625\n",
      "accurracy fold 2: 0.68\n",
      "accurracy fold 3: 0.6475\n",
      "accurracy fold 4: 0.7\n",
      "\n",
      "Average accuracy k Ridge Reg is : 0.6575\n",
      "\n",
      "time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "#     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "#               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM'\n",
    "\n",
    "# c  = \n",
    "sigma  = 4.119788517147901\n",
    "kenel = rbf_kernel\n",
    "lam = 1.2752298700618223e-14\n",
    "# tol = \n",
    "    \n",
    "#     ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "#     ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "#     ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "#     KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "\n",
    "    \n",
    "models = {ksolveRR : 'k Ridge Reg'}\n",
    "\n",
    "for model in models:\n",
    "    accuracy = []\n",
    "    for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "\n",
    "        X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "        X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "\n",
    "        if models[model] == 'weigh Ridge Reg':\n",
    "            sample_weights = np.random.rand(len(y_train))\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "        elif models[model] == 'k Logistic Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=500, tol = tol, kernel = kenel)\n",
    "        \n",
    "        elif models[model] == 'k Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, kernel = kenel)\n",
    "        else:\n",
    "            model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kenel)\n",
    "            \n",
    "        model_curr.fit()\n",
    "\n",
    "        accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "        print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "    \n",
    "    print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 525 µs\n"
     ]
    }
   ],
   "source": [
    "# 0.6535 = 0.68800\n",
    "# 0.657 = 0.69200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 881 µs\n"
     ]
    }
   ],
   "source": [
    "# # Cehckinf full model\n",
    "# model = ksolveRR(X_cross, y_cross, lam = lam, sigma = sigma, kernel = kenel)\n",
    "# # model = svm_primal_soft_to_qp(X_cross, y_cross, C=1)\n",
    "\n",
    "# model.fit()\n",
    "\n",
    "# model.Accuracy_check(X_cross, y_cross, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 393 ms\n"
     ]
    }
   ],
   "source": [
    "model = ksolveRR(X_cross, y_cross, lam = lam, sigma = sigma, kernel = kenel)\n",
    "model.fit()\n",
    "y_pred = model.predict(X_t_enc, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id\n",
       "0   0\n",
       "1   1\n",
       "2   2\n",
       "3   3\n",
       "4   4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.73 ms\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1000).reshape(-1, 1)\n",
    "sample = pd.DataFrame(data=X, columns=['Id'])\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.42 ms\n"
     ]
    }
   ],
   "source": [
    "sample['Bound'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Bound\n",
       "995  995      0\n",
       "996  996      0\n",
       "997  997      1\n",
       "998  998      1\n",
       "999  999      1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.8 ms\n"
     ]
    }
   ],
   "source": [
    "sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.12 ms\n"
     ]
    }
   ],
   "source": [
    "sample.to_csv('./ksolveRR_6575_cv_rbf_kernel_sigma_4.119788517147901_lam_1.2752298700618223e-14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
