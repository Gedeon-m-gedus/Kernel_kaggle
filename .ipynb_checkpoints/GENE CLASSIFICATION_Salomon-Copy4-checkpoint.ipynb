{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#@title Installation\n",
    "!pip install --quie ipdb # debug\n",
    "!pip install --quie ipython-autotime  # timming\n",
    "!pip install --quie optuna  # hyperparaeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxopt\n",
    "np.random.seed(54321)\n",
    "\n",
    "import ipdb\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46.2 ms\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test=pd.read_csv('./data/Xte.csv', sep=',') #we will use this data set later to validate our model\n",
    "\n",
    "# X_train_mat=pd.read_csv('./data/Xtr_mat100.csv', sep=',') #we use this dataset to train our model\n",
    "# X_test_mat=pd.read_csv('./data/Xte_mat100.csv', sep=',') #we will use this data set later to validate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                                seq\n",
       "1995  1995  TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...\n",
       "1996  1996  ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...\n",
       "1997  1997  TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...\n",
       "1998  1998  CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...\n",
       "1999  1999  TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.8 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_train dataset is: (2000, 2)\n",
      "The shape of the Y_train dataset is: (2000, 2)\n",
      "time: 1.93 ms\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the X_train dataset is:',X_train.shape)\n",
    "print('The shape of the Y_train dataset is:',Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 794 µs\n"
     ]
    }
   ],
   "source": [
    "# X_train['len'] = X_train.seq.apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   1  CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   2  GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   3  GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   4  GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.7 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   1  CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   2  GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   3  GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   4  GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.4 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 938 µs\n"
     ]
    }
   ],
   "source": [
    "# X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "# X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "# y = Y_train.Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegressionBinary():\n",
    "    def __init__(self, lr=0.1, num_iter=100000, batch_size=1, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def __sigmoid_func(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y = self.trans_y(y)\n",
    "        X = self.__add_intercept(X)\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.__sigmoid_func(z)\n",
    "                        \n",
    "            rand = np.random.choice(y.size, self.batch_size).squeeze()\n",
    "            gradient = np.dot(X[rand].T, (h[rand] - y[rand]))/y.size   \n",
    "        \n",
    "            self.theta -= self.lr * gradient\n",
    "            #print('theta and grad',self.theta.shape ,  gradient.shape )\n",
    "            if(self.verbose == True and i % 100 == 0):\n",
    "                z = np.dot(X, self.theta)\n",
    "                h = self.__sigmoid(z)\n",
    "                print(f'loss: {self.__loss(h, y)} \\t')\n",
    "    \n",
    "    def predict_probability(self, X):\n",
    "        X = self.__add_intercept(X)\n",
    "    \n",
    "        return self.__sigmoid_func(np.dot(X, self.theta))\n",
    "    \n",
    "    def predict(self, X, threshold=.5):\n",
    "          return np.where(self.predict_probability(X) >= 0.5, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self, X, y, threshold = 0.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "    def trans_y(self, y):\n",
    "        if isinstance(y, pd.Series):\n",
    "            y = y.values\n",
    "        if isinstance(y, list):\n",
    "            y = np.array(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression (RR)\n",
    "\n",
    "class solveRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "            \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        A = (X.T.dot(X)) + np.eye(p)*lam*n\n",
    "        b = X.T.dot(y)\n",
    "        \n",
    "        self.beta = np.linalg.solve(A, b)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Weighted Ridge Regression (WRR)\n",
    "class solveWRR():\n",
    "    def __init__(self, X, y, w, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.w = w\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        w = self.w\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == len(w) == n)\n",
    "\n",
    "        y1 = np.sqrt(w) * y\n",
    "        X1 = (np.sqrt(w) * X.T).T\n",
    "        \n",
    "        # Hint:\n",
    "        # Find y1 and X1 such that:\n",
    "        \n",
    "        self.beta = solveRR(X1, y1, lam).fit()\n",
    "                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Logistic Ridge Regression (LRR)\n",
    "class solveLRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "    \n",
    "        lam = self.lam \n",
    "        max_iter = 50\n",
    "        eps = 1e-3\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialize\n",
    "        self.beta = np.zeros(p)\n",
    "\n",
    "        # Hint: Use IRLS\n",
    "        for i in range(max_iter):\n",
    "            beta_old = self.beta\n",
    "            f = X.dot(beta_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*f)\n",
    "            self.beta = solveWRR(X, z, w, 2*lam).fit()\n",
    "            # Break condition (achieved convergence)\n",
    "            #if np.sum((beta-beta_old)**2) < eps:\n",
    "            #    break                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 89.3 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "### Functions for you to fill in ###\n",
    "\n",
    "def polynomial_kernel(X, Y, c, p):\n",
    "    \"\"\"\n",
    "        Compute the polynomial kernel between two matrices X and Y::\n",
    "            K(x, y) = (<x, y> + c)^p\n",
    "        for each pair of rows x in X and y in Y.\n",
    "\n",
    "        Args:\n",
    "            X - (n, d) NumPy array (n datapoints each with d features)\n",
    "            Y - (m, d) NumPy array (m datapoints each with d features)\n",
    "            c - a coefficient to trade off high-order and low-order terms (scalar)\n",
    "            p - the degree of the polynomial kernel\n",
    "\n",
    "        Returns:\n",
    "            kernel_matrix - (n, m) Numpy array containing the kernel matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError\n",
    "    kernel_matrix = (X.dot(Y.T) + c)**p\n",
    "    \n",
    "    return kernel_matrix\n",
    "\n",
    "\n",
    "def rbf_kernel_element_wise(x, y, sigma=1):\n",
    "    '''\n",
    "    returns the RBF (Gaussian) kernel k(x, y)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    x and y are p-dimensional vectors \n",
    "    '''\n",
    "    K = np.exp(- np.sum((x - y)**2) / (2 * sigma ** 2))\n",
    "    return K\n",
    "\n",
    "# def rbf_kernel(X1, X2, sigma=10):\n",
    "#     '''\n",
    "#     Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "#     Input:\n",
    "#     ------\n",
    "#     X1: an (n1, p) matrix\n",
    "#     X2: an (n2, p) matrix\n",
    "#     '''\n",
    "#     # For loop with rbf_kernel_element works but is slow in python\n",
    "#     # Use matrix operations!\n",
    "#     X2_norm = np.sum(X2 ** 2, axis=-1)\n",
    "#     X1_norm = np.sum(X1 ** 2, axis=-1)\n",
    "#     gamma = 1 / (2 * sigma ** 2)\n",
    "#     K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "#     return K\n",
    "\n",
    "# class rbf_kernel():\n",
    "#     '''\n",
    "#     Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "#     Input:\n",
    "#     ------\n",
    "#     X1: an (n1, p) matrix\n",
    "#     X2: a\n",
    "#     '''\n",
    "\n",
    "#     def __init__(self, sigma=2.0):\n",
    "#         self.sigma = sigma\n",
    "\n",
    "#     def _compute(self, X1, X2):\n",
    "#         # For loop with rbf_kernel_element works but is slow in python\n",
    "#         # Use matrix operations!\n",
    "#         X2_norm = np.sum(X2 ** 2, axis=-1)\n",
    "#         X1_norm = np.sum(X1 ** 2, axis=-1)\n",
    "#         gamma = 1 / (2 * self.sigma ** 2)\n",
    "#         K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "#         return K\n",
    "\n",
    "\n",
    "\n",
    "def laplace(X1, X2, alpha=10):\n",
    "    return np.exp(-alpha*np.abs(X1-X2))\n",
    "\n",
    "\n",
    "def linear_kernel(X1, X2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the linear kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return X1.dot(X2.T)\n",
    "\n",
    "def quadratic_kernel(X1, X2, power=2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the quadratic kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return (1 + linear_kernel(X1, X2))**power\n",
    "\n",
    "def rbf_poly_kernel(X1, X2, sigma=10, d=2, rbf=1.0, poly=1.0):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis=-1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis=-1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    \n",
    "    return rbf*K + poly*(X1.dot(X2.T) +1)**d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 44 ms\n"
     ]
    }
   ],
   "source": [
    "class ksolveRR_2():\n",
    "    def __init__(self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = None):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.sigma = sigma\n",
    "        self.kernel = kernel\n",
    "        self.sample_weights = sample_weights\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        if self.sample_weights is not None:\n",
    "            self.X *= self.sample_weights[:, None]\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "        A = self.kernel(X, X, self.sigma)+n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42 ms\n"
     ]
    }
   ],
   "source": [
    "class ksolveRR():\n",
    "    def __init__(self, X, y, lam= 0.0001, kernel=None):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.kernel = kernel\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "#         if self.sigma is None:\n",
    "#             self.sigma = sigma_from_median(X)\n",
    "            \n",
    "#         A = self.kernel(X, X, self.sigma)+n*self.lam*np.eye(n)\n",
    "        A = self.kernel(X, X) + n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "#         K_x = self.kernel(X, self.X, self.sigma)\n",
    "        K_x = self.kernel(X, self.X)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 92.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Logistic Ridge Regression (LRR)\n",
    "class ksolveLRR():\n",
    "    def __init__(self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=None):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        K = self.kernel(X, X)\n",
    "\n",
    "        # Initialize\n",
    "        alpha = np.zeros(n)\n",
    "        \n",
    "        # Hint: Use IRLS\n",
    "        for n_iter in range(self.max_iter):\n",
    "            alpha_old = alpha\n",
    "            f = K.dot(alpha_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*(f))\n",
    "            \n",
    "            alpha = ksolveRR_2(X, y, lam = 2*self.lam, \\\n",
    "                               sigma=self.sigma, sample_weights = w).fit().alpha\n",
    "            \n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < self.tol:\n",
    "                break  \n",
    "                \n",
    "                \n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        K_x = self.kernel(X, self.X)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "# You don't need to look at this, this is just to adapt our matrices\n",
    "# to the solver being used\n",
    "solver='cvxopt'\n",
    "\n",
    "import cvxopt\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    #cvxopt.solvers.options['show_progress'] = False\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = cvxopt_qp\n",
    "\n",
    "def quadprog_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "    qp_G = .5 * (P + P.T)   # make sure P is symmetric\n",
    "    qp_a = -q\n",
    "    if A is not None:\n",
    "        qp_C = -np.vstack([A, G]).T\n",
    "        qp_b = -np.hstack([b, h])\n",
    "        meq = A.shape[0]\n",
    "    else:  # no equality constraint\n",
    "        qp_C = - G.T\n",
    "        qp_b = - h\n",
    "        meq = 0\n",
    "    return quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)[0]\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices)\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = {'quadprog': quadprog_solve_qp, 'cvxopt': cvxopt_qp}[solver]\n",
    "\n",
    "def svm_dual_soft_to_qp_kernel(K, y, C=1):\n",
    "    n = K.shape[0]\n",
    "    assert (len(y) == n)\n",
    "        \n",
    "    # Dual formulation, soft margin\n",
    "    P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "    # As a regularization, we add epsilon * identity to P\n",
    "    eps = 1e-12\n",
    "    P += eps * np.eye(n)\n",
    "    q = - np.ones(n)\n",
    "    G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "    h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "    A = y[np.newaxis, :]\n",
    "    A = A.astype('float')\n",
    "    b = np.array([0.])\n",
    "    return P, q, G, h, A, b\n",
    "\n",
    "# SVM primal soft\n",
    "class KernelSVM():\n",
    "    def __init__(self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=None):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.lam = lam        \n",
    "        self.sigma = sigma\n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        C = self.C\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        K = self.kernel(X, X)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = solve_qp(*svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        \n",
    "       # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha>self.tol), (self.C - self.alpha > self.tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha*y)\n",
    "        self.bias =  self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "#         y_pred = self.kernel(X, self.X_).dot(self.alphas* seld.y_)\n",
    "        K_x = self.kernel(X, self.X)\n",
    "        return np.where((K_x.dot(self.alpha * self.y) +  self.bias) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 141 ms\n"
     ]
    }
   ],
   "source": [
    "X_train_ = pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train_ = pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test_ = pd.read_csv('./data/Xte.csv', sep=',')\n",
    "\n",
    "kfold=KFold(n_splits=5)\n",
    "\n",
    "def spectrum_kernal(X_train, y, X_test, n=2, encoder=4, one_hot = True, normalise = False):\n",
    "    \n",
    "    d = {'A': 0.1, 'C':0.2, 'G':0.3, 'T':0.4}\n",
    "    \n",
    "    for i in range(0, 101-n+1, 1):\n",
    "        X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :x[i:i+n])\n",
    "        X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :x[i:i+n])\n",
    "        \n",
    "        X_train['seq_'+str(i)] = X_train['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        X_test['seq_'+str(i)] = X_test['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        \n",
    "        \n",
    "        \n",
    "    X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "    X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "    y = Y_train.Bound\n",
    "    \n",
    "#     print(f'Train: \\n{X.tail()}\\n -----------------------\\n')\n",
    "#     print(f'Test: \\n {X_t.tail()}')\n",
    "\n",
    "    if one_hot:\n",
    "        onehot_encoder = OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore')\n",
    "\n",
    "        X_cross = X.values\n",
    "        X_t = X_t.values\n",
    "        \n",
    "        enc = onehot_encoder.fit(X)\n",
    "        X_cross = enc.transform(X)\n",
    "        X_t_enc = enc.transform(X_t)\n",
    "        \n",
    "    elif normalise:\n",
    "        scaler = MinMaxScaler()#MinMaxScaler() # StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        \n",
    "        X_cross = scaler.transform(X)\n",
    "        X_t_enc = scaler.transform(X_t)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        X_cross = X.values\n",
    "        X_t_enc = X_t.values\n",
    "    \n",
    "    y_cross = y.values\n",
    "    \n",
    "    return X_cross, y_cross, X_t_enc\n",
    "\n",
    "# X_cross, y_cross, X_t_enc = spectrum_kernal(X_train, Y_train, X_test, n=5, encoder=3, one_hot = True, normalise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.32 ms\n"
     ]
    }
   ],
   "source": [
    "# X_train_ = pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "# Y_train_ = pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "# X_test_ = pd.read_csv('./data/Xte.csv', sep=',')\n",
    "\n",
    "# X_cross, y_cross, X_t_enc = spectrum_kernal(X_train_, Y_train_, X_test_, n=1, encoder=8, one_hot = True, normalise = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 916 µs\n"
     ]
    }
   ],
   "source": [
    "# rbf_kernel(X_cross, X_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 578 µs\n"
     ]
    }
   ],
   "source": [
    "# Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.73 ms\n"
     ]
    }
   ],
   "source": [
    "from kernels.basic import RBF, Linear, Polynomial\n",
    "from kernels.regular import rbf_kernel, Exponential, Laplacian, RationalQuadratic, \\\n",
    "                            InverseMultiquadratic, Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 710 µs\n"
     ]
    }
   ],
   "source": [
    "# k = rbf_kernel(sigma=2)\n",
    "# k(X_cross, X_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2d4339915a4fa2adc50bec33383c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8603e+03 -2.7158e+04  4e+04  2e-01  8e-16\n",
      " 1: -3.2513e+03 -5.3800e+03  2e+03  8e-03  2e-15\n",
      " 2: -4.8974e+03 -5.0050e+03  1e+02  2e-04  1e-15\n",
      " 3: -4.9135e+03 -4.9145e+03  1e+00  2e-06  9e-16\n",
      " 4: -4.9136e+03 -4.9136e+03  1e-02  2e-08  1e-15\n",
      " 5: -4.9136e+03 -4.9136e+03  1e-04  2e-10  8e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8816e+03 -2.7287e+04  4e+04  2e-01  1e-15\n",
      " 1: -3.2755e+03 -5.4158e+03  2e+03  8e-03  9e-16\n",
      " 2: -4.9338e+03 -5.0420e+03  1e+02  2e-04  1e-15\n",
      " 3: -4.9500e+03 -4.9511e+03  1e+00  2e-06  8e-16\n",
      " 4: -4.9502e+03 -4.9502e+03  1e-02  2e-08  9e-16\n",
      " 5: -4.9502e+03 -4.9502e+03  1e-04  2e-10  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.7753e+03 -2.6640e+04  4e+04  2e-01  8e-16\n",
      " 1: -3.1546e+03 -5.2370e+03  2e+03  8e-03  1e-15\n",
      " 2: -4.7518e+03 -4.8569e+03  1e+02  2e-04  1e-15\n",
      " 3: -4.7673e+03 -4.7684e+03  1e+00  2e-06  1e-15\n",
      " 4: -4.7675e+03 -4.7675e+03  1e-02  2e-08  1e-15\n",
      " 5: -4.7675e+03 -4.7675e+03  1e-04  2e-10  7e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8497e+03 -2.7093e+04  4e+04  2e-01  9e-16\n",
      " 1: -3.2392e+03 -5.3621e+03  2e+03  8e-03  1e-15\n",
      " 2: -4.8792e+03 -4.9865e+03  1e+02  2e-04  1e-15\n",
      " 3: -4.8952e+03 -4.8963e+03  1e+00  2e-06  2e-15\n",
      " 4: -4.8954e+03 -4.8954e+03  1e-02  2e-08  1e-15\n",
      " 5: -4.8954e+03 -4.8954e+03  1e-04  2e-10  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8391e+03 -2.7028e+04  4e+04  2e-01  9e-16\n",
      " 1: -3.2271e+03 -5.3443e+03  2e+03  8e-03  1e-15\n",
      " 2: -4.8610e+03 -4.9680e+03  1e+02  2e-04  1e-15\n",
      " 3: -4.8769e+03 -4.8780e+03  1e+00  2e-06  9e-16\n",
      " 4: -4.8771e+03 -4.8771e+03  1e-02  2e-08  1e-15\n",
      " 5: -4.8771e+03 -4.8771e+03  1e-04  2e-10  1e-15\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:45:55,553]\u001b[0m Finished trial#0 with value: 0.501 with parameters: {'q': 0.00042532549726246536, 'sigma': 4.52986806816326, 'kernel': 1, 'lam': 1.4110280090288133e-05, 'd': 8, 'c': 6.088766642253131, 'degree': 3, 'n': 3}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.5308e+02 -2.7333e+03  7e+03  1e+00  6e-16\n",
      " 1: -7.4189e+02 -1.4124e+03  7e+02  1e-02  5e-16\n",
      " 2: -8.8379e+02 -9.1083e+02  3e+01  5e-04  4e-16\n",
      " 3: -8.9902e+02 -8.9929e+02  3e-01  5e-06  2e-16\n",
      " 4: -8.9917e+02 -8.9917e+02  3e-03  5e-08  4e-16\n",
      " 5: -8.9917e+02 -8.9917e+02  3e-05  5e-10  5e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.5943e+02 -2.7403e+03  7e+03  1e+00  6e-16\n",
      " 1: -7.4739e+02 -1.4198e+03  7e+02  1e-02  4e-16\n",
      " 2: -8.9035e+02 -9.1748e+02  3e+01  5e-04  5e-16\n",
      " 3: -9.0570e+02 -9.0597e+02  3e-01  5e-06  3e-16\n",
      " 4: -9.0585e+02 -9.0586e+02  3e-03  5e-08  4e-16\n",
      " 5: -9.0586e+02 -9.0586e+02  3e-05  5e-10  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.2771e+02 -2.7050e+03  7e+03  1e+00  6e-16\n",
      " 1: -7.1986e+02 -1.3827e+03  7e+02  1e-02  3e-16\n",
      " 2: -8.5751e+02 -8.8425e+02  3e+01  5e-04  4e-16\n",
      " 3: -8.7228e+02 -8.7255e+02  3e-01  5e-06  3e-16\n",
      " 4: -8.7243e+02 -8.7243e+02  3e-03  5e-08  4e-16\n",
      " 5: -8.7243e+02 -8.7243e+02  3e-05  5e-10  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.4991e+02 -2.7297e+03  7e+03  1e+00  6e-16\n",
      " 1: -7.3913e+02 -1.4087e+03  7e+02  1e-02  3e-16\n",
      " 2: -8.8050e+02 -9.0751e+02  3e+01  5e-04  4e-16\n",
      " 3: -8.9567e+02 -8.9595e+02  3e-01  5e-06  4e-16\n",
      " 4: -8.9583e+02 -8.9583e+02  3e-03  5e-08  2e-16\n",
      " 5: -8.9583e+02 -8.9583e+02  3e-05  5e-10  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.4674e+02 -2.7262e+03  7e+03  1e+00  6e-16\n",
      " 1: -7.3638e+02 -1.4050e+03  7e+02  1e-02  3e-16\n",
      " 2: -8.7722e+02 -9.0419e+02  3e+01  5e-04  5e-16\n",
      " 3: -8.9233e+02 -8.9260e+02  3e-01  5e-06  3e-16\n",
      " 4: -8.9248e+02 -8.9249e+02  3e-03  5e-08  4e-16\n",
      " 5: -8.9248e+02 -8.9248e+02  3e-05  5e-10  3e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:46:31,981]\u001b[0m Finished trial#1 with value: 0.501 with parameters: {'q': 1.9426943455671572e-05, 'sigma': 4.809976736266953, 'kernel': 10, 'lam': 3.260055780612738e-08, 'd': 6, 'c': 1.1142129241348206, 'degree': 2, 'n': 3}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.9426e+02 -3.0336e+03  7e+03  1e+00  4e-16\n",
      " 1: -8.0403e+02 -1.5083e+03  7e+02  1e-02  3e-16\n",
      " 2: -9.6542e+02 -9.9313e+02  3e+01  4e-04  3e-16\n",
      " 3: -9.8135e+02 -9.8163e+02  3e-01  4e-06  3e-16\n",
      " 4: -9.8151e+02 -9.8151e+02  3e-03  4e-08  3e-16\n",
      " 5: -9.8151e+02 -9.8151e+02  3e-05  4e-10  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.0090e+02 -3.0417e+03  7e+03  1e+00  4e-16\n",
      " 1: -8.0999e+02 -1.5164e+03  7e+02  1e-02  2e-16\n",
      " 2: -9.7259e+02 -1.0004e+03  3e+01  4e-04  4e-16\n",
      " 3: -9.8865e+02 -9.8892e+02  3e-01  4e-06  4e-16\n",
      " 4: -9.8881e+02 -9.8881e+02  3e-03  4e-08  3e-16\n",
      " 5: -9.8881e+02 -9.8881e+02  3e-05  4e-10  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.6766e+02 -3.0013e+03  7e+03  1e+00  4e-16\n",
      " 1: -7.8015e+02 -1.4757e+03  7e+02  1e-02  3e-16\n",
      " 2: -9.3672e+02 -9.6409e+02  3e+01  4e-04  5e-16\n",
      " 3: -9.5216e+02 -9.5244e+02  3e-01  4e-06  6e-16\n",
      " 4: -9.5232e+02 -9.5232e+02  3e-03  4e-08  3e-16\n",
      " 5: -9.5232e+02 -9.5232e+02  3e-05  4e-10  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.9093e+02 -3.0296e+03  7e+03  1e+00  4e-16\n",
      " 1: -8.0104e+02 -1.5042e+03  7e+02  1e-02  5e-16\n",
      " 2: -9.6183e+02 -9.8950e+02  3e+01  4e-04  3e-16\n",
      " 3: -9.7770e+02 -9.7798e+02  3e-01  4e-06  3e-16\n",
      " 4: -9.7786e+02 -9.7786e+02  3e-03  4e-08  3e-16\n",
      " 5: -9.7786e+02 -9.7786e+02  3e-05  4e-10  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.8761e+02 -3.0255e+03  7e+03  1e+00  4e-16\n",
      " 1: -7.9806e+02 -1.5001e+03  7e+02  1e-02  3e-16\n",
      " 2: -9.5825e+02 -9.8587e+02  3e+01  4e-04  4e-16\n",
      " 3: -9.7405e+02 -9.7433e+02  3e-01  4e-06  4e-16\n",
      " 4: -9.7421e+02 -9.7421e+02  3e-03  4e-08  4e-16\n",
      " 5: -9.7421e+02 -9.7421e+02  3e-05  4e-10  4e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:47:09,005]\u001b[0m Finished trial#2 with value: 0.501 with parameters: {'q': 0.01736946041319355, 'sigma': 5.0509382057867995, 'kernel': 5, 'lam': 1.7585519686136793e-12, 'd': 8, 'c': 1.2162456270043573, 'degree': 6, 'n': 3}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1734e+03 -5.2917e+03  1e+04  7e-01  5e-16\n",
      " 1: -1.2069e+03 -2.0999e+03  9e+02  7e-03  5e-16\n",
      " 2: -1.5261e+03 -1.5491e+03  2e+01  2e-04  5e-16\n",
      " 3: -1.5396e+03 -1.5399e+03  2e-01  2e-06  5e-16\n",
      " 4: -1.5398e+03 -1.5398e+03  2e-03  2e-08  4e-16\n",
      " 5: -1.5398e+03 -1.5398e+03  2e-05  2e-10  5e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1821e+03 -5.3084e+03  1e+04  7e-01  5e-16\n",
      " 1: -1.2159e+03 -2.1127e+03  9e+02  7e-03  4e-16\n",
      " 2: -1.5375e+03 -1.5605e+03  2e+01  2e-04  4e-16\n",
      " 3: -1.5511e+03 -1.5513e+03  2e-01  2e-06  5e-16\n",
      " 4: -1.5512e+03 -1.5512e+03  2e-03  2e-08  4e-16\n",
      " 5: -1.5512e+03 -1.5512e+03  2e-05  2e-10  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1385e+03 -5.2251e+03  1e+04  7e-01  5e-16\n",
      " 1: -1.1711e+03 -2.0488e+03  9e+02  7e-03  5e-16\n",
      " 2: -1.4808e+03 -1.5033e+03  2e+01  2e-04  4e-16\n",
      " 3: -1.4939e+03 -1.4941e+03  2e-01  2e-06  4e-16\n",
      " 4: -1.4940e+03 -1.4940e+03  2e-03  2e-08  5e-16\n",
      " 5: -1.4940e+03 -1.4940e+03  2e-05  2e-10  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1690e+03 -5.2834e+03  1e+04  7e-01  5e-16\n",
      " 1: -1.2024e+03 -2.0935e+03  9e+02  7e-03  6e-16\n",
      " 2: -1.5205e+03 -1.5434e+03  2e+01  2e-04  6e-16\n",
      " 3: -1.5339e+03 -1.5342e+03  2e-01  2e-06  4e-16\n",
      " 4: -1.5341e+03 -1.5341e+03  2e-03  2e-08  4e-16\n",
      " 5: -1.5341e+03 -1.5341e+03  2e-05  2e-10  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1647e+03 -5.2751e+03  1e+04  7e-01  5e-16\n",
      " 1: -1.1979e+03 -2.0871e+03  9e+02  7e-03  4e-16\n",
      " 2: -1.5148e+03 -1.5376e+03  2e+01  2e-04  4e-16\n",
      " 3: -1.5282e+03 -1.5284e+03  2e-01  2e-06  4e-16\n",
      " 4: -1.5283e+03 -1.5283e+03  2e-03  2e-08  3e-16\n",
      " 5: -1.5283e+03 -1.5283e+03  2e-05  2e-10  4e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:47:47,360]\u001b[0m Finished trial#3 with value: 0.501 with parameters: {'q': 2.114834193317894, 'sigma': 6.15293574729403, 'kernel': 2, 'lam': 3.441415152826428e-12, 'd': 3, 'c': 1.9080313510754066, 'degree': 3, 'n': 3}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6330e+03 -9.8508e+03  2e+04  5e-01  6e-16\n",
      " 1: -1.8157e+03 -2.9322e+03  1e+03  5e-03  6e-16\n",
      " 2: -2.4526e+03 -2.4885e+03  4e+01  1e-04  8e-16\n",
      " 3: -2.4589e+03 -2.4592e+03  4e-01  1e-06  6e-16\n",
      " 4: -2.4589e+03 -2.4589e+03  4e-03  1e-08  5e-16\n",
      " 5: -2.4589e+03 -2.4589e+03  4e-05  1e-10  7e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6451e+03 -9.8878e+03  2e+04  5e-01  6e-16\n",
      " 1: -1.8291e+03 -2.9516e+03  1e+03  5e-03  8e-16\n",
      " 2: -2.4708e+03 -2.5069e+03  4e+01  1e-04  7e-16\n",
      " 3: -2.4771e+03 -2.4775e+03  4e-01  1e-06  6e-16\n",
      " 4: -2.4772e+03 -2.4772e+03  4e-03  1e-08  6e-16\n",
      " 5: -2.4772e+03 -2.4772e+03  4e-05  1e-10  8e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.5844e+03 -9.7028e+03  2e+04  5e-01  7e-16\n",
      " 1: -1.7617e+03 -2.8545e+03  1e+03  5e-03  7e-16\n",
      " 2: -2.3797e+03 -2.4148e+03  4e+01  1e-04  6e-16\n",
      " 3: -2.3857e+03 -2.3861e+03  4e-01  1e-06  6e-16\n",
      " 4: -2.3858e+03 -2.3858e+03  4e-03  1e-08  7e-16\n",
      " 5: -2.3858e+03 -2.3858e+03  4e-05  1e-10  6e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6269e+03 -9.8323e+03  2e+04  5e-01  7e-16\n",
      " 1: -1.8089e+03 -2.9225e+03  1e+03  5e-03  5e-16\n",
      " 2: -2.4435e+03 -2.4793e+03  4e+01  1e-04  7e-16\n",
      " 3: -2.4497e+03 -2.4501e+03  4e-01  1e-06  6e-16\n",
      " 4: -2.4498e+03 -2.4498e+03  4e-03  1e-08  5e-16\n",
      " 5: -2.4498e+03 -2.4498e+03  4e-05  1e-10  6e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.6208e+03 -9.8138e+03  2e+04  5e-01  8e-16\n",
      " 1: -1.8022e+03 -2.9128e+03  1e+03  5e-03  8e-16\n",
      " 2: -2.4344e+03 -2.4700e+03  4e+01  1e-04  6e-16\n",
      " 3: -2.4406e+03 -2.4409e+03  4e-01  1e-06  9e-16\n",
      " 4: -2.4406e+03 -2.4406e+03  4e-03  1e-08  6e-16\n",
      " 5: -2.4406e+03 -2.4406e+03  4e-05  1e-10  6e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:54:37,529]\u001b[0m Finished trial#4 with value: 0.501 with parameters: {'q': 0.011173002776383363, 'sigma': 5.928493467960246, 'kernel': 7, 'lam': 1.416156449776579e-07, 'd': 4, 'c': 3.0469825342138903, 'degree': 5, 'n': 1}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.9592e+02 -3.0460e+03  7e+03  1e+00  7e-16\n",
      " 1: -8.0653e+02 -1.5121e+03  7e+02  1e-02  6e-16\n",
      " 2: -9.6873e+02 -9.9646e+02  3e+01  4e-04  3e-16\n",
      " 3: -9.8469e+02 -9.8497e+02  3e-01  4e-06  4e-16\n",
      " 4: -9.8485e+02 -9.8485e+02  3e-03  4e-08  3e-16\n",
      " 5: -9.8485e+02 -9.8485e+02  3e-05  4e-10  4e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.0259e+02 -3.0541e+03  7e+03  1e+00  8e-16\n",
      " 1: -8.1251e+02 -1.5203e+03  7e+02  1e-02  5e-16\n",
      " 2: -9.7593e+02 -1.0037e+03  3e+01  4e-04  4e-16\n",
      " 3: -9.9201e+02 -9.9229e+02  3e-01  4e-06  3e-16\n",
      " 4: -9.9217e+02 -9.9217e+02  3e-03  4e-08  3e-16\n",
      " 5: -9.9217e+02 -9.9217e+02  3e-05  4e-10  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.6928e+02 -3.0135e+03  7e+03  1e+00  7e-16\n",
      " 1: -7.8258e+02 -1.4794e+03  7e+02  1e-02  5e-16\n",
      " 2: -9.3994e+02 -9.6732e+02  3e+01  4e-04  4e-16\n",
      " 3: -9.5540e+02 -9.5568e+02  3e-01  4e-06  3e-16\n",
      " 4: -9.5556e+02 -9.5556e+02  3e-03  4e-08  5e-16\n",
      " 5: -9.5556e+02 -9.5556e+02  3e-05  4e-10  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.9259e+02 -3.0419e+03  7e+03  1e+00  7e-16\n",
      " 1: -8.0353e+02 -1.5080e+03  7e+02  1e-02  4e-16\n",
      " 2: -9.6513e+02 -9.9282e+02  3e+01  4e-04  4e-16\n",
      " 3: -9.8103e+02 -9.8130e+02  3e-01  4e-06  3e-16\n",
      " 4: -9.8119e+02 -9.8119e+02  3e-03  4e-08  3e-16\n",
      " 5: -9.8119e+02 -9.8119e+02  3e-05  4e-10  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -8.8926e+02 -3.0379e+03  7e+03  1e+00  7e-16\n",
      " 1: -8.0054e+02 -1.5039e+03  7e+02  1e-02  5e-16\n",
      " 2: -9.6154e+02 -9.8918e+02  3e+01  4e-04  4e-16\n",
      " 3: -9.7737e+02 -9.7764e+02  3e-01  4e-06  3e-16\n",
      " 4: -9.7752e+02 -9.7753e+02  3e-03  4e-08  4e-16\n",
      " 5: -9.7753e+02 -9.7753e+02  3e-05  4e-10  3e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:55:19,849]\u001b[0m Finished trial#5 with value: 0.501 with parameters: {'q': 0.016718534478240316, 'sigma': 7.514904028566807, 'kernel': 3, 'lam': 1.1652164303229493e-06, 'd': 2, 'c': 1.220381608531525, 'degree': 8, 'n': 2}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8598e+03 -1.0088e+05  1e+05  1e-01  2e-15\n",
      " 1: -6.4283e+03 -1.2278e+04  6e+03  5e-03  2e-15\n",
      " 2: -1.0869e+04 -1.1408e+04  6e+02  2e-04  2e-15\n",
      " 3: -1.0912e+04 -1.0918e+04  6e+00  2e-06  2e-15\n",
      " 4: -1.0913e+04 -1.0913e+04  6e-02  2e-08  2e-15\n",
      " 5: -1.0913e+04 -1.0913e+04  6e-04  2e-10  3e-15\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.9034e+03 -1.0146e+05  1e+05  1e-01  2e-15\n",
      " 1: -6.4761e+03 -1.2361e+04  6e+03  5e-03  2e-15\n",
      " 2: -1.0950e+04 -1.1493e+04  6e+02  2e-04  2e-15\n",
      " 3: -1.0993e+04 -1.0999e+04  6e+00  2e-06  2e-15\n",
      " 4: -1.0994e+04 -1.0994e+04  6e-02  2e-08  3e-15\n",
      " 5: -1.0994e+04 -1.0994e+04  6e-04  2e-10  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.6856e+03 -9.8519e+04  1e+05  1e-01  2e-15\n",
      " 1: -6.2371e+03 -1.1947e+04  6e+03  5e-03  2e-15\n",
      " 2: -1.0546e+04 -1.1072e+04  6e+02  2e-04  3e-15\n",
      " 3: -1.0588e+04 -1.0593e+04  6e+00  2e-06  2e-15\n",
      " 4: -1.0588e+04 -1.0588e+04  6e-02  2e-08  3e-15\n",
      " 5: -1.0588e+04 -1.0588e+04  6e-04  2e-10  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8380e+03 -1.0058e+05  1e+05  1e-01  2e-15\n",
      " 1: -6.4044e+03 -1.2237e+04  6e+03  5e-03  1e-15\n",
      " 2: -1.0829e+04 -1.1366e+04  6e+02  2e-04  3e-15\n",
      " 3: -1.0872e+04 -1.0877e+04  6e+00  2e-06  3e-15\n",
      " 4: -1.0872e+04 -1.0872e+04  6e-02  2e-08  3e-15\n",
      " 5: -1.0872e+04 -1.0872e+04  6e-04  2e-10  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8163e+03 -1.0029e+05  1e+05  1e-01  2e-15\n",
      " 1: -6.3805e+03 -1.2195e+04  6e+03  5e-03  3e-15\n",
      " 2: -1.0789e+04 -1.1324e+04  6e+02  2e-04  3e-15\n",
      " 3: -1.0831e+04 -1.0836e+04  6e+00  2e-06  2e-15\n",
      " 4: -1.0832e+04 -1.0832e+04  6e-02  2e-08  3e-15\n",
      " 5: -1.0832e+04 -1.0832e+04  6e-04  2e-10  3e-15\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:56:04,018]\u001b[0m Finished trial#6 with value: 0.501 with parameters: {'q': 1.8896534387017767, 'sigma': 6.821190051908898, 'kernel': 3, 'lam': 9.570977272238608e-06, 'd': 6, 'c': 13.522504648437053, 'degree': 10, 'n': 3}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.9615e+02 -3.8131e+03  8e+03  1e+00  3e-16\n",
      " 1: -9.5464e+02 -1.7348e+03  8e+02  1e-02  5e-16\n",
      " 2: -1.1685e+03 -1.1965e+03  3e+01  3e-04  3e-16\n",
      " 3: -1.1851e+03 -1.1854e+03  3e-01  3e-06  4e-16\n",
      " 4: -1.1853e+03 -1.1853e+03  3e-03  3e-08  3e-16\n",
      " 5: -1.1853e+03 -1.1853e+03  3e-05  3e-10  4e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0036e+03 -3.8240e+03  8e+03  1e+00  3e-16\n",
      " 1: -9.6173e+02 -1.7447e+03  8e+02  1e-02  4e-16\n",
      " 2: -1.1772e+03 -1.2052e+03  3e+01  3e-04  3e-16\n",
      " 3: -1.1939e+03 -1.1942e+03  3e-01  3e-06  3e-16\n",
      " 4: -1.1941e+03 -1.1941e+03  3e-03  3e-08  3e-16\n",
      " 5: -1.1941e+03 -1.1941e+03  3e-05  3e-10  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.6652e+02 -3.7696e+03  8e+03  1e+00  3e-16\n",
      " 1: -9.2630e+02 -1.6952e+03  8e+02  1e-02  5e-16\n",
      " 2: -1.1337e+03 -1.1613e+03  3e+01  3e-04  3e-16\n",
      " 3: -1.1499e+03 -1.1502e+03  3e-01  3e-06  4e-16\n",
      " 4: -1.1500e+03 -1.1500e+03  3e-03  3e-08  4e-16\n",
      " 5: -1.1500e+03 -1.1500e+03  3e-05  3e-10  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.9244e+02 -3.8077e+03  8e+03  1e+00  3e-16\n",
      " 1: -9.5110e+02 -1.7299e+03  8e+02  1e-02  4e-16\n",
      " 2: -1.1641e+03 -1.1921e+03  3e+01  3e-04  3e-16\n",
      " 3: -1.1807e+03 -1.1810e+03  3e-01  3e-06  5e-16\n",
      " 4: -1.1809e+03 -1.1809e+03  3e-03  3e-08  3e-16\n",
      " 5: -1.1809e+03 -1.1809e+03  3e-05  3e-10  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.8874e+02 -3.8023e+03  8e+03  1e+00  3e-16\n",
      " 1: -9.4756e+02 -1.7249e+03  8e+02  1e-02  7e-16\n",
      " 2: -1.1598e+03 -1.1877e+03  3e+01  3e-04  4e-16\n",
      " 3: -1.1763e+03 -1.1766e+03  3e-01  3e-06  4e-16\n",
      " 4: -1.1765e+03 -1.1765e+03  3e-03  3e-08  3e-16\n",
      " 5: -1.1765e+03 -1.1765e+03  3e-05  3e-10  4e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:56:40,200]\u001b[0m Finished trial#7 with value: 0.501 with parameters: {'q': 0.0002344474770176594, 'sigma': 6.625885878725239, 'kernel': 0, 'lam': 8.203135981397247e-07, 'd': 3, 'c': 1.468766072031067, 'degree': 6, 'n': 2}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4416e+03 -7.8249e+03  1e+04  5e-01  1e-15\n",
      " 1: -1.5689e+03 -2.6013e+03  1e+03  5e-03  6e-16\n",
      " 2: -2.0711e+03 -2.0921e+03  2e+01  8e-05  5e-16\n",
      " 3: -2.0761e+03 -2.0763e+03  2e-01  8e-07  5e-16\n",
      " 4: -2.0761e+03 -2.0761e+03  2e-03  8e-09  5e-16\n",
      " 5: -2.0761e+03 -2.0761e+03  2e-05  8e-11  6e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4523e+03 -7.8525e+03  1e+04  5e-01  9e-16\n",
      " 1: -1.5806e+03 -2.6181e+03  1e+03  5e-03  7e-16\n",
      " 2: -2.0865e+03 -2.1076e+03  2e+01  8e-05  5e-16\n",
      " 3: -2.0915e+03 -2.0917e+03  2e-01  8e-07  5e-16\n",
      " 4: -2.0916e+03 -2.0916e+03  2e-03  8e-09  5e-16\n",
      " 5: -2.0916e+03 -2.0916e+03  2e-05  8e-11  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3987e+03 -7.7146e+03  1e+04  5e-01  1e-15\n",
      " 1: -1.5223e+03 -2.5342e+03  1e+03  5e-03  6e-16\n",
      " 2: -2.0095e+03 -2.0302e+03  2e+01  8e-05  6e-16\n",
      " 3: -2.0143e+03 -2.0145e+03  2e-01  8e-07  5e-16\n",
      " 4: -2.0144e+03 -2.0144e+03  2e-03  8e-09  5e-16\n",
      " 5: -2.0144e+03 -2.0144e+03  2e-05  8e-11  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4362e+03 -7.8111e+03  1e+04  5e-01  1e-15\n",
      " 1: -1.5631e+03 -2.5929e+03  1e+03  5e-03  5e-16\n",
      " 2: -2.0634e+03 -2.0844e+03  2e+01  8e-05  5e-16\n",
      " 3: -2.0684e+03 -2.0686e+03  2e-01  8e-07  6e-16\n",
      " 4: -2.0684e+03 -2.0684e+03  2e-03  8e-09  4e-16\n",
      " 5: -2.0684e+03 -2.0684e+03  2e-05  8e-11  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4308e+03 -7.7973e+03  1e+04  5e-01  1e-15\n",
      " 1: -1.5573e+03 -2.5845e+03  1e+03  5e-03  6e-16\n",
      " 2: -2.0557e+03 -2.0766e+03  2e+01  8e-05  5e-16\n",
      " 3: -2.0606e+03 -2.0609e+03  2e-01  8e-07  5e-16\n",
      " 4: -2.0607e+03 -2.0607e+03  2e-03  8e-09  5e-16\n",
      " 5: -2.0607e+03 -2.0607e+03  2e-05  8e-11  5e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:57:17,184]\u001b[0m Finished trial#8 with value: 0.501 with parameters: {'q': 0.013874152052236306, 'sigma': 3.2940874639605595, 'kernel': 3, 'lam': 6.640143436864129e-13, 'd': 2, 'c': 2.572656426323438, 'degree': 7, 'n': 2}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0572e+03 -1.4989e+04  2e+04  3e-01  8e-16\n",
      " 1: -2.3370e+03 -3.6119e+03  1e+03  3e-03  8e-16\n",
      " 2: -3.2978e+03 -3.3469e+03  5e+01  8e-05  1e-15\n",
      " 3: -3.3073e+03 -3.3078e+03  5e-01  8e-07  6e-16\n",
      " 4: -3.3074e+03 -3.3074e+03  5e-03  8e-09  7e-16\n",
      " 5: -3.3074e+03 -3.3074e+03  5e-05  8e-11  6e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0725e+03 -1.5051e+04  2e+04  3e-01  9e-16\n",
      " 1: -2.3544e+03 -3.6367e+03  1e+03  3e-03  8e-16\n",
      " 2: -3.3223e+03 -3.3717e+03  5e+01  8e-05  1e-15\n",
      " 3: -3.3319e+03 -3.3324e+03  5e-01  8e-07  9e-16\n",
      " 4: -3.3320e+03 -3.3320e+03  5e-03  8e-09  4e-16\n",
      " 5: -3.3320e+03 -3.3320e+03  5e-05  8e-11  7e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.9960e+03 -1.4738e+04  2e+04  3e-01  9e-16\n",
      " 1: -2.2675e+03 -3.5128e+03  1e+03  3e-03  1e-15\n",
      " 2: -3.1997e+03 -3.2474e+03  5e+01  8e-05  8e-16\n",
      " 3: -3.2089e+03 -3.2094e+03  5e-01  8e-07  7e-16\n",
      " 4: -3.2090e+03 -3.2090e+03  5e-03  8e-09  6e-16\n",
      " 5: -3.2090e+03 -3.2090e+03  5e-05  8e-11  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0495e+03 -1.4957e+04  2e+04  3e-01  8e-16\n",
      " 1: -2.3283e+03 -3.5995e+03  1e+03  3e-03  9e-16\n",
      " 2: -3.2855e+03 -3.3344e+03  5e+01  8e-05  9e-16\n",
      " 3: -3.2950e+03 -3.2955e+03  5e-01  8e-07  8e-16\n",
      " 4: -3.2951e+03 -3.2951e+03  5e-03  8e-09  6e-16\n",
      " 5: -3.2951e+03 -3.2951e+03  5e-05  8e-11  9e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0419e+03 -1.4926e+04  2e+04  3e-01  9e-16\n",
      " 1: -2.3196e+03 -3.5871e+03  1e+03  3e-03  9e-16\n",
      " 2: -3.2733e+03 -3.3220e+03  5e+01  8e-05  1e-15\n",
      " 3: -3.2827e+03 -3.2832e+03  5e-01  8e-07  1e-15\n",
      " 4: -3.2828e+03 -3.2828e+03  5e-03  8e-09  1e-15\n",
      " 5: -3.2828e+03 -3.2828e+03  5e-05  8e-11  7e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:57:54,527]\u001b[0m Finished trial#9 with value: 0.501 with parameters: {'q': 0.00016931716414205072, 'sigma': 6.542749187193906, 'kernel': 1, 'lam': 3.3254107760031857e-10, 'd': 4, 'c': 4.098370117812993, 'degree': 8, 'n': 2}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2856e+03 -5.6626e+04  7e+04  1e-01  1e-15\n",
      " 1: -4.7863e+03 -8.6300e+03  4e+03  7e-03  2e-15\n",
      " 2: -7.7355e+03 -8.0201e+03  3e+02  3e-04  1e-15\n",
      " 3: -7.7640e+03 -7.7668e+03  3e+00  3e-06  2e-15\n",
      " 4: -7.7643e+03 -7.7643e+03  3e-02  3e-08  2e-15\n",
      " 5: -7.7643e+03 -7.7643e+03  3e-04  3e-10  1e-15\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3175e+03 -5.6933e+04  7e+04  1e-01  1e-15\n",
      " 1: -4.8219e+03 -8.6875e+03  4e+03  7e-03  2e-15\n",
      " 2: -7.7930e+03 -8.0794e+03  3e+02  3e-04  1e-15\n",
      " 3: -7.8217e+03 -7.8246e+03  3e+00  3e-06  2e-15\n",
      " 4: -7.8220e+03 -7.8220e+03  3e-02  3e-08  1e-15\n",
      " 5: -7.8220e+03 -7.8220e+03  3e-04  3e-10  2e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1582e+03 -5.5400e+04  7e+04  1e-01  1e-15\n",
      " 1: -4.6440e+03 -8.3998e+03  4e+03  7e-03  2e-15\n",
      " 2: -7.5055e+03 -7.7833e+03  3e+02  3e-04  2e-15\n",
      " 3: -7.5331e+03 -7.5359e+03  3e+00  3e-06  1e-15\n",
      " 4: -7.5333e+03 -7.5334e+03  3e-02  3e-08  2e-15\n",
      " 5: -7.5333e+03 -7.5333e+03  3e-04  3e-10  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2697e+03 -5.6473e+04  7e+04  1e-01  1e-15\n",
      " 1: -4.7685e+03 -8.6012e+03  4e+03  7e-03  1e-15\n",
      " 2: -7.7068e+03 -7.9905e+03  3e+02  3e-04  2e-15\n",
      " 3: -7.7351e+03 -7.7379e+03  3e+00  3e-06  1e-15\n",
      " 4: -7.7354e+03 -7.7354e+03  3e-02  3e-08  1e-15\n",
      " 5: -7.7354e+03 -7.7354e+03  3e-04  3e-10  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2538e+03 -5.6320e+04  7e+04  1e-01  1e-15\n",
      " 1: -4.7507e+03 -8.5725e+03  4e+03  7e-03  1e-15\n",
      " 2: -7.6780e+03 -7.9609e+03  3e+02  3e-04  2e-15\n",
      " 3: -7.7062e+03 -7.7091e+03  3e+00  3e-06  2e-15\n",
      " 4: -7.7065e+03 -7.7066e+03  3e-02  3e-08  1e-15\n",
      " 5: -7.7065e+03 -7.7065e+03  3e-04  3e-10  2e-15\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:58:29,907]\u001b[0m Finished trial#10 with value: 0.501 with parameters: {'q': 0.00046944229759419525, 'sigma': 3.4742272388941418, 'kernel': 1, 'lam': 1.3597058160730362e-09, 'd': 8, 'c': 9.621133364194023, 'degree': 4, 'n': 1}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.1049e+03 -3.1499e+04  4e+04  2e-01  2e-15\n",
      " 1: -3.5203e+03 -5.9359e+03  3e+03  9e-03  1e-15\n",
      " 2: -5.3845e+03 -5.5174e+03  1e+02  2e-04  1e-15\n",
      " 3: -5.4026e+03 -5.4039e+03  1e+00  2e-06  1e-15\n",
      " 4: -5.4028e+03 -5.4028e+03  1e-02  2e-08  1e-15\n",
      " 5: -5.4028e+03 -5.4028e+03  1e-04  2e-10  9e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.1280e+03 -3.1653e+04  4e+04  2e-01  2e-15\n",
      " 1: -3.5464e+03 -5.9753e+03  3e+03  9e-03  1e-15\n",
      " 2: -5.4245e+03 -5.5582e+03  1e+02  2e-04  1e-15\n",
      " 3: -5.4427e+03 -5.4441e+03  1e+00  2e-06  1e-15\n",
      " 4: -5.4429e+03 -5.4429e+03  1e-02  2e-08  1e-15\n",
      " 5: -5.4429e+03 -5.4429e+03  1e-04  2e-10  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.0125e+03 -3.0880e+04  4e+04  2e-01  2e-15\n",
      " 1: -3.4156e+03 -5.7783e+03  3e+03  9e-03  1e-15\n",
      " 2: -5.2243e+03 -5.3542e+03  1e+02  2e-04  1e-15\n",
      " 3: -5.2419e+03 -5.2432e+03  1e+00  2e-06  1e-15\n",
      " 4: -5.2421e+03 -5.2421e+03  1e-02  2e-08  9e-16\n",
      " 5: -5.2421e+03 -5.2421e+03  1e-04  2e-10  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.0933e+03 -3.1421e+04  4e+04  2e-01  2e-15\n",
      " 1: -3.5072e+03 -5.9162e+03  3e+03  9e-03  1e-15\n",
      " 2: -5.3645e+03 -5.4970e+03  1e+02  2e-04  1e-15\n",
      " 3: -5.3825e+03 -5.3838e+03  1e+00  2e-06  1e-15\n",
      " 4: -5.3827e+03 -5.3827e+03  1e-02  2e-08  1e-15\n",
      " 5: -5.3827e+03 -5.3827e+03  1e-04  2e-10  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.0818e+03 -3.1344e+04  4e+04  2e-01  2e-15\n",
      " 1: -3.4941e+03 -5.8965e+03  3e+03  9e-03  1e-15\n",
      " 2: -5.3444e+03 -5.4766e+03  1e+02  2e-04  1e-15\n",
      " 3: -5.3624e+03 -5.3637e+03  1e+00  2e-06  1e-15\n",
      " 4: -5.3626e+03 -5.3626e+03  1e-02  2e-08  1e-15\n",
      " 5: -5.3626e+03 -5.3626e+03  1e-04  2e-10  1e-15\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-31 19:59:10,838]\u001b[0m Finished trial#11 with value: 0.501 with parameters: {'q': 1.1639625742684502e-05, 'sigma': 4.114468425365752, 'kernel': 10, 'lam': 8.513254445662254e-05, 'd': 6, 'c': 6.694871855890823, 'degree': 2, 'n': 3}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.9406e+03 -2.8550e+04  4e+04  2e-01  4e-17\n",
      " 1: -3.3399e+03 -5.5624e+03  2e+03  9e-03  6e-16\n",
      " 2: -5.0573e+03 -5.1729e+03  1e+02  2e-04  1e-15\n",
      " 3: -5.0740e+03 -5.0751e+03  1e+00  2e-06  1e-15\n",
      " 4: -5.0741e+03 -5.0742e+03  1e-02  2e-08  9e-16\n",
      " 5: -5.0741e+03 -5.0741e+03  1e-04  2e-10  2e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-440503788d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective_sgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 334\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                 )\n\u001b[1;32m    336\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    646\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             message = \"Setting status of trial#{} as {}. {}\".format(\n",
      "\u001b[0;32m<ipython-input-29-440503788d7a>\u001b[0m in \u001b[0;36mobjective_sgd\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mmodel_curr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mmodel_curr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-0a28e79d2a80>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Solve dual problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/Kernel_kaggle/kernels/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data_1, data_2)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/root/Kernel_kaggle/kernels/regular.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, data_1, data_2)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mcolumn_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                       \u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcolumn_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47min 32s\n"
     ]
    }
   ],
   "source": [
    "# from kernels.basic import RBF, Linear, Polynomial\n",
    "# from kernels.regular import Exponential, Laplacian, RationalQuadratic, \\\n",
    "#                             InverseMultiquadratic, Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen\n",
    "\n",
    "def objective_sgd(trial):\n",
    "    \n",
    "    q  = trial.suggest_loguniform('q', 1e-5, 4e+0)\n",
    "    \n",
    "    sigma  = trial.suggest_loguniform('sigma', 3e-0, 8e+0) # trial.suggest_float('sigma', 1e-5, 1e-3, log=True)\n",
    "    \n",
    "    kernel = trial.suggest_categorical('kernel', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])#[Exponential, Laplacian, RationalQuadratic, InverseMultiquadratic, \\\n",
    "                                               #Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen])\n",
    "    \n",
    "    lam = trial.suggest_loguniform('lam', 1e-15, 1e-4)\n",
    "    \n",
    "    d = trial.suggest_int('d', 2, 8)\n",
    "    c = trial.suggest_loguniform('c', 1, 20)\n",
    "    \n",
    "    degree = trial.suggest_int('degree', 2, 10)\n",
    "    \n",
    "    # trick to avoid warnning from opma that support only basic datatype\n",
    "    trick_list = [rbf_kernel, Exponential, Laplacian, RationalQuadratic, InverseMultiquadratic, \\\n",
    "                        Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen]\n",
    "    \n",
    "    tol = 1e-7 # trial.suggest_loguniform('tol', 1e-7, 1e-0)\n",
    "    \n",
    "    n = trial.suggest_int('n', 1, 3)\n",
    "    \n",
    "#     tol = trial.suggest_loguniform('tol', 1e-7, 1e-0)\n",
    "\n",
    "#     sigma=10, d=2, rbf=1.0, poly=1.0\n",
    "    \n",
    "#     lr  = trial.suggest_loguniform('lr', 2e-5, 1e-1)\n",
    "    \n",
    "#     normalise = trial.suggest_categorical('normalise', [False , True])\n",
    "    \n",
    "#     rbf = trial.suggest_loguniform('rbf', 1e-3, 3e+0)\n",
    "    \n",
    "#     poly = trial.suggest_loguniform('poly', 1e-3, 3e+0)\n",
    "    \n",
    "    \n",
    "#     model = trial.suggest_categorical('models', [ksolveRR , ksolveRR_2, ksolveLRR, KernelSVM])\n",
    "    \n",
    "    # ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "    # ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "    # ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "    # KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "    \n",
    "#     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "#               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM', LogisticRegressionBinary: 'log reg'} \n",
    "#     \n",
    "    kernels = {rbf_kernel : 'rbf',\n",
    "               Exponential : 'Exponential kernel (self, sigma=None)',\n",
    "               Laplacian : 'Laplacian kernel (self, sigma=None)',\n",
    "               Cauchy : 'Cauchy kernel (self, sigma=None)',\n",
    "               \n",
    "               RationalQuadratic : 'Rational quadratic kernel (self, c=1)',\n",
    "               InverseMultiquadratic : 'Inverse multiquadratic kernel (self, c=1)',\n",
    "               \n",
    "               TStudent : 'T-Student kernel (self, degree=2)',\n",
    "               \n",
    "               ANOVA : 'ANOVA kernel (self, sigma=1., d=2)',\n",
    "               \n",
    "               Fourier : 'Fourier kernel (self, q=0.1)',\n",
    "               \n",
    "               Tanimoto : 'Tanimoto kernel',\n",
    "               Sorensen : 'Sorensen kernel'\n",
    "              }\n",
    "    \n",
    "    if kernels[trick_list[kernel]] == 'ANOVA kernel (self, sigma=sigma, d=d)':\n",
    "        kernel = trick_list[kernel](sigma=sigma, d=d)\n",
    "        \n",
    "    elif kernels[trick_list[kernel]] == 'Exponential kernel (self, sigma=None)' or \\\n",
    "                        kernels[trick_list[kernel]] == 'Laplacian kernel (self, sigma=None)' or \\\n",
    "                        kernels[trick_list[kernel]] == 'Cauchy kernel (self, sigma=None)'or \\\n",
    "                        kernels[trick_list[kernel]] == 'rbf':\n",
    "        \n",
    "        kernel = trick_list[kernel](sigma=sigma)\n",
    "        \n",
    "    elif kernels[trick_list[kernel]] == 'Rational quadratic kernel (self, c=1)' or \\\n",
    "                        kernels[trick_list[kernel]] == 'Inverse multiquadratic kernel (self, c=1)':\n",
    "        kernel = trick_list[kernel](c=c)\n",
    "        \n",
    "    elif kernels[trick_list[kernel]] == 'T-Student kernel (self, degree=2)':\n",
    "        kernel = trick_list[kernel](degree=degree)\n",
    "        \n",
    "    elif kernels[trick_list[kernel]] == 'Fourier kernel (self, q=0.1)':\n",
    "        kernel = trick_list[kernel](q=q)\n",
    "        \n",
    "    else:\n",
    "        kernel = trick_list[kernel]()\n",
    "        \n",
    "    \n",
    "#     n = 1\n",
    "    \n",
    "    models = {KernelSVM : 'Kernal SVM'}\n",
    "    \n",
    "\n",
    "    X_cross, y_cross, X_t_enc = spectrum_kernal(X_train_, Y_train_, X_test_, n=n, encoder=8, one_hot = True, normalise = False)\n",
    "    \n",
    "    for model in models:\n",
    "        accuracy = []\n",
    "        for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "            X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "            X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "\n",
    "    #             ipdb.set_trace()\n",
    "            if models[model] == 'weigh Ridge Reg':\n",
    "                sample_weights = np.random.rand(len(y_train))\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kernel)\n",
    "\n",
    "            elif models[model] == 'k Logistic Ridge Reg':\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kernel)\n",
    "            elif models[model] == 'k Ridge Reg':\n",
    "#                 model_curr = model(X_train, y_train, lam= lam, sigma = sigma, d=d, rbf=rbf, poly=poly, kernel=kernel)\n",
    "                \n",
    "                model_curr = model(X_train, y_train, lam= lam, kernel=kernel)\n",
    "            elif models[model] == 'log reg':\n",
    "                model_curr = model(lr=lr, num_iter=5000, batch_size=1)\n",
    "            else:\n",
    "                model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kernel)\n",
    "                \n",
    "            if models[model] == 'log reg':\n",
    "                model_curr.fit(X_train, y_train)\n",
    "            else:\n",
    "                model_curr.fit()\n",
    "            \n",
    "\n",
    "            accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "                \n",
    "    #       print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "\n",
    "    #         print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')\n",
    "\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective_sgd, n_trials=1500, show_progress_bar=True)\n",
    "\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.9 ms\n"
     ]
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: 0.7025 (overfitting on accuracy 4)\n",
    "# Best hyperparameters: {'sigma': 4.133127895830191, 'lam': 6.196055115305764e-14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented data\n",
    "\n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-20, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-20, 1e-1)\n",
    "\n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Augmented data)\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: 0.6555\n",
    "    # Best hyperparameters: {'sigma': 4.065620491225982, 'lam': 0.013374107290659768}\n",
    "    # time: 49min 21s\n",
    "    #----\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.6575 # 0.6575000000000001\n",
    "    # Best hyperparameters: {'sigma': 4.119788517147901, 'lam': 1.2752298700618223e-14}, {'sigma': 4.063158315715049, 'lam': 8.30834772639223e-05}\n",
    "    # time: 32min 57s\n",
    "    \n",
    "    # ------\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.6595000000000001\n",
    "    # Best hyperparameters: {'sigma': 4.1032895001889464, 'lam': 0.00014526367793975609}\n",
    "    # time: --\n",
    "\n",
    "    \n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-3, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "\n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Non-Augmented data)\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: 0.6555\n",
    "    # Best hyperparameters: {'sigma': 4.069738272304652, 'lam': 0.053817561640154984}\n",
    "    # time: 48min 12s\n",
    "    #----\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.6575000000000001\n",
    "    # Best hyperparameters: {'sigma': 4.001185698777986, 'lam': 1.9770379950513775e-10}\n",
    "    # time: 29min 58s\n",
    "    \n",
    "\n",
    "# Accuracy: 0.6605000000000001\n",
    "# Best hyperparameters: {'sigma': 4.538118805230398, 'lam': 8.583924705371449e-15}\n",
    "# time: 1.32 ms\n",
    "\n",
    "# Original data\n",
    "\n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-3, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "  \n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Non-Augmented data standardize)\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.612\n",
    "    # Best hyperparameters: {'sigma': 2.8925324917718167, 'lam': 1.2575244169567934e-08}\n",
    "    # time: 28min 33s \n",
    "    #----\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: EROOR LinearAlg\n",
    "    # Best hyperparameters: \n",
    "    # time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'sigma': 4.119788517147901, 'lam': 1.2752298700618223e-14}    # time: 32min 57s BEST(69.4)\n",
    "# ksolveRR_65_cv_0.00000000001_4.csv Second (69.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sigma': 4.001616944273439, 'lam': 4.873253388094652e-09}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.78 ms\n"
     ]
    }
   ],
   "source": [
    "trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy fold 0: 0.5975\n",
      "accurracy fold 1: 0.6625\n",
      "accurracy fold 2: 0.68\n",
      "accurracy fold 3: 0.6475\n",
      "accurracy fold 4: 0.7\n",
      "\n",
      "Average accuracy k Ridge Reg is : 0.6575\n",
      "\n",
      "time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "#     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "#               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM'\n",
    "\n",
    "# c  = \n",
    "\n",
    "# trial.params\n",
    "sigma  = 4.119788517147901 #trial.params['sigma'] #4.133127895830191 #4#4.119788517147901 #4.538118805230398\n",
    "kenel = 0\n",
    "lam = 1.2752298700618223e-14 #trial.params['lam'] #6.196055115305764e-14#0.00000000001#1.2752298700618223e-14#8.583924705371449e-15 8.583924705371449e-15 #\n",
    "# tol = \n",
    "    \n",
    "#     ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "#     ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "#     ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "#     KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "\n",
    "trick_list = [rbf_kernel, Exponential, Laplacian, RationalQuadratic, InverseMultiquadratic, \\\n",
    "                        Cauchy, TStudent, ANOVA, Fourier, Tanimoto, Sorensen]\n",
    "    \n",
    "#     tol = trial.suggest_loguniform('tol', 1e-7, 1e-0)\n",
    "\n",
    "#     sigma=10, d=2, rbf=1.0, poly=1.0\n",
    "    \n",
    "#     lr  = trial.suggest_loguniform('lr', 2e-5, 1e-1)\n",
    "    \n",
    "#     normalise = trial.suggest_categorical('normalise', [False , True])\n",
    "    \n",
    "#     rbf = trial.suggest_loguniform('rbf', 1e-3, 3e+0)\n",
    "    \n",
    "#     poly = trial.suggest_loguniform('poly', 1e-3, 3e+0)\n",
    "    \n",
    "    \n",
    "#     model = trial.suggest_categorical('models', [ksolveRR , ksolveRR_2, ksolveLRR, KernelSVM])\n",
    "    \n",
    "    # ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "    # ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "    # ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "    # KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "    \n",
    "#     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "#               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM', LogisticRegressionBinary: 'log reg'} \n",
    "#     \n",
    "kernels = {rbf_kernel : 'rbf',\n",
    "               Exponential : 'Exponential kernel (self, sigma=None)',\n",
    "               Laplacian : 'Laplacian kernel (self, sigma=None)',\n",
    "               Cauchy : 'Cauchy kernel (self, sigma=None)',\n",
    "               \n",
    "               RationalQuadratic : 'Rational quadratic kernel (self, c=1)',\n",
    "               InverseMultiquadratic : 'Inverse multiquadratic kernel (self, c=1)',\n",
    "               \n",
    "               TStudent : 'T-Student kernel (self, degree=2)',\n",
    "               \n",
    "               ANOVA : 'ANOVA kernel (self, sigma=1., d=2)',\n",
    "               \n",
    "               Fourier : 'Fourier kernel (self, q=0.1)',\n",
    "               \n",
    "               Tanimoto : 'Tanimoto kernel',\n",
    "               Sorensen : 'Sorensen kernel'\n",
    "              }\n",
    "\n",
    "if kernels[trick_list[kenel]] == 'ANOVA kernel (self, sigma=sigma, d=d)':\n",
    "        kenel = trick_list[kenel](sigma=sigma, d=d)\n",
    "        \n",
    "elif kernels[trick_list[kenel]] == 'Exponential kernel (self, sigma=None)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Laplacian kernel (self, sigma=None)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Cauchy kernel (self, sigma=None)'or \\\n",
    "                    kernels[trick_list[kenel]] == 'rbf':\n",
    "\n",
    "    kenel = trick_list[kenel](sigma=sigma)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'Rational quadratic kernel (self, c=1)' or \\\n",
    "                    kernels[trick_list[kenel]] == 'Inverse multiquadratic kernel (self, c=1)':\n",
    "    kenel = trick_list[kenel](c=c)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'T-Student kernel (self, degree=2)':\n",
    "    kenel = trick_list[kenel](degree=degree)\n",
    "\n",
    "elif kernels[trick_list[kenel]] == 'Fourier kernel (self, q=0.1)':\n",
    "    kenel = trick_list[kenel](q=q)\n",
    "\n",
    "else:\n",
    "    kenel = trick_list[kenel]()\n",
    "\n",
    "\n",
    "n = 1\n",
    "\n",
    "models = {KernelSVM : 'Kernal SVM'} \n",
    "\n",
    "#     accuracy = []\n",
    "#     for model in models:\n",
    "#     ipdb.set_trace()\n",
    "\n",
    "\n",
    "X_cross, y_cross, X_t_enc = spectrum_kernal(X_train_, Y_train_, X_test_, n=n, encoder=8, one_hot = True, normalise = False)\n",
    "\n",
    "for model in models:\n",
    "    accuracy = []\n",
    "    for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "        X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "        X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "\n",
    "#             ipdb.set_trace()\n",
    "        if models[model] == 'weigh Ridge Reg':\n",
    "            sample_weights = np.random.rand(len(y_train))\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "\n",
    "        elif models[model] == 'k Logistic Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kenel)\n",
    "        elif models[model] == 'k Ridge Reg':\n",
    "#                 model_curr = model(X_train, y_train, lam= lam, sigma = sigma, d=d, rbf=rbf, poly=poly, kernel=rbf_kernel)\n",
    "\n",
    "            model_curr = model(X_train, y_train, lam= lam, kernel=kenel)\n",
    "        elif models[model] == 'log reg':\n",
    "            model_curr = model(lr=lr, num_iter=5000, batch_size=1)\n",
    "        else:\n",
    "            model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kenel)\n",
    "\n",
    "        if models[model] == 'log reg':\n",
    "            model_curr.fit(X_train, y_train)\n",
    "        else:\n",
    "            model_curr.fit()\n",
    "\n",
    "\n",
    "        accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "        print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "\n",
    "print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 525 µs\n"
     ]
    }
   ],
   "source": [
    "# 0.6535 = 0.68800\n",
    "# 0.657 = 0.69200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 544 ms\n"
     ]
    }
   ],
   "source": [
    "# Cehckinf full model\n",
    "model = ksolveRR(X_cross, y_cross, lam = lam, sigma = sigma, kernel = kenel)\n",
    "# model = svm_primal_soft_to_qp(X_cross, y_cross, C=1)\n",
    "\n",
    "model.fit()\n",
    "\n",
    "model.Accuracy_check(X_cross, y_cross, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 443 ms\n"
     ]
    }
   ],
   "source": [
    "model = ksolveRR(X_cross, y_cross, lam = lam, sigma = sigma, kernel = kenel)\n",
    "model.fit()\n",
    "y_pred = model.predict(X_t_enc, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id\n",
       "0   0\n",
       "1   1\n",
       "2   2\n",
       "3   3\n",
       "4   4"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.91 ms\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1000).reshape(-1, 1)\n",
    "sample = pd.DataFrame(data=X, columns=['Id'])\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.85 ms\n"
     ]
    }
   ],
   "source": [
    "sample['Bound'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Bound\n",
       "995  995      0\n",
       "996  996      0\n",
       "997  997      1\n",
       "998  998      1\n",
       "999  999      1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.87 ms\n"
     ]
    }
   ],
   "source": [
    "sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "sample.to_csv('./ksolveRR_0.6625000000000001_cv_rbf_kernel_sigma_'+str(sigma)+'_lam_'+str(lam)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
