{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipdb in /usr/local/lib/python3.6/dist-packages (0.13.2)\n",
      "Requirement already satisfied: ipython>=5.1.0; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (46.4.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.0.18)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.7.5)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.8.1)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (2.1.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.3.3)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.1.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.12.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.2.0)\n",
      "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.6/dist-packages (0.1)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.17)\n",
      "Requirement already satisfied: cmaes>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from optuna) (0.5.0)\n",
      "Requirement already satisfied: cliff in /usr/local/lib/python3.6/dist-packages (from optuna) (3.1.0)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (from optuna) (4.1.0)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.2)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.15.1)\n",
      "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
      "Requirement already satisfied: cmd2!=0.8.3,<0.9.0,>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.8.9)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.12.0)\n",
      "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
      "Requirement already satisfied: stevedore>=1.20.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.32.0)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (5.4.5)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.1.2)\n",
      "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (1.0.4)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
      "Requirement already satisfied: pyperclip in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,<0.9.0,>=0.8.0->cliff->optuna) (1.8.0)\n",
      "Requirement already satisfied: wcwidth; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,<0.9.0,>=0.8.0->cliff->optuna) (0.1.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# @title Installation\n",
    "!pip install ipdb # debug\n",
    "!pip install ipython-autotime  # timming\n",
    "!pip install optuna  # hyperparaeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 6.3 ms\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxopt\n",
    "np.random.seed(54321)\n",
    "\n",
    "import ipdb\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.05 ms\n"
     ]
    }
   ],
   "source": [
    "# seq = ['seq_'+str(i) for i in range(100)]\n",
    "# X_train=pd.read_csv('./data/Xtr_mat100.csv', sep=' ', names = seq) #we use this dataset to train our model\n",
    "# X_test=pd.read_csv('./data/Xte_mat100.csv', sep=' ', names = seq) #we will use this data set later to validate our model\n",
    "\n",
    "# Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.8 ms\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test=pd.read_csv('./data/Xte.csv', sep=',') #we will use this data set later to validate our model\n",
    "\n",
    "# X_train_mat=pd.read_csv('./data/Xtr_mat100.csv', sep=',') #we use this dataset to train our model\n",
    "# X_test_mat=pd.read_csv('./data/Xte_mat100.csv', sep=',') #we will use this data set later to validate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.47 ms\n"
     ]
    }
   ],
   "source": [
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                                seq\n",
       "1995  1995  TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...\n",
       "1996  1996  ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...\n",
       "1997  1997  TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...\n",
       "1998  1998  CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...\n",
       "1999  1999  TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.8 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_train dataset is: (2000, 2)\n",
      "The shape of the Y_train dataset is: (2000, 2)\n",
      "time: 2.41 ms\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the X_train dataset is:',X_train.shape)\n",
    "print('The shape of the Y_train dataset is:',Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 594 µs\n"
     ]
    }
   ],
   "source": [
    "# train.seq.apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   1  CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   2  GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   3  GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   4  GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.3 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.05 ms\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "Alphabet_dict = dict(zip(string.ascii_uppercase, range(1,27)))\n",
    "\n",
    "d = {'A': 0, 'C':1, 'G':2, 'T':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.15 ms\n"
     ]
    }
   ],
   "source": [
    "101-3+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 381 ms\n"
     ]
    }
   ],
   "source": [
    "# X_train['seq_1'] = X_train.seq.apply(lambda x : (' '.join(map(str, list(x))))[0])\n",
    "\n",
    "def number_of_split(X_train, X_test, Y_train, n=3):\n",
    "    for i in range(0, 101-n+1, 1):\n",
    "    #     X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :Alphabet_dict[x[i]])\n",
    "    #     X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :Alphabet_dict[x[i]])\n",
    "\n",
    "    #     X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :Alphabet_dict[x[i]])\n",
    "    #     X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :Alphabet_dict[x[i]]\n",
    "\n",
    "        X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :x[i:i+n])\n",
    "        X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :x[i:i+n])\n",
    "        \n",
    "    X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "    X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "    y = Y_train.Bound\n",
    "    return X, X_t, y\n",
    "\n",
    "\n",
    "X, X_t, y = number_of_split((X_train, X_test, Y_train, n=3)) \n",
    "# X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "# X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "# y = Y_train.Bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_0</th>\n",
       "      <th>seq_1</th>\n",
       "      <th>seq_2</th>\n",
       "      <th>seq_3</th>\n",
       "      <th>seq_4</th>\n",
       "      <th>seq_5</th>\n",
       "      <th>seq_6</th>\n",
       "      <th>seq_7</th>\n",
       "      <th>seq_8</th>\n",
       "      <th>seq_9</th>\n",
       "      <th>seq_10</th>\n",
       "      <th>seq_11</th>\n",
       "      <th>seq_12</th>\n",
       "      <th>seq_13</th>\n",
       "      <th>seq_14</th>\n",
       "      <th>seq_15</th>\n",
       "      <th>seq_16</th>\n",
       "      <th>seq_17</th>\n",
       "      <th>seq_18</th>\n",
       "      <th>seq_19</th>\n",
       "      <th>seq_20</th>\n",
       "      <th>seq_21</th>\n",
       "      <th>seq_22</th>\n",
       "      <th>seq_23</th>\n",
       "      <th>seq_24</th>\n",
       "      <th>seq_25</th>\n",
       "      <th>seq_26</th>\n",
       "      <th>seq_27</th>\n",
       "      <th>seq_28</th>\n",
       "      <th>seq_29</th>\n",
       "      <th>seq_30</th>\n",
       "      <th>seq_31</th>\n",
       "      <th>seq_32</th>\n",
       "      <th>seq_33</th>\n",
       "      <th>seq_34</th>\n",
       "      <th>seq_35</th>\n",
       "      <th>seq_36</th>\n",
       "      <th>seq_37</th>\n",
       "      <th>seq_38</th>\n",
       "      <th>seq_39</th>\n",
       "      <th>...</th>\n",
       "      <th>seq_61</th>\n",
       "      <th>seq_62</th>\n",
       "      <th>seq_63</th>\n",
       "      <th>seq_64</th>\n",
       "      <th>seq_65</th>\n",
       "      <th>seq_66</th>\n",
       "      <th>seq_67</th>\n",
       "      <th>seq_68</th>\n",
       "      <th>seq_69</th>\n",
       "      <th>seq_70</th>\n",
       "      <th>seq_71</th>\n",
       "      <th>seq_72</th>\n",
       "      <th>seq_73</th>\n",
       "      <th>seq_74</th>\n",
       "      <th>seq_75</th>\n",
       "      <th>seq_76</th>\n",
       "      <th>seq_77</th>\n",
       "      <th>seq_78</th>\n",
       "      <th>seq_79</th>\n",
       "      <th>seq_80</th>\n",
       "      <th>seq_81</th>\n",
       "      <th>seq_82</th>\n",
       "      <th>seq_83</th>\n",
       "      <th>seq_84</th>\n",
       "      <th>seq_85</th>\n",
       "      <th>seq_86</th>\n",
       "      <th>seq_87</th>\n",
       "      <th>seq_88</th>\n",
       "      <th>seq_89</th>\n",
       "      <th>seq_90</th>\n",
       "      <th>seq_91</th>\n",
       "      <th>seq_92</th>\n",
       "      <th>seq_93</th>\n",
       "      <th>seq_94</th>\n",
       "      <th>seq_95</th>\n",
       "      <th>seq_96</th>\n",
       "      <th>seq_97</th>\n",
       "      <th>seq_98</th>\n",
       "      <th>seq_99</th>\n",
       "      <th>seq_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGA</td>\n",
       "      <td>GAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCC</td>\n",
       "      <td>CCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGA</td>\n",
       "      <td>GAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGA</td>\n",
       "      <td>GAC</td>\n",
       "      <td>ACT</td>\n",
       "      <td>CTC</td>\n",
       "      <td>TCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>...</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCG</td>\n",
       "      <td>CGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTC</td>\n",
       "      <td>TCC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACA</td>\n",
       "      <td>CAT</td>\n",
       "      <td>ATG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGA</td>\n",
       "      <td>GAG</td>\n",
       "      <td>AGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTT</td>\n",
       "      <td>TTA</td>\n",
       "      <td>TAC</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGA</td>\n",
       "      <td>GAT</td>\n",
       "      <td>ATG</td>\n",
       "      <td>...</td>\n",
       "      <td>TCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGC</td>\n",
       "      <td>GCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGT</td>\n",
       "      <td>GTA</td>\n",
       "      <td>TAC</td>\n",
       "      <td>ACT</td>\n",
       "      <td>CTA</td>\n",
       "      <td>TAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTC</td>\n",
       "      <td>TCC</td>\n",
       "      <td>CCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GAC</td>\n",
       "      <td>ACA</td>\n",
       "      <td>CAA</td>\n",
       "      <td>AAC</td>\n",
       "      <td>ACG</td>\n",
       "      <td>CGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCG</td>\n",
       "      <td>CGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTC</td>\n",
       "      <td>TCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCG</td>\n",
       "      <td>CGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTT</td>\n",
       "      <td>TTC</td>\n",
       "      <td>TCG</td>\n",
       "      <td>CGA</td>\n",
       "      <td>GAC</td>\n",
       "      <td>ACT</td>\n",
       "      <td>CTC</td>\n",
       "      <td>TCA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGA</td>\n",
       "      <td>GAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>...</td>\n",
       "      <td>TAC</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGA</td>\n",
       "      <td>GAA</td>\n",
       "      <td>AAT</td>\n",
       "      <td>ATC</td>\n",
       "      <td>TCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCA</td>\n",
       "      <td>CAT</td>\n",
       "      <td>ATC</td>\n",
       "      <td>TCC</td>\n",
       "      <td>CCC</td>\n",
       "      <td>CCG</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTC</td>\n",
       "      <td>TCC</td>\n",
       "      <td>CCC</td>\n",
       "      <td>CCC</td>\n",
       "      <td>CCG</td>\n",
       "      <td>CGA</td>\n",
       "      <td>GAA</td>\n",
       "      <td>AAG</td>\n",
       "      <td>AGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGC</td>\n",
       "      <td>GCG</td>\n",
       "      <td>CGT</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GCC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTC</td>\n",
       "      <td>TCC</td>\n",
       "      <td>CCC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTT</td>\n",
       "      <td>TTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CCA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACG</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGA</td>\n",
       "      <td>GAG</td>\n",
       "      <td>AGA</td>\n",
       "      <td>GAC</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGT</td>\n",
       "      <td>GTT</td>\n",
       "      <td>TTT</td>\n",
       "      <td>TTT</td>\n",
       "      <td>TTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGA</td>\n",
       "      <td>GAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCG</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>...</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTC</td>\n",
       "      <td>TCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGA</td>\n",
       "      <td>GAA</td>\n",
       "      <td>AAG</td>\n",
       "      <td>AGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGA</td>\n",
       "      <td>GAA</td>\n",
       "      <td>AAG</td>\n",
       "      <td>AGT</td>\n",
       "      <td>GTT</td>\n",
       "      <td>TTT</td>\n",
       "      <td>TTC</td>\n",
       "      <td>TCG</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGC</td>\n",
       "      <td>GCA</td>\n",
       "      <td>CAG</td>\n",
       "      <td>AGA</td>\n",
       "      <td>GAG</td>\n",
       "      <td>AGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTA</td>\n",
       "      <td>TAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACT</td>\n",
       "      <td>CTA</td>\n",
       "      <td>TAC</td>\n",
       "      <td>ACT</td>\n",
       "      <td>CTA</td>\n",
       "      <td>TAC</td>\n",
       "      <td>ACA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CCC</td>\n",
       "      <td>CCA</td>\n",
       "      <td>CAT</td>\n",
       "      <td>ATT</td>\n",
       "      <td>TTG</td>\n",
       "      <td>TGC</td>\n",
       "      <td>GCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTA</td>\n",
       "      <td>TAA</td>\n",
       "      <td>AAT</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TAG</td>\n",
       "      <td>AGT</td>\n",
       "      <td>GTA</td>\n",
       "      <td>TAA</td>\n",
       "      <td>AAG</td>\n",
       "      <td>AGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCG</td>\n",
       "      <td>CGG</td>\n",
       "      <td>GGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGC</td>\n",
       "      <td>GCC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>...</td>\n",
       "      <td>GTC</td>\n",
       "      <td>TCC</td>\n",
       "      <td>CCT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGG</td>\n",
       "      <td>GGG</td>\n",
       "      <td>GGA</td>\n",
       "      <td>GAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAT</td>\n",
       "      <td>ATA</td>\n",
       "      <td>TAC</td>\n",
       "      <td>ACA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACT</td>\n",
       "      <td>CTC</td>\n",
       "      <td>TCA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACA</td>\n",
       "      <td>CAC</td>\n",
       "      <td>ACT</td>\n",
       "      <td>CTT</td>\n",
       "      <td>TTG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTA</td>\n",
       "      <td>TAC</td>\n",
       "      <td>ACT</td>\n",
       "      <td>CTG</td>\n",
       "      <td>TGT</td>\n",
       "      <td>GTT</td>\n",
       "      <td>TTA</td>\n",
       "      <td>TAC</td>\n",
       "      <td>ACC</td>\n",
       "      <td>CCC</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  seq_0 seq_1 seq_2 seq_3 seq_4  ... seq_96 seq_97 seq_98 seq_99 seq_100\n",
       "0   GAG   AGG   GGG   GGG   GGC  ...    GGC    GCA    CAG      A       G\n",
       "1   CGG   GGC   GCC   CCT   CTG  ...    GGT    GTG    TGG      G       G\n",
       "2   GAC   ACA   CAA   AAC   ACG  ...    TGC    GCG    CGT      G       T\n",
       "3   GCC   CCT   CTC   TCC   CCC  ...    CTA    TAA    AAA      A       A\n",
       "4   GCA   CAC   ACT   CTA   TAC  ...    TAC    ACC    CCC      C       C\n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 227 ms\n"
     ]
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about counting number of different caracters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 691 µs\n"
     ]
    }
   ],
   "source": [
    "# X.loc[200].iloc[98]='o'\n",
    "# X.loc[200].iloc[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: \n",
      "      seq_0  seq_1  seq_2  seq_3  seq_4  ...  seq_92  seq_93  seq_94  seq_95  seq_96\n",
      "1995  743.2  799.6  814.0  817.6  716.0  ...   701.2   686.8   478.4   528.8   746.0\n",
      "1996  551.6  547.2  443.6  724.8  795.2  ...   520.0   539.2   544.0   442.8   622.4\n",
      "1997  759.2  496.4  533.2  747.2  493.6  ...   786.0   810.4   714.0   690.0   581.6\n",
      "1998  622.4  564.8  755.2  700.4  789.2  ...   764.4   805.2   712.8   587.2   556.0\n",
      "1999  496.8  635.6  772.8  807.2  713.2  ...   434.4   722.4   692.0   786.8   810.8\n",
      "\n",
      "[5 rows x 97 columns]\n",
      " -----------------------\n",
      "\n",
      "Test: \n",
      "      seq_0  seq_1  seq_2  seq_3  seq_4  ...  seq_92  seq_93  seq_94  seq_95  seq_96\n",
      "995  760.4  804.0  712.4  484.8  632.8  ...   622.4   667.2   473.6   425.2   515.6\n",
      "996  549.2  444.0  622.4  564.8  755.2  ...   686.4   683.2   580.0   451.6   419.6\n",
      "997  601.2  457.2  421.2  412.0  409.6  ...   446.4   725.6   795.2   812.8   817.2\n",
      "998  494.8  430.4  619.2  564.0  447.6  ...   790.0   709.2   791.2   811.6   612.0\n",
      "999  754.8  802.8  712.4  792.0  504.8  ...   502.0   432.4   722.0   794.4   607.6\n",
      "\n",
      "[5 rows x 97 columns]\n",
      "time: 2.86 s\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test=pd.read_csv('./data/Xte.csv', sep=',')\n",
    "\n",
    "def spectrum_kernal(X_train, y, X_test, n=3, encoder=4, one_hot = True, normalise = False):\n",
    "    \n",
    "    d = {'A': 0.3, 'C':0.4, 'G':0.5, 'T':0.6}\n",
    "    \n",
    "    for i in range(0, 101-n+1, 1):\n",
    "        X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :x[i:i+n])\n",
    "        X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :x[i:i+n])\n",
    "        \n",
    "        X_train['seq_'+str(i)] = X_train['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        X_test['seq_'+str(i)] = X_test['seq_'+str(i)].apply(lambda x : sum([d[x[ii]]*encoder**(ii+1) for ii in range(n)]))\n",
    "        \n",
    "        \n",
    "        \n",
    "    X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "    X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "    y = Y_train.Bound\n",
    "    \n",
    "#     print(f'Train: \\n{X.tail()}\\n -----------------------\\n')\n",
    "#     print(f'Test: \\n {X_t.tail()}')\n",
    "\n",
    "    if one_hot:\n",
    "        onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "        X_cross = X.values\n",
    "        X_t = X_t.values\n",
    "\n",
    "        y_cross = y.values\n",
    "\n",
    "\n",
    "        X_cross = onehot_encoder.fit_transform(X)\n",
    "        X_t_enc = onehot_encoder.fit_transform(X_t)\n",
    "        \n",
    "    elif normalise:\n",
    "        scaler = MinMaxScaler()#MinMaxScaler() # StandardScaler()\n",
    "        scaler.fit(X)\n",
    "        \n",
    "        X_cross = scaler.transform(X)\n",
    "        X_t_enc = scaler.transform(X_t)\n",
    "    else :\n",
    "        \n",
    "        X_cross = X.values\n",
    "        X_t_enc = X_t.values\n",
    "\n",
    "    return X_cross, y, X_t_enc\n",
    "\n",
    "X, y, X_t = spectrum_kernal(X_train, Y_train, X_test, n=5, encoder=4, one_hot = False, normalise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 97)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.52 ms\n"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 97)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.87 ms\n"
     ]
    }
   ],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 878 µs\n"
     ]
    }
   ],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.07 ms\n"
     ]
    }
   ],
   "source": [
    "# X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "# X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "# y = Y_train.Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.2 ms\n"
     ]
    }
   ],
   "source": [
    "# class LogisticRegressionBinary():\n",
    "#     def __init__(self, lr=0.1, num_iter=100000, batch_size=1, verbose=False):\n",
    "#         self.lr = lr\n",
    "#         self.num_iter = num_iter\n",
    "#         self.batch_size = batch_size\n",
    "#         self.verbose = verbose\n",
    "    \n",
    "#     def __add_intercept(self, X):\n",
    "#         intercept = np.ones((X.shape[0], 1))\n",
    "#         return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "#     def __sigmoid_func(self, z):\n",
    "#         return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "#     def __loss(self, h, y):\n",
    "#         return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "#     def fit(self, X, y):\n",
    "#         y = self.trans_y(y)\n",
    "#         X = self.__add_intercept(X)\n",
    "#         self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "#         for i in range(self.num_iter):\n",
    "#             z = np.dot(X, self.theta)\n",
    "#             h = self.__sigmoid_func(z)\n",
    "                        \n",
    "#             rand = np.random.choice(y.size, self.batch_size).squeeze()\n",
    "#             gradient = np.dot(X[rand].T, (h[rand] - y[rand]))/y.size   \n",
    "        \n",
    "#             self.theta -= self.lr * gradient\n",
    "#             #print('theta and grad',self.theta.shape ,  gradient.shape )\n",
    "#             if(self.verbose == True and i % 100 == 0):\n",
    "#                 z = np.dot(X, self.theta)\n",
    "#                 h = self.__sigmoid(z)\n",
    "#                 print(f'loss: {self.__loss(h, y)} \\t')\n",
    "    \n",
    "#     def predict_probability(self, X):\n",
    "#         X = self.__add_intercept(X)\n",
    "    \n",
    "#         return self.__sigmoid_func(np.dot(X, self.theta))\n",
    "    \n",
    "#     def predict(self, X, threshold=.5):\n",
    "#           return np.where(self.predict_probability(X) >= 0.5, 1, 0)\n",
    "        \n",
    "          \n",
    "#     def Accuracy_check(self,X,y):\n",
    "#         return np.mean(self.predict(X)==y)\n",
    "    \n",
    "#     def trans_y(self, y):\n",
    "#         if isinstance(y, pd.Series):\n",
    "#             y = y.values\n",
    "#         if isinstance(y, list):\n",
    "#             y = np.array(y)\n",
    "#         return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression (RR)\n",
    "\n",
    "class solveRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "            \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        A = (X.T.dot(X)) + np.eye(p)*lam*n\n",
    "        b = X.T.dot(y)\n",
    "        \n",
    "        self.beta = np.linalg.solve(A, b)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Weighted Ridge Regression (WRR)\n",
    "class solveWRR():\n",
    "    def __init__(self, X, y, w, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.w = w\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        w = self.w\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == len(w) == n)\n",
    "\n",
    "        y1 = np.sqrt(w) * y\n",
    "        X1 = (np.sqrt(w) * X.T).T\n",
    "        \n",
    "        # Hint:\n",
    "        # Find y1 and X1 such that:\n",
    "        \n",
    "        self.beta = solveRR(X1, y1, lam).fit()\n",
    "                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Logistic Ridge Regression (LRR)\n",
    "class solveLRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "    \n",
    "        lam = self.lam \n",
    "        max_iter = 50\n",
    "        eps = 1e-3\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialize\n",
    "        self.beta = np.zeros(p)\n",
    "\n",
    "        # Hint: Use IRLS\n",
    "        for i in range(max_iter):\n",
    "            beta_old = self.beta\n",
    "            f = X.dot(beta_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*f)\n",
    "            self.beta = solveWRR(X, z, w, 2*lam).fit()\n",
    "            # Break condition (achieved convergence)\n",
    "            #if np.sum((beta-beta_old)**2) < eps:\n",
    "            #    break                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 156 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "### Functions for you to fill in ###\n",
    "\n",
    "def polynomial_kernel(X, Y, c, p):\n",
    "    \"\"\"\n",
    "        Compute the polynomial kernel between two matrices X and Y::\n",
    "            K(x, y) = (<x, y> + c)^p\n",
    "        for each pair of rows x in X and y in Y.\n",
    "\n",
    "        Args:\n",
    "            X - (n, d) NumPy array (n datapoints each with d features)\n",
    "            Y - (m, d) NumPy array (m datapoints each with d features)\n",
    "            c - a coefficient to trade off high-order and low-order terms (scalar)\n",
    "            p - the degree of the polynomial kernel\n",
    "\n",
    "        Returns:\n",
    "            kernel_matrix - (n, m) Numpy array containing the kernel matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError\n",
    "    kernel_matrix = (X.dot(Y.T) + c)**p\n",
    "    \n",
    "    return kernel_matrix\n",
    "\n",
    "\n",
    "def rbf_kernel_2(X, Y, gamma):\n",
    "    \"\"\"\n",
    "        Compute the Gaussian RBF kernel between two matrices X and Y::\n",
    "            K(x, y) = exp(-gamma ||x-y||^2)\n",
    "        for each pair of rows x in X and y in Y.\n",
    "\n",
    "        Args:\n",
    "            X - (n, d) NumPy array (n datapoints each with d features)\n",
    "            Y - (m, d) NumPy array (m datapoints each with d features)\n",
    "            gamma - the gamma parameter of gaussian function (scalar)\n",
    "\n",
    "        Returns:\n",
    "            kernel_matrix - (n, m) Numpy array containing the kernel matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError\n",
    "    n, d = X.shape\n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    kernel_matrix = X**2 @ np.ones((d,m)) + np.ones((n,d)) @ Y.T**2 - 2*(X @ Y.T)\n",
    "    kernel_matrix = np.exp(-gamma*kernel_matrix)\n",
    "    \n",
    "    return kernel_matrix\n",
    "\n",
    "\n",
    "def rbf_kernel_element_wise(x, y, sigma=1):\n",
    "    '''\n",
    "    returns the RBF (Gaussian) kernel k(x, y)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    x and y are p-dimensional vectors \n",
    "    '''\n",
    "    K = np.exp(- np.sum((x - y)**2) / (2 * sigma ** 2))\n",
    "    return K\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis=-1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis=-1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    '''\n",
    "    Returns the median of ||Xi-Xj||\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    X: (n, p) matrix\n",
    "    '''\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "# def laplace(X1, X2, alpha=10):\n",
    "#     return np.exp(-alpha*np.abs(X1-X2))\n",
    "\n",
    "# def polynomial(X1, X2, d=2):\n",
    "#     return (X1.dot(X2.T) +1)**d\n",
    "\n",
    "def linear_kernel(X1, X2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the linear kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return X1.dot(X2.T)\n",
    "\n",
    "def quadratic_kernel(X1, X2, power=2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the quadratic kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return (1 + linear_kernel(X1, X2))**power\n",
    "\n",
    "def rbf_poly_kernel(X1, X2, sigma=10, d=2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis=-1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis=-1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    \n",
    "    return K+(X1.dot(X2.T) +1)**d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.8 ms\n"
     ]
    }
   ],
   "source": [
    "class ksolveRR_2():\n",
    "    def __init__(self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.sigma = sigma\n",
    "        self.kernel = kernel\n",
    "        self.sample_weights = sample_weights\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        if self.sample_weights is not None:\n",
    "            self.X *= self.sample_weights[:, None]\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "        A = self.kernel(X, X, self.sigma)+n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.8 ms\n"
     ]
    }
   ],
   "source": [
    "class ksolveRR():\n",
    "    def __init__(self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.sigma = sigma\n",
    "        self.kernel = kernel\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "        if self.sigma is None:\n",
    "            self.sigma = sigma_from_median(X)\n",
    "            \n",
    "        A = self.kernel(X, X, self.sigma)+n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 86.3 ms\n"
     ]
    }
   ],
   "source": [
    "import ipdb\n",
    "# Logistic Ridge Regression (LRR)\n",
    "class ksolveLRR():\n",
    "    def __init__(self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        K = self.kernel(X, X, self.sigma)\n",
    "\n",
    "        # Initialize\n",
    "        alpha = np.zeros(n)\n",
    "        \n",
    "        # Hint: Use IRLS\n",
    "        for n_iter in range(self.max_iter):\n",
    "            alpha_old = alpha\n",
    "            f = K.dot(alpha_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*(f))\n",
    "            \n",
    "            alpha = ksolveRR_2(X, y, lam = 2*self.lam, \\\n",
    "                               sigma=self.sigma, sample_weights = w).fit().alpha\n",
    "            \n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < self.tol:\n",
    "                break  \n",
    "                \n",
    "                \n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 285 ms\n"
     ]
    }
   ],
   "source": [
    "# You don't need to look at this, this is just to adapt our matrices\n",
    "# to the solver being used\n",
    "solver='cvxopt'\n",
    "\n",
    "import cvxopt\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    #cvxopt.solvers.options['show_progress'] = False\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = cvxopt_qp\n",
    "\n",
    "def quadprog_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "    qp_G = .5 * (P + P.T)   # make sure P is symmetric\n",
    "    qp_a = -q\n",
    "    if A is not None:\n",
    "        qp_C = -np.vstack([A, G]).T\n",
    "        qp_b = -np.hstack([b, h])\n",
    "        meq = A.shape[0]\n",
    "    else:  # no equality constraint\n",
    "        qp_C = - G.T\n",
    "        qp_b = - h\n",
    "        meq = 0\n",
    "    return quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)[0]\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices)\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = {'quadprog': quadprog_solve_qp, 'cvxopt': cvxopt_qp}[solver]\n",
    "\n",
    "def svm_dual_soft_to_qp_kernel(K, y, C=1):\n",
    "    n = K.shape[0]\n",
    "    assert (len(y) == n)\n",
    "        \n",
    "    # Dual formulation, soft margin\n",
    "    P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "    # As a regularization, we add epsilon * identity to P\n",
    "    eps = 1e-12\n",
    "    P += eps * np.eye(n)\n",
    "    q = - np.ones(n)\n",
    "    G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "    h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "    A = y[np.newaxis, :]\n",
    "    A = A.astype('float')\n",
    "    b = np.array([0.])\n",
    "    return P, q, G, h, A, b\n",
    "\n",
    "# SVM primal soft\n",
    "class KernelSVM():\n",
    "    def __init__(self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.lam = lam        \n",
    "        self.sigma = sigma\n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        C = self.C\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        K = self.kernel(X, X, self.sigma)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = solve_qp(*svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        \n",
    "       # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha>self.tol), (self.C - self.alpha > self.tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha*y)\n",
    "        self.bias =  self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "#         y_pred = self.kernel(X, self.X_).dot(self.alphas* seld.y_)\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where((K_x.dot(self.alpha * self.y) +  self.bias) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.12 ms\n"
     ]
    }
   ],
   "source": [
    "# # Logistic Ridge Regression (LRR)\n",
    "# class perceptron():\n",
    "#     def __init__(self, X, y, iteration=100):\n",
    "#         self.theta = np.zeros(len(X))\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.iteration = iteration\n",
    "#         self.theta_0 = 0\n",
    "    \n",
    "#     def fit(self):\n",
    "        \n",
    "#         X = self.X\n",
    "#         y = self.y\n",
    "        \n",
    "#         n, p = X.shape\n",
    "#         assert (len(y) == n)\n",
    "        \n",
    "#         for it in range(self.iteration):\n",
    "#             for i in range(len(y)):\n",
    "#                 if y[i]*(np.dot(self.theta, X[i]) + self.theta_0)<= 0 :\n",
    "#                     self.theta = self.theta + (np.dot(y[i], X[i]))\n",
    "#                     self.theta_0 += y[i]\n",
    "    \n",
    "        \n",
    "#     def predict(self, X, threshold):\n",
    "#         return np.where(X.dot(self.self.theta)+self.theta_0 >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "#     def Accuracy_check(self,X, y, threshold=.5):\n",
    "#         return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.17 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import TransformerM\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.48 ms\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = CountVectorizer(max_features=2000)\n",
    "# vectorizer.fit_transform(X[:10])\n",
    "# # vectorizer.get_feature_names()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.2 ms\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=5)\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "# X_cross = X.values\n",
    "# X_t = X_t.values\n",
    "\n",
    "y_cross = y.values\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_cross = vectorizer.fit_transform(X)\n",
    "\n",
    "# X_cross = onehot_encoder.fit_transform(X.values[:, :101])\n",
    "# X_t_enc = onehot_encoder.fit_transform(X_t.values[:, :101])\n",
    "\n",
    "# X_cross = onehot_encoder.fit_transform(X)\n",
    "# X_t_enc = onehot_encoder.fit_transform(X_t)\n",
    "\n",
    "\n",
    "X_cross = X.values\n",
    "X_t_enc = X_t.values\n",
    "\n",
    "\n",
    "# scaler = MinMaxScaler()#MinMaxScaler() # StandardScaler()\n",
    "# scaler.fit(X_cross)\n",
    "\n",
    "# X_cross = scaler.transform(X_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 775 µs\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.83 ms\n"
     ]
    }
   ],
   "source": [
    "# def feature_selector(X):\n",
    "#     #sel = VarianceThreshold()\n",
    "#     sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "#     sel.fit_transform(X)\n",
    "#     return X\n",
    "# def best_feature_selector(X,y,num_features=50):\n",
    "#     #print(X.shape)\n",
    "#     features = SelectKBest(chi2, k=num_features).fit(X, y)\n",
    "#     #print(X_new.shape)\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 99)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.43 ms\n"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 722 µs\n"
     ]
    }
   ],
   "source": [
    "# trans = best_feature_selector(X, y, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 890 µs\n"
     ]
    }
   ],
   "source": [
    "# X = trans.transform(X)\n",
    "# X_t = trans.transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 99)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.16 ms\n"
     ]
    }
   ],
   "source": [
    "X.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 99)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.33 ms\n"
     ]
    }
   ],
   "source": [
    "X_t.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 99)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.49 ms\n"
     ]
    }
   ],
   "source": [
    "X_t_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 99)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.05 ms\n"
     ]
    }
   ],
   "source": [
    "X_cross.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.63 ms\n"
     ]
    }
   ],
   "source": [
    "# PRUNNING TRIAL \n",
    "\n",
    "# def objective_sgd(trial):\n",
    "# #     c  = trial.suggest_loguniform('c', 1e-20, 30)\n",
    "#     sigma  = trial.suggest_loguniform('sigma', 1e-3, 20) # trial.suggest_float('sigma', 1e-5, 1e-3, log=True)\n",
    "# #     kenel = trial.suggest_categorical('kenel', [rbf_kernel, quadratic_kernel])\n",
    "#     lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "# #     tol = trial.suggest_loguniform('tol', 1e-10, 1e-0)\n",
    "    \n",
    "#     # ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "#     # ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "#     # ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "#     # KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "    \n",
    "# #     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "# #               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM'} \n",
    "# #     \n",
    "#     kenel = rbf_kernel\n",
    "#     models = {ksolveRR: 'k Ridge Reg'} \n",
    "      \n",
    "# #     accuracy = []\n",
    "#     for model in models:\n",
    "#         accuracy = []\n",
    "#         for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "#             X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "#             X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "            \n",
    "            \n",
    "# #             ipdb.set_trace()\n",
    "#             if models[model] == 'weigh Ridge Reg':\n",
    "#                 sample_weights = np.random.rand(len(y_train))\n",
    "#                 model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "                \n",
    "#             elif models[model] == 'k Logistic Ridge Reg':\n",
    "#                 model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kenel)\n",
    "#             elif models[model] == 'k Ridge Reg':\n",
    "#                 model_curr = model(X_train, y_train, lam = lam, sigma = sigma, kernel = kenel)\n",
    "#             else:\n",
    "#                 model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kenel)\n",
    "            \n",
    "#             model_curr.fit()\n",
    "            \n",
    "#             acc = model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5)\n",
    "#             accuracy.append(acc)\n",
    "            \n",
    "#             intermediate_value = acc\n",
    "#             trial.report(intermediate_value, i)\n",
    "        \n",
    "# #             print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "        \n",
    "# #         print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')\n",
    "\n",
    "#     return np.mean(accuracy)\n",
    "\n",
    "# # Set up the median stopping rule as the pruning condition.\n",
    "# # study = optuna.create_study(pruner=optuna.pruners.MedianPruner())\n",
    "# study = optuna.create_study(pruner=optuna.pruners.MedianPruner(), sampler=sampler, direction='maximize')\n",
    "\n",
    "# # sampler = optuna.samplers.TPESampler()    # sampler = SimulatedAnnealingSampler()\n",
    "# # study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "# study.optimize(func=objective_sgd, n_trials=1500,show_progress_bar=True)\n",
    "\n",
    "\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print('Accuracy: {}'.format(trial.value))\n",
    "# print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.72 ms\n"
     ]
    }
   ],
   "source": [
    "2e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340b8802aa1d40efa3d4eba35b63686b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/distributions.py:331: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function rbf_kernel at 0x7fdeba31ff28> which is of type function.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/optuna/distributions.py:331: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function quadratic_kernel at 0x7fdeba335f28> which is of type function.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/optuna/distributions.py:331: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR'> which is of type type.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/optuna/distributions.py:331: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR_2'> which is of type type.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/optuna/distributions.py:331: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveLRR'> which is of type type.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/optuna/distributions.py:331: UserWarning:\n",
      "\n",
      "Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.KernelSVM'> which is of type type.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2020-05-29 03:24:02,451]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function rbf_kernel at 0x7fdeba31ff28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:02,455]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function quadratic_kernel at 0x7fdeba335f28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:02,461]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:02,464]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR_2'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:02,467]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveLRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:02,471]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.KernelSVM'> which is of type type.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 03:24:47,417]\u001b[0m Finished trial#0 with value: 0.501 with parameters: {'c': 8.83470335971282e-08, 'sigma': 0.7749222834484071, 'kenel': <function rbf_kernel at 0x7fdeba31ff28>, 'lam': 0.05942920176774147, 'tol': 0.008371027295223075, 'models': <class '__main__.ksolveLRR'>}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:47,429]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function rbf_kernel at 0x7fdeba31ff28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:47,431]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function quadratic_kernel at 0x7fdeba335f28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:47,434]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:47,436]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR_2'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:47,437]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveLRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:24:47,438]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.KernelSVM'> which is of type type.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0383e+02 -2.3233e+00  7e+03  8e+01  7e-16\n",
      " 1: -4.5681e+00 -2.3218e+00  7e+01  8e-01  6e-16\n",
      " 2: -5.7877e-01 -2.1804e+00  2e+00  8e-03  3e-16\n",
      " 3: -6.1428e-01 -7.1848e-01  1e-01  2e-04  7e-16\n",
      " 4: -6.6830e-01 -6.6943e-01  1e-03  2e-06  3e-16\n",
      " 5: -6.6884e-01 -6.6885e-01  1e-05  2e-08  2e-16\n",
      " 6: -6.6885e-01 -6.6885e-01  1e-07  2e-10  3e-16\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:100: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in greater_equal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0684e+02 -2.3258e+00  7e+03  8e+01  6e-16\n",
      " 1: -4.6021e+00 -2.3243e+00  7e+01  8e-01  4e-16\n",
      " 2: -5.8307e-01 -2.1833e+00  2e+00  8e-03  5e-16\n",
      " 3: -6.1885e-01 -7.2317e-01  1e-01  2e-04  7e-16\n",
      " 4: -6.7327e-01 -6.7440e-01  1e-03  2e-06  3e-16\n",
      " 5: -6.7381e-01 -6.7382e-01  1e-05  2e-08  2e-16\n",
      " 6: -6.7382e-01 -6.7382e-01  1e-07  2e-10  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9182e+02 -2.3133e+00  7e+03  8e+01  6e-16\n",
      " 1: -4.4322e+00 -2.3118e+00  7e+01  8e-01  5e-16\n",
      " 2: -5.6155e-01 -2.1686e+00  2e+00  8e-03  4e-16\n",
      " 3: -5.9602e-01 -6.9974e-01  1e-01  2e-04  7e-16\n",
      " 4: -6.4843e-01 -6.4955e-01  1e-03  2e-06  3e-16\n",
      " 5: -6.4895e-01 -6.4896e-01  1e-05  2e-08  2e-16\n",
      " 6: -6.4895e-01 -6.4895e-01  1e-07  2e-10  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0233e+02 -2.3220e+00  7e+03  8e+01  6e-16\n",
      " 1: -4.5511e+00 -2.3205e+00  7e+01  8e-01  2e-16\n",
      " 2: -5.7662e-01 -2.1789e+00  2e+00  8e-03  3e-16\n",
      " 3: -6.1200e-01 -7.1614e-01  1e-01  2e-04  7e-16\n",
      " 4: -6.6582e-01 -6.6695e-01  1e-03  2e-06  3e-16\n",
      " 5: -6.6635e-01 -6.6637e-01  1e-05  2e-08  3e-16\n",
      " 6: -6.6636e-01 -6.6636e-01  1e-07  2e-10  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0083e+02 -2.3208e+00  7e+03  8e+01  6e-16\n",
      " 1: -4.5341e+00 -2.3193e+00  7e+01  8e-01  5e-16\n",
      " 2: -5.7446e-01 -2.1774e+00  2e+00  8e-03  4e-16\n",
      " 3: -6.0972e-01 -7.1380e-01  1e-01  2e-04  8e-16\n",
      " 4: -6.6333e-01 -6.6446e-01  1e-03  2e-06  6e-16\n",
      " 5: -6.6387e-01 -6.6388e-01  1e-05  2e-08  3e-16\n",
      " 6: -6.6387e-01 -6.6387e-01  1e-07  2e-10  3e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-29 03:25:24,453]\u001b[0m Finished trial#1 with value: 0.501 with parameters: {'c': 0.000828804924279396, 'sigma': 16.18553833110275, 'kenel': <function rbf_kernel at 0x7fdeba31ff28>, 'lam': 0.02448132670091159, 'tol': 0.00013030010860717688, 'models': <class '__main__.KernelSVM'>}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:25:24,459]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function rbf_kernel at 0x7fdeba31ff28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:25:24,478]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function quadratic_kernel at 0x7fdeba335f28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:25:24,484]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:25:24,485]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR_2'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:25:24,486]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveLRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:25:24,494]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.KernelSVM'> which is of type type.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0356e+02 -3.9861e-01  7e+03  8e+01  6e-16\n",
      " 1: -4.1265e+00 -3.9857e-01  7e+01  8e-01  4e-16\n",
      " 2: -1.3224e-01 -3.9415e-01  1e+00  8e-03  4e-16\n",
      " 3: -9.8402e-02 -2.0462e-01  1e-01  8e-05  1e-15\n",
      " 4: -1.1283e-01 -1.1700e-01  4e-03  3e-06  3e-16\n",
      " 5: -1.1473e-01 -1.1477e-01  4e-05  3e-08  3e-16\n",
      " 6: -1.1474e-01 -1.1474e-01  4e-07  3e-10  2e-16\n",
      " 7: -1.1474e-01 -1.1474e-01  4e-09  3e-12  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0656e+02 -3.9904e-01  7e+03  8e+01  6e-16\n",
      " 1: -4.1571e+00 -3.9899e-01  7e+01  8e-01  3e-16\n",
      " 2: -1.3323e-01 -3.9460e-01  1e+00  8e-03  3e-16\n",
      " 3: -9.9133e-02 -2.0546e-01  1e-01  8e-05  1e-15\n",
      " 4: -1.1367e-01 -1.1784e-01  4e-03  3e-06  5e-16\n",
      " 5: -1.1558e-01 -1.1562e-01  4e-05  3e-08  2e-16\n",
      " 6: -1.1560e-01 -1.1560e-01  4e-07  3e-10  3e-16\n",
      " 7: -1.1560e-01 -1.1560e-01  4e-09  3e-12  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9156e+02 -3.9690e-01  7e+03  8e+01  7e-16\n",
      " 1: -4.0037e+00 -3.9686e-01  7e+01  8e-01  5e-16\n",
      " 2: -1.2831e-01 -3.9239e-01  1e+00  8e-03  3e-16\n",
      " 3: -9.5477e-02 -2.0126e-01  1e-01  8e-05  1e-15\n",
      " 4: -1.0948e-01 -1.1363e-01  4e-03  3e-06  3e-16\n",
      " 5: -1.1131e-01 -1.1135e-01  4e-05  3e-08  2e-16\n",
      " 6: -1.1133e-01 -1.1133e-01  4e-07  3e-10  3e-16\n",
      " 7: -1.1133e-01 -1.1133e-01  4e-09  3e-12  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0206e+02 -3.9840e-01  7e+03  8e+01  6e-16\n",
      " 1: -4.1111e+00 -3.9835e-01  7e+01  8e-01  2e-16\n",
      " 2: -1.3175e-01 -3.9393e-01  1e+00  8e-03  5e-16\n",
      " 3: -9.8036e-02 -2.0420e-01  1e-01  8e-05  1e-15\n",
      " 4: -1.1241e-01 -1.1658e-01  4e-03  3e-06  4e-16\n",
      " 5: -1.1430e-01 -1.1434e-01  4e-05  3e-08  2e-16\n",
      " 6: -1.1432e-01 -1.1432e-01  4e-07  3e-10  2e-16\n",
      " 7: -1.1432e-01 -1.1432e-01  4e-09  3e-12  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0056e+02 -3.9818e-01  7e+03  8e+01  7e-16\n",
      " 1: -4.0958e+00 -3.9814e-01  7e+01  8e-01  3e-16\n",
      " 2: -1.3126e-01 -3.9371e-01  1e+00  8e-03  4e-16\n",
      " 3: -9.7671e-02 -2.0378e-01  1e-01  8e-05  1e-15\n",
      " 4: -1.1199e-01 -1.1615e-01  4e-03  3e-06  5e-16\n",
      " 5: -1.1387e-01 -1.1391e-01  4e-05  3e-08  3e-16\n",
      " 6: -1.1389e-01 -1.1389e-01  4e-07  3e-10  2e-16\n",
      " 7: -1.1389e-01 -1.1389e-01  4e-09  3e-12  2e-16\n",
      "Optimal solution found.\n",
      "\u001b[32m[I 2020-05-29 03:26:04,225]\u001b[0m Finished trial#2 with value: 0.501 with parameters: {'c': 0.0001421861317752202, 'sigma': 13.296126780421123, 'kenel': <function rbf_kernel at 0x7fdeba31ff28>, 'lam': 0.09451038921601106, 'tol': 0.09846068663224075, 'models': <class '__main__.KernelSVM'>}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:04,229]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function rbf_kernel at 0x7fdeba31ff28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:04,229]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function quadratic_kernel at 0x7fdeba335f28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:04,231]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:04,232]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR_2'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:04,232]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveLRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:04,233]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.KernelSVM'> which is of type type.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 03:26:09,764]\u001b[0m Finished trial#3 with value: 0.501 with parameters: {'c': 1.484347130010786e-11, 'sigma': 16.428598764737377, 'kenel': <function rbf_kernel at 0x7fdeba31ff28>, 'lam': 0.01380586116741167, 'tol': 0.20942077833177328, 'models': <class '__main__.ksolveRR_2'>}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:09,776]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function rbf_kernel at 0x7fdeba31ff28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:09,779]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function quadratic_kernel at 0x7fdeba335f28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:09,782]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:09,784]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR_2'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:09,796]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveLRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:09,796]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.KernelSVM'> which is of type type.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 03:26:17,834]\u001b[0m Finished trial#4 with value: 0.483 with parameters: {'c': 4.9817427513496135e-20, 'sigma': 18.063848698217715, 'kenel': <function quadratic_kernel at 0x7fdeba335f28>, 'lam': 0.0642752445036771, 'tol': 0.005237318775522299, 'models': <class '__main__.ksolveRR_2'>}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:17,839]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function rbf_kernel at 0x7fdeba31ff28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:17,840]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <function quadratic_kernel at 0x7fdeba335f28> which is of type function.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:17,842]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:17,843]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveRR_2'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:17,844]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.ksolveLRR'> which is of type type.\u001b[0m\n",
      "\u001b[33m[W 2020-05-29 03:26:17,844]\u001b[0m Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains <class '__main__.KernelSVM'> which is of type type.\u001b[0m\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0350e+02 -1.5643e-10  7e+03  8e+01  1e-16\n",
      " 1: -4.0350e+00 -6.3025e-11  7e+01  8e-01  3e-16\n",
      " 2: -4.0350e-02 -6.2990e-11  7e-01  8e-03  3e-16\n",
      " 3: -4.0350e-04 -6.2990e-11  7e-03  8e-05  3e-16\n",
      " 4: -4.0350e-06 -6.2990e-11  7e-05  8e-07  5e-16\n",
      " 5: -4.0365e-08 -6.2990e-11  7e-07  8e-09  4e-16\n",
      " 6: -4.1801e-10 -6.2979e-11  7e-09  8e-11  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0650e+02 -1.5734e-10  7e+03  8e+01  3e-16\n",
      " 1: -4.0650e+00 -6.3253e-11  7e+01  8e-01  3e-16\n",
      " 2: -4.0650e-02 -6.3054e-11  7e-01  8e-03  2e-16\n",
      " 3: -4.0650e-04 -6.3057e-11  7e-03  8e-05  3e-16\n",
      " 4: -4.0650e-06 -6.3057e-11  7e-05  8e-07  5e-16\n",
      " 5: -4.0665e-08 -6.3057e-11  7e-07  8e-09  3e-16\n",
      " 6: -4.2111e-10 -6.3046e-11  7e-09  8e-11  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9150e+02 -1.5461e-10  7e+03  8e+01  2e-16\n",
      " 1: -3.9150e+00 -6.2741e-11  7e+01  8e-01  2e-16\n",
      " 2: -3.9150e-02 -6.2721e-11  7e-01  8e-03  2e-16\n",
      " 3: -3.9150e-04 -6.2720e-11  7e-03  8e-05  3e-16\n",
      " 4: -3.9150e-06 -6.2720e-11  7e-05  8e-07  2e-16\n",
      " 5: -3.9164e-08 -6.2720e-11  7e-07  8e-09  4e-16\n",
      " 6: -4.0557e-10 -6.2709e-11  7e-09  8e-11  2e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0200e+02 -1.5643e-10  7e+03  8e+01  2e-16\n",
      " 1: -4.0200e+00 -6.3096e-11  7e+01  8e-01  3e-16\n",
      " 2: -4.0200e-02 -6.2953e-11  7e-01  8e-03  3e-16\n",
      " 3: -4.0200e-04 -6.2956e-11  7e-03  8e-05  3e-16\n",
      " 4: -4.0200e-06 -6.2956e-11  7e-05  8e-07  5e-16\n",
      " 5: -4.0214e-08 -6.2956e-11  7e-07  8e-09  5e-16\n",
      " 6: -4.1645e-10 -6.2945e-11  7e-09  8e-11  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0050e+02 -1.5461e-10  7e+03  8e+01  1e-16\n",
      " 1: -4.0050e+00 -6.2940e-11  7e+01  8e-01  3e-16\n",
      " 2: -4.0050e-02 -6.2923e-11  7e-01  8e-03  2e-16\n",
      " 3: -4.0050e-04 -6.2923e-11  7e-03  8e-05  3e-16\n",
      " 4: -4.0050e-06 -6.2923e-11  7e-05  8e-07  3e-16\n"
     ]
    }
   ],
   "source": [
    "def objective_sgd(trial):\n",
    "    c  = trial.suggest_loguniform('c', 1e-20, 2e1)\n",
    "    sigma  = trial.suggest_float('sigma', 1e-20, 20) # trial.suggest_float('sigma', 1e-5, 1e-3, log=True)\n",
    "    kenel = trial.suggest_categorical('kenel', [rbf_kernel, quadratic_kernel])\n",
    "    lam = trial.suggest_float('lam', 1e-20, 1e-1)\n",
    "    tol = trial.suggest_loguniform('tol', 1e-7, 1e-0)\n",
    "    \n",
    "    model = trial.suggest_categorical('models', [ksolveRR , ksolveRR_2, ksolveLRR, KernelSVM])\n",
    "    \n",
    "    # ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "    # ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "    # ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "    # KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "    \n",
    "    models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "              ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM'} \n",
    "#     \n",
    "#     kenel = rbf_kernel\n",
    "#     models = {ksolveRR : 'k Ridge Reg'} \n",
    "      \n",
    "#     accuracy = []\n",
    "#     for model in models:\n",
    "    accuracy = []\n",
    "    for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "        X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "        X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "\n",
    "\n",
    "#             ipdb.set_trace()\n",
    "        if models[model] == 'weigh Ridge Reg':\n",
    "            sample_weights = np.random.rand(len(y_train))\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "\n",
    "        elif models[model] == 'k Logistic Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kenel)\n",
    "        elif models[model] == 'k Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, kernel = kenel)\n",
    "        else:\n",
    "            model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kenel)\n",
    "\n",
    "        model_curr.fit()\n",
    "        accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "#             print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "        \n",
    "#         print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')\n",
    "\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective_sgd, n_trials=5500,show_progress_bar=True)\n",
    "\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.624\n",
      "Best hyperparameters: {'sigma': 0.5676751743446526, 'lam': 5.181586550863371e-06}\n",
      "time: 973 µs\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kenel = rbf_kernel\n",
    "#     models = {ksolveRR: 'k Ridge Reg'} \n",
    "# Accuracy: 0.624\n",
    "# Best hyperparameters: {'sigma': 0.5676751743446526, 'lam': 5.181586550863371e-06}\n",
    "# time: 973 µs\n",
    "\n",
    "#------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented data\n",
    "\n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-20, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-20, 1e-1)\n",
    "\n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Augmented data)\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: 0.6555\n",
    "    # Best hyperparameters: {'sigma': 4.065620491225982, 'lam': 0.013374107290659768}\n",
    "    # time: 49min 21s\n",
    "    #----\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.6575 # 0.6575000000000001\n",
    "    # Best hyperparameters: {'sigma': 4.119788517147901, 'lam': 1.2752298700618223e-14}, {'sigma': 4.063158315715049, 'lam': 8.30834772639223e-05}\n",
    "    # time: 32min 57s\n",
    "\n",
    "    \n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-3, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "\n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Non-Augmented data)\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: 0.6555\n",
    "    # Best hyperparameters: {'sigma': 4.069738272304652, 'lam': 0.053817561640154984}\n",
    "    # time: 48min 12s\n",
    "    #----\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.6575000000000001\n",
    "    # Best hyperparameters: {'sigma': 4.001185698777986, 'lam': 1.9770379950513775e-10}\n",
    "    # time: 29min 58s\n",
    "    \n",
    "\n",
    "\n",
    "# Original data\n",
    "\n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-3, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "  \n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Non-Augmented data standardize)\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.612\n",
    "    # Best hyperparameters: {'sigma': 2.8925324917718167, 'lam': 1.2575244169567934e-08}\n",
    "    # time: 28min 33s \n",
    "    #----\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: EROOR LinearAlg\n",
    "    # Best hyperparameters: \n",
    "    # time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy fold 0: 0.4875\n",
      "accurracy fold 1: 0.4725\n",
      "accurracy fold 2: 0.5475\n",
      "accurracy fold 3: 0.495\n",
      "accurracy fold 4: 0.5025\n",
      "\n",
      "Average accuracy k Ridge Reg is : 0.501\n",
      "\n",
      "time: 9.2 s\n"
     ]
    }
   ],
   "source": [
    "#     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "#               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM'\n",
    "\n",
    "# c  = \n",
    "sigma  = 4.119788517147901\n",
    "kenel = rbf_kernel\n",
    "lam = 1.2752298700618223e-14\n",
    "# tol = \n",
    "    \n",
    "#     ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "#     ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "#     ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "#     KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "\n",
    "    \n",
    "models = {ksolveRR : 'k Ridge Reg'}\n",
    "\n",
    "for model in models:\n",
    "    accuracy = []\n",
    "    for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "\n",
    "        X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "        X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "\n",
    "        if models[model] == 'weigh Ridge Reg':\n",
    "            sample_weights = np.random.rand(len(y_train))\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "        elif models[model] == 'k Logistic Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=500, tol = tol, kernel = kenel)\n",
    "        \n",
    "        elif models[model] == 'k Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, kernel = kenel)\n",
    "        else:\n",
    "            model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kenel)\n",
    "            \n",
    "        model_curr.fit()\n",
    "\n",
    "        accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "        print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "    \n",
    "    print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 525 µs\n"
     ]
    }
   ],
   "source": [
    "# 0.6535 = 0.68800\n",
    "# 0.657 = 0.69200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 881 µs\n"
     ]
    }
   ],
   "source": [
    "# # Cehckinf full model\n",
    "# model = ksolveRR(X_cross, y_cross, lam = lam, sigma = sigma, kernel = kenel)\n",
    "# # model = svm_primal_soft_to_qp(X_cross, y_cross, C=1)\n",
    "\n",
    "# model.fit()\n",
    "\n",
    "# model.Accuracy_check(X_cross, y_cross, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 393 ms\n"
     ]
    }
   ],
   "source": [
    "model = ksolveRR(X_cross, y_cross, lam = lam, sigma = sigma, kernel = kenel)\n",
    "model.fit()\n",
    "y_pred = model.predict(X_t_enc, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id\n",
       "0   0\n",
       "1   1\n",
       "2   2\n",
       "3   3\n",
       "4   4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.73 ms\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1000).reshape(-1, 1)\n",
    "sample = pd.DataFrame(data=X, columns=['Id'])\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.42 ms\n"
     ]
    }
   ],
   "source": [
    "sample['Bound'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Bound\n",
       "995  995      0\n",
       "996  996      0\n",
       "997  997      1\n",
       "998  998      1\n",
       "999  999      1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.8 ms\n"
     ]
    }
   ],
   "source": [
    "sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.12 ms\n"
     ]
    }
   ],
   "source": [
    "sample.to_csv('./ksolveRR_6575_cv_rbf_kernel_sigma_4.119788517147901_lam_1.2752298700618223e-14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
