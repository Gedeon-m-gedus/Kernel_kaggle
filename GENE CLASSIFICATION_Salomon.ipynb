{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxopt\n",
    "np.random.seed(54321)\n",
    "\n",
    "!pip install ipdb\n",
    "import ipdb\n",
    "\n",
    "!pip install ipython-autotime\n",
    "%load_ext autotime\n",
    "\n",
    "!pip install optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.8 ms\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.read_csv('./data/Xtr.csv', sep=',') #we use this dataset to train our model\n",
    "Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "X_test=pd.read_csv('./data/Xte.csv', sep=',') #we will use this data set later to validate our model\n",
    "\n",
    "# X_train_mat=pd.read_csv('./data/Xtr_mat100.csv', sep=',') #we use this dataset to train our model\n",
    "# X_test_mat=pd.read_csv('./data/Xte_mat100.csv', sep=',') #we will use this data set later to validate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 686 µs\n"
     ]
    }
   ],
   "source": [
    "# X_train=pd.read_csv('./data/train_data_preprocessing1.csv', sep=',') #we use this dataset to train our model\n",
    "# Y_train=pd.read_csv('./data/Ytr.csv', sep=',') #we use this dataset to train our model\n",
    "# X_test=pd.read_csv('./data/test_data_preprocessing1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 470 µs\n"
     ]
    }
   ],
   "source": [
    "# X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                                seq\n",
       "1995  1995  TAACTTTTGACAGGTCAGAATACAAAACTGATTTATTTACAGTGTC...\n",
       "1996  1996  ACGCCCATTCCGCCCTGCTAAGCCTCGCCCATTACATCCAGACTGC...\n",
       "1997  1997  TGGCTACTAGCTAGAGATAGCATCTCTCTGTGGACAACTCTCCAGC...\n",
       "1998  1998  CCCAGCTGTCAAAAAGCAGCCCAAAGGAAGCTCACGGTGTGCCGGC...\n",
       "1999  1999  TGCTAGTTGATGAAACAATAACTGCTAAAAGGTATACAGCCATGTC..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.8 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_train dataset is: (2000, 2)\n",
      "The shape of the Y_train dataset is: (2000, 2)\n",
      "time: 867 µs\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the X_train dataset is:',X_train.shape)\n",
    "print('The shape of the Y_train dataset is:',Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 361 µs\n"
     ]
    }
   ],
   "source": [
    "# X_train['len'] = X_train.seq.apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq\n",
       "0   0  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...\n",
       "1   1  CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...\n",
       "2   2  GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...\n",
       "3   3  GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...\n",
       "4   4  GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.17 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 709 µs\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "Alphabet_dict = dict(zip(string.ascii_uppercase, range(1,27)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 277 ms\n"
     ]
    }
   ],
   "source": [
    "#  X_train['seq_1'] = X_train.seq.apply(lambda x : (' '.join(map(str, list(x))))[0])\n",
    "for i in range(0, 101, 1):\n",
    "    X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :Alphabet_dict[x[i]])\n",
    "    X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :Alphabet_dict[x[i]])\n",
    "    \n",
    "#     X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :Alphabet_dict[x[i]])\n",
    "#     X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :Alphabet_dict[x[i]]\n",
    "\n",
    "#     X_train['seq_'+str(i)] = X_train.seq.apply(lambda x :x[i:i+3])\n",
    "#     X_test['seq_'+str(i)] = X_test.seq.apply(lambda x :x[i:i+3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>seq</th>\n",
       "      <th>seq_0</th>\n",
       "      <th>seq_1</th>\n",
       "      <th>seq_2</th>\n",
       "      <th>seq_3</th>\n",
       "      <th>seq_4</th>\n",
       "      <th>seq_5</th>\n",
       "      <th>seq_6</th>\n",
       "      <th>seq_7</th>\n",
       "      <th>seq_8</th>\n",
       "      <th>seq_9</th>\n",
       "      <th>seq_10</th>\n",
       "      <th>seq_11</th>\n",
       "      <th>seq_12</th>\n",
       "      <th>seq_13</th>\n",
       "      <th>seq_14</th>\n",
       "      <th>seq_15</th>\n",
       "      <th>seq_16</th>\n",
       "      <th>seq_17</th>\n",
       "      <th>seq_18</th>\n",
       "      <th>seq_19</th>\n",
       "      <th>seq_20</th>\n",
       "      <th>seq_21</th>\n",
       "      <th>seq_22</th>\n",
       "      <th>seq_23</th>\n",
       "      <th>seq_24</th>\n",
       "      <th>seq_25</th>\n",
       "      <th>seq_26</th>\n",
       "      <th>seq_27</th>\n",
       "      <th>seq_28</th>\n",
       "      <th>seq_29</th>\n",
       "      <th>seq_30</th>\n",
       "      <th>seq_31</th>\n",
       "      <th>seq_32</th>\n",
       "      <th>seq_33</th>\n",
       "      <th>seq_34</th>\n",
       "      <th>seq_35</th>\n",
       "      <th>seq_36</th>\n",
       "      <th>seq_37</th>\n",
       "      <th>...</th>\n",
       "      <th>seq_61</th>\n",
       "      <th>seq_62</th>\n",
       "      <th>seq_63</th>\n",
       "      <th>seq_64</th>\n",
       "      <th>seq_65</th>\n",
       "      <th>seq_66</th>\n",
       "      <th>seq_67</th>\n",
       "      <th>seq_68</th>\n",
       "      <th>seq_69</th>\n",
       "      <th>seq_70</th>\n",
       "      <th>seq_71</th>\n",
       "      <th>seq_72</th>\n",
       "      <th>seq_73</th>\n",
       "      <th>seq_74</th>\n",
       "      <th>seq_75</th>\n",
       "      <th>seq_76</th>\n",
       "      <th>seq_77</th>\n",
       "      <th>seq_78</th>\n",
       "      <th>seq_79</th>\n",
       "      <th>seq_80</th>\n",
       "      <th>seq_81</th>\n",
       "      <th>seq_82</th>\n",
       "      <th>seq_83</th>\n",
       "      <th>seq_84</th>\n",
       "      <th>seq_85</th>\n",
       "      <th>seq_86</th>\n",
       "      <th>seq_87</th>\n",
       "      <th>seq_88</th>\n",
       "      <th>seq_89</th>\n",
       "      <th>seq_90</th>\n",
       "      <th>seq_91</th>\n",
       "      <th>seq_92</th>\n",
       "      <th>seq_93</th>\n",
       "      <th>seq_94</th>\n",
       "      <th>seq_95</th>\n",
       "      <th>seq_96</th>\n",
       "      <th>seq_97</th>\n",
       "      <th>seq_98</th>\n",
       "      <th>seq_99</th>\n",
       "      <th>seq_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                                seq  ...  seq_99  seq_100\n",
       "0   0  GAGGGGCTGGGGAGGGGGCTGGCCCAGAGGCACCAGACTCTGCAGA...  ...       1        7\n",
       "1   1  CGGCCTGGGGGCCACATGTGAGTGCTTACCTGTGTGGGGATGAGGG...  ...       7        7\n",
       "2   2  GACAACGCCGCTGTCAGCCGCCTTCGACTCACCTGGGAGGTGATGA...  ...       7       20\n",
       "3   3  GCCTCCCTTGGCACCACGGGAGACCAGTTTTGGAGGGGCGGGGCTG...  ...       1        1\n",
       "4   4  GCACTACTACACCCATTGCTGTAATAGTAAGTGCCGGTGCCTTCAC...  ...       3        3\n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about counting number of different caracters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 520 µs\n"
     ]
    }
   ],
   "source": [
    "# A, C, G, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 426 µs\n"
     ]
    }
   ],
   "source": [
    "# X_train.seq.apply(lambda x : np.unique(x[:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.11 ms\n"
     ]
    }
   ],
   "source": [
    "X = X_train.drop(['seq', 'Id'], axis=1)\n",
    "X_t = X_test.drop(['seq', 'Id'], axis=1)\n",
    "y = Y_train.Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.39 ms\n"
     ]
    }
   ],
   "source": [
    "# class LogisticRegressionBinary():\n",
    "#     def __init__(self, lr=0.1, num_iter=100000, batch_size=1, verbose=False):\n",
    "#         self.lr = lr\n",
    "#         self.num_iter = num_iter\n",
    "#         self.batch_size = batch_size\n",
    "#         self.verbose = verbose\n",
    "    \n",
    "#     def __add_intercept(self, X):\n",
    "#         intercept = np.ones((X.shape[0], 1))\n",
    "#         return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "#     def __sigmoid_func(self, z):\n",
    "#         return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "#     def __loss(self, h, y):\n",
    "#         return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "#     def fit(self, X, y):\n",
    "#         y = self.trans_y(y)\n",
    "#         X = self.__add_intercept(X)\n",
    "#         self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "#         for i in range(self.num_iter):\n",
    "#             z = np.dot(X, self.theta)\n",
    "#             h = self.__sigmoid_func(z)\n",
    "                        \n",
    "#             rand = np.random.choice(y.size, self.batch_size).squeeze()\n",
    "#             gradient = np.dot(X[rand].T, (h[rand] - y[rand]))/y.size   \n",
    "        \n",
    "#             self.theta -= self.lr * gradient\n",
    "#             #print('theta and grad',self.theta.shape ,  gradient.shape )\n",
    "#             if(self.verbose == True and i % 100 == 0):\n",
    "#                 z = np.dot(X, self.theta)\n",
    "#                 h = self.__sigmoid(z)\n",
    "#                 print(f'loss: {self.__loss(h, y)} \\t')\n",
    "    \n",
    "#     def predict_probability(self, X):\n",
    "#         X = self.__add_intercept(X)\n",
    "    \n",
    "#         return self.__sigmoid_func(np.dot(X, self.theta))\n",
    "    \n",
    "#     def predict(self, X, threshold=.5):\n",
    "#           return np.where(self.predict_probability(X) >= 0.5, 1, 0)\n",
    "        \n",
    "          \n",
    "#     def Accuracy_check(self,X,y):\n",
    "#         return np.mean(self.predict(X)==y)\n",
    "    \n",
    "#     def trans_y(self, y):\n",
    "#         if isinstance(y, pd.Series):\n",
    "#             y = y.values\n",
    "#         if isinstance(y, list):\n",
    "#             y = np.array(y)\n",
    "#         return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 98.4 ms\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression (RR)\n",
    "\n",
    "class solveRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "            \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        A = (X.T.dot(X)) + np.eye(p)*lam*n\n",
    "        b = X.T.dot(y)\n",
    "        \n",
    "        self.beta = np.linalg.solve(A, b)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Weighted Ridge Regression (WRR)\n",
    "class solveWRR():\n",
    "    def __init__(self, X, y, w, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.w = w\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        w = self.w\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == len(w) == n)\n",
    "\n",
    "        y1 = np.sqrt(w) * y\n",
    "        X1 = (np.sqrt(w) * X.T).T\n",
    "        \n",
    "        # Hint:\n",
    "        # Find y1 and X1 such that:\n",
    "        \n",
    "        self.beta = solveRR(X1, y1, lam).fit()\n",
    "                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)\n",
    "    \n",
    "\n",
    "# Logistic Ridge Regression (LRR)\n",
    "class solveLRR():\n",
    "    def __init__(self, X, y, lam=0.1):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "    \n",
    "        lam = self.lam \n",
    "        max_iter = 50\n",
    "        eps = 1e-3\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Initialize\n",
    "        self.beta = np.zeros(p)\n",
    "\n",
    "        # Hint: Use IRLS\n",
    "        for i in range(max_iter):\n",
    "            beta_old = self.beta\n",
    "            f = X.dot(beta_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*f)\n",
    "            self.beta = solveWRR(X, z, w, 2*lam).fit()\n",
    "            # Break condition (achieved convergence)\n",
    "            #if np.sum((beta-beta_old)**2) < eps:\n",
    "            #    break                \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        return np.where(X.dot(self.beta) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.2 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "### Functions for you to fill in ###\n",
    "\n",
    "def polynomial_kernel(X, Y, c, p):\n",
    "    \"\"\"\n",
    "        Compute the polynomial kernel between two matrices X and Y::\n",
    "            K(x, y) = (<x, y> + c)^p\n",
    "        for each pair of rows x in X and y in Y.\n",
    "\n",
    "        Args:\n",
    "            X - (n, d) NumPy array (n datapoints each with d features)\n",
    "            Y - (m, d) NumPy array (m datapoints each with d features)\n",
    "            c - a coefficient to trade off high-order and low-order terms (scalar)\n",
    "            p - the degree of the polynomial kernel\n",
    "\n",
    "        Returns:\n",
    "            kernel_matrix - (n, m) Numpy array containing the kernel matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError\n",
    "    kernel_matrix = (X.dot(Y.T) + c)**p\n",
    "    \n",
    "    return kernel_matrix\n",
    "\n",
    "\n",
    "def rbf_kernel_2(X, Y, gamma):\n",
    "    \"\"\"\n",
    "        Compute the Gaussian RBF kernel between two matrices X and Y::\n",
    "            K(x, y) = exp(-gamma ||x-y||^2)\n",
    "        for each pair of rows x in X and y in Y.\n",
    "\n",
    "        Args:\n",
    "            X - (n, d) NumPy array (n datapoints each with d features)\n",
    "            Y - (m, d) NumPy array (m datapoints each with d features)\n",
    "            gamma - the gamma parameter of gaussian function (scalar)\n",
    "\n",
    "        Returns:\n",
    "            kernel_matrix - (n, m) Numpy array containing the kernel matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError\n",
    "    n, d = X.shape\n",
    "    m = Y.shape[0]\n",
    "    \n",
    "    kernel_matrix = X**2 @ np.ones((d,m)) + np.ones((n,d)) @ Y.T**2 - 2*(X @ Y.T)\n",
    "    kernel_matrix = np.exp(-gamma*kernel_matrix)\n",
    "    \n",
    "    return kernel_matrix\n",
    "\n",
    "\n",
    "def rbf_kernel_element_wise(x, y, sigma=1):\n",
    "    '''\n",
    "    returns the RBF (Gaussian) kernel k(x, y)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    x and y are p-dimensional vectors \n",
    "    '''\n",
    "    K = np.exp(- np.sum((x - y)**2) / (2 * sigma ** 2))\n",
    "    return K\n",
    "\n",
    "def rbf_kernel(X1, X2, sigma=10):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis=-1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis=-1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    return K\n",
    "\n",
    "def sigma_from_median(X):\n",
    "    '''\n",
    "    Returns the median of ||Xi-Xj||\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    X: (n, p) matrix\n",
    "    '''\n",
    "    pairwise_diff = X[:, :, None] - X[:, :, None].T\n",
    "    pairwise_diff *= pairwise_diff\n",
    "    euclidean_dist = np.sqrt(pairwise_diff.sum(axis=1))\n",
    "    return np.median(euclidean_dist)\n",
    "\n",
    "# def laplace(X1, X2, alpha=10):\n",
    "#     return np.exp(-alpha*np.abs(X1-X2))\n",
    "\n",
    "# def polynomial(X1, X2, d=2):\n",
    "#     return (X1.dot(X2.T) +1)**d\n",
    "\n",
    "def linear_kernel(X1, X2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the linear kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return X1.dot(X2.T)\n",
    "\n",
    "def quadratic_kernel(X1, X2, power=2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    where K is the quadratic kernel\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    return (1 + linear_kernel(X1, X2))**power\n",
    "\n",
    "def rbf_poly_kernel(X1, X2, sigma=10, d=2):\n",
    "    '''\n",
    "    Returns the kernel matrix K(X1_i, X2_j): size (n1, n2)\n",
    "    \n",
    "    Input:\n",
    "    ------\n",
    "    X1: an (n1, p) matrix\n",
    "    X2: an (n2, p) matrix\n",
    "    '''\n",
    "    # For loop with rbf_kernel_element works but is slow in python\n",
    "    # Use matrix operations!\n",
    "    X2_norm = np.sum(X2 ** 2, axis=-1)\n",
    "    X1_norm = np.sum(X1 ** 2, axis=-1)\n",
    "    gamma = 1 / (2 * sigma ** 2)\n",
    "    K = np.exp(- gamma * (X1_norm[:, None] + X2_norm[None, :] - 2 * np.dot(X1, X2.T)))\n",
    "    \n",
    "    return K+(X1.dot(X2.T) +1)**d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "class ksolveRR_2():\n",
    "    def __init__(self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.sigma = sigma\n",
    "        self.kernel = kernel\n",
    "        self.sample_weights = sample_weights\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        if self.sample_weights is not None:\n",
    "            self.X *= self.sample_weights[:, None]\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "        A = self.kernel(X, X, self.sigma)+n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.7 ms\n"
     ]
    }
   ],
   "source": [
    "class ksolveRR():\n",
    "    def __init__(self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel):\n",
    "        self.beta = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        self.sigma = sigma\n",
    "        self.kernel = kernel\n",
    "            \n",
    "    \n",
    "    def fit(self):\n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        lam = self.lam \n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        \n",
    "        if self.sigma is None:\n",
    "            self.sigma = sigma_from_median(X)\n",
    "            \n",
    "        A = self.kernel(X, X, self.sigma)+n*self.lam*np.eye(n)\n",
    "        self.alpha = np.linalg.solve(A, y)\n",
    "        \n",
    "        return self.beta\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold=.5):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.5 ms\n"
     ]
    }
   ],
   "source": [
    "import ipdb\n",
    "# Logistic Ridge Regression (LRR)\n",
    "class ksolveLRR():\n",
    "    def __init__(self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.lam = lam\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        \n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "\n",
    "        sigmoid = lambda a: 1/(1 + np.exp(-a))\n",
    "        \n",
    "        K = self.kernel(X, X, self.sigma)\n",
    "\n",
    "        # Initialize\n",
    "        alpha = np.zeros(n)\n",
    "        \n",
    "        # Hint: Use IRLS\n",
    "        for n_iter in range(self.max_iter):\n",
    "            alpha_old = alpha\n",
    "            f = K.dot(alpha_old)\n",
    "            w = sigmoid(f) * sigmoid(-f)\n",
    "            z = f + y / sigmoid(y*(f))\n",
    "            \n",
    "            alpha = ksolveRR_2(X, y, lam = 2*self.lam, \\\n",
    "                               sigma=self.sigma, sample_weights = w).fit().alpha\n",
    "            \n",
    "            # Break condition (achieved convergence)\n",
    "            if np.sum((alpha-alpha_old)**2) < self.tol:\n",
    "                break  \n",
    "                \n",
    "                \n",
    "        self.n_iter = n_iter\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where(K_x.dot(self.alpha) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "# You don't need to look at this, this is just to adapt our matrices\n",
    "# to the solver being used\n",
    "solver='cvxopt'\n",
    "\n",
    "import cvxopt\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    #cvxopt.solvers.options['show_progress'] = False\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices, options={'show_progress': False})\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = cvxopt_qp\n",
    "\n",
    "def quadprog_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "    qp_G = .5 * (P + P.T)   # make sure P is symmetric\n",
    "    qp_a = -q\n",
    "    if A is not None:\n",
    "        qp_C = -np.vstack([A, G]).T\n",
    "        qp_b = -np.hstack([b, h])\n",
    "        meq = A.shape[0]\n",
    "    else:  # no equality constraint\n",
    "        qp_C = - G.T\n",
    "        qp_b = - h\n",
    "        meq = 0\n",
    "    return quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)[0]\n",
    "\n",
    "def cvxopt_qp(P, q, G, h, A, b):\n",
    "    P = .5 * (P + P.T)\n",
    "    cvx_matrices = [\n",
    "        cvxopt.matrix(M) if M is not None else None for M in [P, q, G, h, A, b] \n",
    "    ]\n",
    "    solution = cvxopt.solvers.qp(*cvx_matrices)\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "solve_qp = {'quadprog': quadprog_solve_qp, 'cvxopt': cvxopt_qp}[solver]\n",
    "\n",
    "def svm_dual_soft_to_qp_kernel(K, y, C=1):\n",
    "    n = K.shape[0]\n",
    "    assert (len(y) == n)\n",
    "        \n",
    "    # Dual formulation, soft margin\n",
    "    P = np.diag(y).dot(K).dot(np.diag(y))\n",
    "    # As a regularization, we add epsilon * identity to P\n",
    "    eps = 1e-12\n",
    "    P += eps * np.eye(n)\n",
    "    q = - np.ones(n)\n",
    "    G = np.vstack([-np.eye(n), np.eye(n)])\n",
    "    h = np.hstack([np.zeros(n), C * np.ones(n)])\n",
    "    A = y[np.newaxis, :]\n",
    "    A = A.astype('float')\n",
    "    b = np.array([0.])\n",
    "    return P, q, G, h, A, b\n",
    "\n",
    "# SVM primal soft\n",
    "class KernelSVM():\n",
    "    def __init__(self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel):\n",
    "        self.alpha = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.lam = lam        \n",
    "        self.sigma = sigma\n",
    "        self.tol = tol\n",
    "    \n",
    "    def fit(self):\n",
    "        \n",
    "        X = self.X\n",
    "        y = self.y\n",
    "        C = self.C\n",
    "        \n",
    "        n, p = X.shape\n",
    "        assert (len(y) == n)\n",
    "        K = self.kernel(X, X, self.sigma)\n",
    "        \n",
    "        # Solve dual problem\n",
    "        self.alpha = solve_qp(*svm_dual_soft_to_qp_kernel(K, y, C=self.C))\n",
    "        \n",
    "        \n",
    "       # Compute support vectors and bias b\n",
    "        sv = np.logical_and((self.alpha>self.tol), (self.C - self.alpha > self.tol))\n",
    "        self.bias = y[sv] - K[sv].dot(self.alpha*y)\n",
    "        self.bias =  self.bias.mean()\n",
    "\n",
    "        self.support_vector_indices = np.nonzero(sv)[0]\n",
    "        \n",
    "        return self\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, X, threshold):\n",
    "#         y_pred = self.kernel(X, self.X_).dot(self.alphas* seld.y_)\n",
    "        K_x = self.kernel(X, self.X, self.sigma)\n",
    "        return np.where((K_x.dot(self.alpha * self.y) +  self.bias) >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "    def Accuracy_check(self,X, y, threshold=.5):\n",
    "        return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.8 ms\n"
     ]
    }
   ],
   "source": [
    "# # Logistic Ridge Regression (LRR)\n",
    "# class perceptron():\n",
    "#     def __init__(self, X, y, iteration=100):\n",
    "#         self.theta = np.zeros(len(X))\n",
    "#         self.X = X\n",
    "#         self.y = y\n",
    "#         self.iteration = iteration\n",
    "#         self.theta_0 = 0\n",
    "    \n",
    "#     def fit(self):\n",
    "        \n",
    "#         X = self.X\n",
    "#         y = self.y\n",
    "        \n",
    "#         n, p = X.shape\n",
    "#         assert (len(y) == n)\n",
    "        \n",
    "#         for it in range(self.iteration):\n",
    "#             for i in range(len(y)):\n",
    "#                 if y[i]*(np.dot(self.theta, X[i]) + self.theta_0)<= 0 :\n",
    "#                     self.theta = self.theta + (np.dot(y[i], X[i]))\n",
    "#                     self.theta_0 += y[i]\n",
    "    \n",
    "        \n",
    "#     def predict(self, X, threshold):\n",
    "#         return np.where(X.dot(self.self.theta)+self.theta_0 >= threshold, 1, 0)\n",
    "        \n",
    "          \n",
    "#     def Accuracy_check(self,X, y, threshold=.5):\n",
    "#         return np.mean(self.predict(X, threshold)==y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25.7 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import TransformerM\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.01 ms\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = CountVectorizer(max_features=2000)\n",
    "# vectorizer.fit_transform(X[:10])\n",
    "# # vectorizer.get_feature_names()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 89.1 ms\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=5)\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "# X_cross = X.values\n",
    "# X_t = X_t.values\n",
    "\n",
    "y_cross = y.values\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_cross = vectorizer.fit_transform(X)\n",
    "\n",
    "# X_cross = onehot_encoder.fit_transform(X.values[:, :101])\n",
    "# X_t_enc = onehot_encoder.fit_transform(X_t.values[:, :101])\n",
    "\n",
    "X_cross = onehot_encoder.fit_transform(X)\n",
    "X_t_enc = onehot_encoder.fit_transform(X_t)\n",
    "\n",
    "\n",
    "# X_cross = transformer.fit_transform(X.values)\n",
    "# X_t_enc = transformer.fit_transform(X_t.values)\n",
    "\n",
    "\n",
    "# scaler = MinMaxScaler()#MinMaxScaler() # StandardScaler()\n",
    "# scaler.fit(X_cross)\n",
    "\n",
    "# X_cross = scaler.transform(X_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 625 µs\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.01 ms\n"
     ]
    }
   ],
   "source": [
    "# def feature_selector(X):\n",
    "#     #sel = VarianceThreshold()\n",
    "#     sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "#     sel.fit_transform(X)\n",
    "#     return X\n",
    "# def best_feature_selector(X,y,num_features=50):\n",
    "#     #print(X.shape)\n",
    "#     features = SelectKBest(chi2, k=num_features).fit(X, y)\n",
    "#     #print(X_new.shape)\n",
    "#     return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 101)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.09 ms\n"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 587 µs\n"
     ]
    }
   ],
   "source": [
    "# trans = best_feature_selector(X, y, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 638 µs\n"
     ]
    }
   ],
   "source": [
    "# X = trans.transform(X)\n",
    "# X_t = trans.transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 101)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.96 ms\n"
     ]
    }
   ],
   "source": [
    "X.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 101)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.63 ms\n"
     ]
    }
   ],
   "source": [
    "X_t.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 404)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.83 ms\n"
     ]
    }
   ],
   "source": [
    "X_t_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 404)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.96 ms\n"
     ]
    }
   ],
   "source": [
    "X_cross.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.48 ms\n"
     ]
    }
   ],
   "source": [
    "# PRUNNING TRIAL \n",
    "\n",
    "# def objective_sgd(trial):\n",
    "# #     c  = trial.suggest_loguniform('c', 1e-20, 30)\n",
    "#     sigma  = trial.suggest_loguniform('sigma', 1e-3, 20) # trial.suggest_float('sigma', 1e-5, 1e-3, log=True)\n",
    "# #     kenel = trial.suggest_categorical('kenel', [rbf_kernel, quadratic_kernel])\n",
    "#     lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "# #     tol = trial.suggest_loguniform('tol', 1e-10, 1e-0)\n",
    "    \n",
    "#     # ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "#     # ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "#     # ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "#     # KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "    \n",
    "# #     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "# #               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM'} \n",
    "# #     \n",
    "#     kenel = rbf_kernel\n",
    "#     models = {ksolveRR: 'k Ridge Reg'} \n",
    "      \n",
    "# #     accuracy = []\n",
    "#     for model in models:\n",
    "#         accuracy = []\n",
    "#         for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "#             X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "#             X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "            \n",
    "            \n",
    "# #             ipdb.set_trace()\n",
    "#             if models[model] == 'weigh Ridge Reg':\n",
    "#                 sample_weights = np.random.rand(len(y_train))\n",
    "#                 model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "                \n",
    "#             elif models[model] == 'k Logistic Ridge Reg':\n",
    "#                 model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kenel)\n",
    "#             elif models[model] == 'k Ridge Reg':\n",
    "#                 model_curr = model(X_train, y_train, lam = lam, sigma = sigma, kernel = kenel)\n",
    "#             else:\n",
    "#                 model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kenel)\n",
    "            \n",
    "#             model_curr.fit()\n",
    "            \n",
    "#             acc = model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5)\n",
    "#             accuracy.append(acc)\n",
    "            \n",
    "#             intermediate_value = acc\n",
    "#             trial.report(intermediate_value, i)\n",
    "        \n",
    "# #             print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "        \n",
    "# #         print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')\n",
    "\n",
    "#     return np.mean(accuracy)\n",
    "\n",
    "# # Set up the median stopping rule as the pruning condition.\n",
    "# # study = optuna.create_study(pruner=optuna.pruners.MedianPruner())\n",
    "# study = optuna.create_study(pruner=optuna.pruners.MedianPruner(), sampler=sampler, direction='maximize')\n",
    "\n",
    "# # sampler = optuna.samplers.TPESampler()    # sampler = SimulatedAnnealingSampler()\n",
    "# # study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "# study.optimize(func=objective_sgd, n_trials=1500,show_progress_bar=True)\n",
    "\n",
    "\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print('Accuracy: {}'.format(trial.value))\n",
    "# print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optuna/_experimental.py:90: ExperimentalWarning:\n",
      "\n",
      "Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31b19a2f1e340719209f4d1fffaee1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-05-29 01:00:18,027]\u001b[0m Finished trial#0 with value: 0.501 with parameters: {'sigma': 12.989484220554361, 'lam': 0.07033641948771067}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:19,254]\u001b[0m Finished trial#1 with value: 0.501 with parameters: {'sigma': 0.630587644061329, 'lam': 0.028350242323757848}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:20,463]\u001b[0m Finished trial#2 with value: 0.501 with parameters: {'sigma': 12.700317554269386, 'lam': 0.09733433160934717}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:21,666]\u001b[0m Finished trial#3 with value: 0.501 with parameters: {'sigma': 2.7047166866381422, 'lam': 0.03350372434101423}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:22,883]\u001b[0m Finished trial#4 with value: 0.501 with parameters: {'sigma': 17.98481577885221, 'lam': 0.08478002512033779}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:24,100]\u001b[0m Finished trial#5 with value: 0.501 with parameters: {'sigma': 14.464525533904961, 'lam': 0.09062898078233012}. Best is trial#0 with value: 0.501.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:25,312]\u001b[0m Finished trial#6 with value: 0.5559999999999999 with parameters: {'sigma': 10.437008744971836, 'lam': 0.026292442940797345}. Best is trial#6 with value: 0.5559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:26,540]\u001b[0m Finished trial#7 with value: 0.501 with parameters: {'sigma': 10.263517637362336, 'lam': 0.05332145268526935}. Best is trial#6 with value: 0.5559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:27,751]\u001b[0m Finished trial#8 with value: 0.501 with parameters: {'sigma': 15.369496752593935, 'lam': 0.0925188490880106}. Best is trial#6 with value: 0.5559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:28,967]\u001b[0m Finished trial#9 with value: 0.6315000000000001 with parameters: {'sigma': 13.1431989992268, 'lam': 0.005173325025282183}. Best is trial#9 with value: 0.6315000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:30,182]\u001b[0m Finished trial#10 with value: 0.6285000000000001 with parameters: {'sigma': 5.590703220976329, 'lam': 0.005517636735986466}. Best is trial#9 with value: 0.6315000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:31,417]\u001b[0m Finished trial#11 with value: 0.6515 with parameters: {'sigma': 5.1032301199562164, 'lam': 0.00020459409915031534}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:32,709]\u001b[0m Finished trial#12 with value: 0.6475000000000001 with parameters: {'sigma': 5.661698658550788, 'lam': 0.00045983449513317676}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:33,927]\u001b[0m Finished trial#13 with value: 0.5215 with parameters: {'sigma': 5.784920631159802, 'lam': 0.013026268307566006}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:35,149]\u001b[0m Finished trial#14 with value: 0.641 with parameters: {'sigma': 6.774113855739593, 'lam': 0.0009341925129090468}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:36,373]\u001b[0m Finished trial#15 with value: 0.501 with parameters: {'sigma': 2.578496113252552, 'lam': 0.016916986896119358}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:37,613]\u001b[0m Finished trial#16 with value: 0.501 with parameters: {'sigma': 8.173497197458643, 'lam': 0.0407590737984113}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:38,828]\u001b[0m Finished trial#17 with value: 0.501 with parameters: {'sigma': 3.433030441603091, 'lam': 0.050292306556736145}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:40,087]\u001b[0m Finished trial#18 with value: 0.501 with parameters: {'sigma': 0.06140277469886524, 'lam': 0.016848197813737097}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:41,309]\u001b[0m Finished trial#19 with value: 0.501 with parameters: {'sigma': 8.134175824253903, 'lam': 0.06447483384594023}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:42,524]\u001b[0m Finished trial#20 with value: 0.501 with parameters: {'sigma': 4.4154394067277325, 'lam': 0.010496714806346667}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:43,754]\u001b[0m Finished trial#21 with value: 0.639 with parameters: {'sigma': 7.520861279802294, 'lam': 0.0015716101826064649}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:44,988]\u001b[0m Finished trial#22 with value: 0.644 with parameters: {'sigma': 6.258178066832411, 'lam': 0.0013536050823006063}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:46,224]\u001b[0m Finished trial#23 with value: 0.501 with parameters: {'sigma': 1.619770187486342, 'lam': 0.00011005593261750063}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:47,482]\u001b[0m Finished trial#24 with value: 0.501 with parameters: {'sigma': 4.487681394101455, 'lam': 0.01898019842569642}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:48,725]\u001b[0m Finished trial#25 with value: 0.569 with parameters: {'sigma': 9.325522159056224, 'lam': 0.02312574295567756}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:49,951]\u001b[0m Finished trial#26 with value: 0.609 with parameters: {'sigma': 6.0286789596044486, 'lam': 0.009220439710976787}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:51,168]\u001b[0m Finished trial#27 with value: 0.501 with parameters: {'sigma': 4.356022882304412, 'lam': 0.03515028370034414}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:52,375]\u001b[0m Finished trial#28 with value: 0.634 with parameters: {'sigma': 9.057398326588547, 'lam': 8.550282288432056e-05}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:53,604]\u001b[0m Finished trial#29 with value: 0.501 with parameters: {'sigma': 1.63675814727865, 'lam': 0.06732616931223773}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:54,828]\u001b[0m Finished trial#30 with value: 0.624 with parameters: {'sigma': 11.657548270266616, 'lam': 0.009614739453245315}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:56,044]\u001b[0m Finished trial#31 with value: 0.6409999999999999 with parameters: {'sigma': 7.060161927086446, 'lam': 0.0010031124427652867}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:57,262]\u001b[0m Finished trial#32 with value: 0.6399999999999999 with parameters: {'sigma': 6.609099679618306, 'lam': 0.00014069822637059892}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:58,479]\u001b[0m Finished trial#33 with value: 0.5094999999999998 with parameters: {'sigma': 4.759220162765029, 'lam': 0.006057599192714967}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:00:59,713]\u001b[0m Finished trial#34 with value: 0.501 with parameters: {'sigma': 3.393848068086824, 'lam': 0.015495570637607032}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:00,930]\u001b[0m Finished trial#35 with value: 0.5225 with parameters: {'sigma': 7.060523848132186, 'lam': 0.022166348317396233}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:02,139]\u001b[0m Finished trial#36 with value: 0.501 with parameters: {'sigma': 5.354923451610524, 'lam': 0.03171334693453118}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:03,382]\u001b[0m Finished trial#37 with value: 0.501 with parameters: {'sigma': 8.844903080385853, 'lam': 0.04162263531254191}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:04,595]\u001b[0m Finished trial#38 with value: 0.632 with parameters: {'sigma': 10.92648399037134, 'lam': 0.005167928537132882}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:05,808]\u001b[0m Finished trial#39 with value: 0.501 with parameters: {'sigma': 1.7849102439186484, 'lam': 0.07934350061831591}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:07,038]\u001b[0m Finished trial#40 with value: 0.501 with parameters: {'sigma': 3.3844778661166743, 'lam': 0.011894818163827191}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:08,257]\u001b[0m Finished trial#41 with value: 0.6399999999999999 with parameters: {'sigma': 6.820665876491894, 'lam': 0.00015771544894093803}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:09,493]\u001b[0m Finished trial#42 with value: 0.6385000000000001 with parameters: {'sigma': 7.682888054169705, 'lam': 0.004977381792874081}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:10,729]\u001b[0m Finished trial#43 with value: 0.6425 with parameters: {'sigma': 6.156528416288988, 'lam': 0.00030822265266982685}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:11,938]\u001b[0m Finished trial#44 with value: 0.6115 with parameters: {'sigma': 5.9089140376752125, 'lam': 0.007949786696738004}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:13,156]\u001b[0m Finished trial#45 with value: 0.632 with parameters: {'sigma': 5.0667949773584535, 'lam': 0.003489458879529858}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:14,411]\u001b[0m Finished trial#46 with value: 0.5599999999999999 with parameters: {'sigma': 19.588816740044827, 'lam': 0.02175091121322022}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:15,663]\u001b[0m Finished trial#47 with value: 0.5624999999999999 with parameters: {'sigma': 6.33331278901037, 'lam': 0.01375401173569667}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:16,899]\u001b[0m Finished trial#48 with value: 0.528 with parameters: {'sigma': 8.324067996011902, 'lam': 0.02698850860050891}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:18,144]\u001b[0m Finished trial#49 with value: 0.501 with parameters: {'sigma': 3.7172194673007484, 'lam': 0.011598082506291203}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:19,394]\u001b[0m Finished trial#50 with value: 0.501 with parameters: {'sigma': 2.433706297254973, 'lam': 0.00643888563468003}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:20,644]\u001b[0m Finished trial#51 with value: 0.642 with parameters: {'sigma': 7.052999164926935, 'lam': 0.0008460326260761279}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:21,882]\u001b[0m Finished trial#52 with value: 0.6479999999999999 with parameters: {'sigma': 5.589531879467601, 'lam': 0.0005545948464728885}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:23,096]\u001b[0m Finished trial#53 with value: 0.501 with parameters: {'sigma': 5.313331580169411, 'lam': 0.05764730572535608}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:24,355]\u001b[0m Finished trial#54 with value: 0.6340000000000001 with parameters: {'sigma': 9.867900663622121, 'lam': 0.003080411412740175}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:25,591]\u001b[0m Finished trial#55 with value: 0.631 with parameters: {'sigma': 7.825094840696234, 'lam': 0.008551809377478478}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:26,828]\u001b[0m Finished trial#56 with value: 0.501 with parameters: {'sigma': 3.891677018757085, 'lam': 0.017881042038899952}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:28,063]\u001b[0m Finished trial#57 with value: 0.643 with parameters: {'sigma': 5.840849240609338, 'lam': 0.003575879814068773}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:29,299]\u001b[0m Finished trial#58 with value: 0.501 with parameters: {'sigma': 0.7433593006908721, 'lam': 0.014171606162993181}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:30,536]\u001b[0m Finished trial#59 with value: 0.501 with parameters: {'sigma': 2.8055267703946876, 'lam': 0.0033376809803197364}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:31,776]\u001b[0m Finished trial#60 with value: 0.609 with parameters: {'sigma': 5.876587616119991, 'lam': 0.00808272911247648}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:33,027]\u001b[0m Finished trial#61 with value: 0.6495 with parameters: {'sigma': 4.774598959271426, 'lam': 0.0006159222172060316}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:34,260]\u001b[0m Finished trial#62 with value: 0.505 with parameters: {'sigma': 4.368543156749123, 'lam': 0.003631691688191856}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:35,518]\u001b[0m Finished trial#63 with value: 0.6475 with parameters: {'sigma': 5.083626391947694, 'lam': 0.0008802066718254413}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:36,729]\u001b[0m Finished trial#64 with value: 0.501 with parameters: {'sigma': 4.845857741989355, 'lam': 0.09964003560676925}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:38,086]\u001b[0m Finished trial#65 with value: 0.501 with parameters: {'sigma': 3.9513917022213474, 'lam': 0.010729254307456172}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:39,318]\u001b[0m Finished trial#66 with value: 0.501 with parameters: {'sigma': 2.8558384033753743, 'lam': 1.1695729948303342e-05}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:40,552]\u001b[0m Finished trial#67 with value: 0.5855 with parameters: {'sigma': 5.394548216834388, 'lam': 0.006965005239595008}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:41,767]\u001b[0m Finished trial#68 with value: 0.613 with parameters: {'sigma': 4.740379582676917, 'lam': 0.0030455075351844426}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:42,989]\u001b[0m Finished trial#69 with value: 0.501 with parameters: {'sigma': 2.1346470989524198, 'lam': 0.015304362903026105}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:44,227]\u001b[0m Finished trial#70 with value: 0.5069999999999999 with parameters: {'sigma': 6.377412167555626, 'lam': 0.020225580614027724}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:45,450]\u001b[0m Finished trial#71 with value: 0.6455 with parameters: {'sigma': 5.8974990920905626, 'lam': 0.00038262817590140746}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:46,697]\u001b[0m Finished trial#72 with value: 0.6154999999999999 with parameters: {'sigma': 5.534471355864231, 'lam': 0.006088736146844221}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:47,927]\u001b[0m Finished trial#73 with value: 0.6435 with parameters: {'sigma': 3.9832730740599636, 'lam': 0.00028093511964430743}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:49,153]\u001b[0m Finished trial#74 with value: 0.501 with parameters: {'sigma': 1.0005538699058834, 'lam': 0.00016643332300114613}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:50,385]\u001b[0m Finished trial#75 with value: 0.501 with parameters: {'sigma': 3.308237711796588, 'lam': 0.010180001155893402}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:51,613]\u001b[0m Finished trial#76 with value: 0.6375 with parameters: {'sigma': 7.401979254382642, 'lam': 0.0002496648729102599}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:52,854]\u001b[0m Finished trial#77 with value: 0.501 with parameters: {'sigma': 4.040721597859678, 'lam': 0.008542542457617812}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:54,081]\u001b[0m Finished trial#78 with value: 0.646 with parameters: {'sigma': 5.127476491281166, 'lam': 0.0028819048067720275}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:55,319]\u001b[0m Finished trial#79 with value: 0.501 with parameters: {'sigma': 4.834319306049611, 'lam': 0.07866064900190169}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:56,545]\u001b[0m Finished trial#80 with value: 0.5959999999999999 with parameters: {'sigma': 6.632547835868955, 'lam': 0.012721687958612254}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:57,768]\u001b[0m Finished trial#81 with value: 0.5279999999999999 with parameters: {'sigma': 4.255119704499695, 'lam': 0.0024151470010635684}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:01:59,031]\u001b[0m Finished trial#82 with value: 0.501 with parameters: {'sigma': 3.018989662689419, 'lam': 0.0055576478488187425}. Best is trial#11 with value: 0.6515.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:00,241]\u001b[0m Finished trial#83 with value: 0.6515000000000001 with parameters: {'sigma': 5.113596856298649, 'lam': 0.0002374889146411573}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:01,563]\u001b[0m Finished trial#84 with value: 0.6205 with parameters: {'sigma': 5.344582504330619, 'lam': 0.005069554296631586}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:02,791]\u001b[0m Finished trial#85 with value: 0.64 with parameters: {'sigma': 6.3395790077026435, 'lam': 0.002232900813644457}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:04,019]\u001b[0m Finished trial#86 with value: 0.6305 with parameters: {'sigma': 8.444988761242563, 'lam': 0.007979652730687289}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:05,267]\u001b[0m Finished trial#87 with value: 0.501 with parameters: {'sigma': 5.114434706945722, 'lam': 0.011669378112306686}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:06,492]\u001b[0m Finished trial#88 with value: 0.6435000000000001 with parameters: {'sigma': 5.940832965759235, 'lam': 0.0021700383917805936}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:07,718]\u001b[0m Finished trial#89 with value: 0.635 with parameters: {'sigma': 6.915268211289836, 'lam': 0.005451937321380551}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:08,937]\u001b[0m Finished trial#90 with value: 0.501 with parameters: {'sigma': 4.631282222079149, 'lam': 0.04537022023901498}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:10,173]\u001b[0m Finished trial#91 with value: 0.6455 with parameters: {'sigma': 5.727390030322069, 'lam': 0.0020461288394607252}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:11,495]\u001b[0m Finished trial#92 with value: 0.6385 with parameters: {'sigma': 7.323434336386642, 'lam': 0.00044916437249081824}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:12,734]\u001b[0m Finished trial#93 with value: 0.633 with parameters: {'sigma': 15.250325738162589, 'lam': 0.004290379206474479}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:13,958]\u001b[0m Finished trial#94 with value: 0.612 with parameters: {'sigma': 5.562825226349571, 'lam': 0.006965365202280578}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:15,181]\u001b[0m Finished trial#95 with value: 0.501 with parameters: {'sigma': 3.4925099001238595, 'lam': 0.00948817488231218}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:16,449]\u001b[0m Finished trial#96 with value: 0.6475000000000001 with parameters: {'sigma': 5.083316847481876, 'lam': 0.002010101040813642}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:17,739]\u001b[0m Finished trial#97 with value: 0.5785 with parameters: {'sigma': 4.40484910533033, 'lam': 0.0023127100714299058}. Best is trial#83 with value: 0.6515000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:18,955]\u001b[0m Finished trial#98 with value: 0.6525000000000001 with parameters: {'sigma': 5.164141464365191, 'lam': 0.0001824768784490587}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:20,166]\u001b[0m Finished trial#99 with value: 0.612 with parameters: {'sigma': 5.002629845017131, 'lam': 0.00415368955155776}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:21,378]\u001b[0m Finished trial#100 with value: 0.6425 with parameters: {'sigma': 6.512217193972361, 'lam': 0.00017328807994143987}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:22,599]\u001b[0m Finished trial#101 with value: 0.6455 with parameters: {'sigma': 5.657432160723, 'lam': 0.0021182477993870624}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:23,827]\u001b[0m Finished trial#102 with value: 0.5345 with parameters: {'sigma': 5.035778070170081, 'lam': 0.006843289613097036}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:25,052]\u001b[0m Finished trial#103 with value: 0.644 with parameters: {'sigma': 5.933043301352573, 'lam': 0.00014806037292278604}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:26,275]\u001b[0m Finished trial#104 with value: 0.5155000000000001 with parameters: {'sigma': 4.523905587477864, 'lam': 0.004234358318080192}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:27,514]\u001b[0m Finished trial#105 with value: 0.6345 with parameters: {'sigma': 7.838912130022861, 'lam': 0.010098764171707708}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:28,727]\u001b[0m Finished trial#106 with value: 0.501 with parameters: {'sigma': 3.7352149911697423, 'lam': 0.001960352839027783}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:29,942]\u001b[0m Finished trial#107 with value: 0.5595 with parameters: {'sigma': 5.13846832889026, 'lam': 0.006683648371983487}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:31,157]\u001b[0m Finished trial#108 with value: 0.5055 with parameters: {'sigma': 5.622680348949921, 'lam': 0.01456444702872761}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:32,363]\u001b[0m Finished trial#109 with value: 0.501 with parameters: {'sigma': 3.158501069811161, 'lam': 0.0043108662611919205}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:33,594]\u001b[0m Finished trial#110 with value: 0.501 with parameters: {'sigma': 4.164326557063658, 'lam': 0.05989504586896449}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:34,831]\u001b[0m Finished trial#111 with value: 0.6405 with parameters: {'sigma': 6.286881781137766, 'lam': 0.001998571055167063}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:36,037]\u001b[0m Finished trial#112 with value: 0.6465 with parameters: {'sigma': 5.6709760354394785, 'lam': 0.0018963322433465457}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:37,254]\u001b[0m Finished trial#113 with value: 0.642 with parameters: {'sigma': 6.8552702338977785, 'lam': 0.0005067186716782531}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:38,483]\u001b[0m Finished trial#114 with value: 0.501 with parameters: {'sigma': 4.633633391447726, 'lam': 0.00835389172061059}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:39,736]\u001b[0m Finished trial#115 with value: 0.6495 with parameters: {'sigma': 5.356329256577354, 'lam': 8.859936397961953e-05}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:40,960]\u001b[0m Finished trial#116 with value: 0.6225 with parameters: {'sigma': 5.283376408602711, 'lam': 0.004723396599976024}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:42,181]\u001b[0m Finished trial#117 with value: 0.6375 with parameters: {'sigma': 13.363262138971578, 'lam': 6.168650807843602e-05}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:43,414]\u001b[0m Finished trial#118 with value: 0.592 with parameters: {'sigma': 3.6502091483469004, 'lam': 1.8675433504436456e-06}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:44,658]\u001b[0m Finished trial#119 with value: 0.6365000000000001 with parameters: {'sigma': 6.127249974738978, 'lam': 0.006094780514113717}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:45,878]\u001b[0m Finished trial#120 with value: 0.501 with parameters: {'sigma': 4.755302591373978, 'lam': 0.012585829828605668}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:47,144]\u001b[0m Finished trial#121 with value: 0.6435 with parameters: {'sigma': 5.734712078861704, 'lam': 0.0026046855883749996}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:48,386]\u001b[0m Finished trial#122 with value: 0.501 with parameters: {'sigma': 4.182194699726648, 'lam': 0.0034371630705693863}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:49,665]\u001b[0m Finished trial#123 with value: 0.6449999999999999 with parameters: {'sigma': 5.251366951504955, 'lam': 0.0017106921941589374}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:50,906]\u001b[0m Finished trial#124 with value: 0.5929999999999999 with parameters: {'sigma': 5.555605622345594, 'lam': 0.007635786531030914}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:52,149]\u001b[0m Finished trial#125 with value: 0.638 with parameters: {'sigma': 7.144928064039931, 'lam': 0.00015239361271435036}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:53,394]\u001b[0m Finished trial#126 with value: 0.6385 with parameters: {'sigma': 6.554423937624717, 'lam': 0.0050368477810438985}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:54,636]\u001b[0m Finished trial#127 with value: 0.605 with parameters: {'sigma': 6.134187348871074, 'lam': 0.009891420974694332}. Best is trial#98 with value: 0.6525000000000001.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:55,900]\u001b[0m Finished trial#128 with value: 0.653 with parameters: {'sigma': 4.8309578888151785, 'lam': 0.00012983543652483407}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:57,164]\u001b[0m Finished trial#129 with value: 0.629 with parameters: {'sigma': 4.829585458909636, 'lam': 0.0027840740834836233}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:58,404]\u001b[0m Finished trial#130 with value: 0.501 with parameters: {'sigma': 2.4668320965554185, 'lam': 8.61955090142232e-05}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:02:59,639]\u001b[0m Finished trial#131 with value: 0.6515 with parameters: {'sigma': 4.405851743508497, 'lam': 4.521746572602693e-05}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:00,876]\u001b[0m Finished trial#132 with value: 0.653 with parameters: {'sigma': 4.426309149269834, 'lam': 0.00015714825029608856}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:02,104]\u001b[0m Finished trial#133 with value: 0.501 with parameters: {'sigma': 4.306252919348594, 'lam': 0.09363822365772215}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:03,325]\u001b[0m Finished trial#134 with value: 0.501 with parameters: {'sigma': 3.8730611573250875, 'lam': 0.004270122071762303}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:04,563]\u001b[0m Finished trial#135 with value: 0.5375 with parameters: {'sigma': 4.98359797220024, 'lam': 0.006354697321014571}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:05,787]\u001b[0m Finished trial#136 with value: 0.501 with parameters: {'sigma': 4.417456112449455, 'lam': 0.036561220011529304}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:07,019]\u001b[0m Finished trial#137 with value: 0.501 with parameters: {'sigma': 3.319025074783438, 'lam': 0.00153180777345592}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:08,244]\u001b[0m Finished trial#138 with value: 0.6505 with parameters: {'sigma': 5.245172761070156, 'lam': 0.00018549466355311406}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:09,474]\u001b[0m Finished trial#139 with value: 0.651 with parameters: {'sigma': 4.008325768677759, 'lam': 0.0002109392475984454}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:10,729]\u001b[0m Finished trial#140 with value: 0.632 with parameters: {'sigma': 3.8438700571054585, 'lam': 0.00015888891675652447}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:11,976]\u001b[0m Finished trial#141 with value: 0.569 with parameters: {'sigma': 4.674256202124523, 'lam': 0.0038365143609293178}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:13,203]\u001b[0m Finished trial#142 with value: 0.6439999999999999 with parameters: {'sigma': 5.378840604741556, 'lam': 0.0017053155804337469}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:14,427]\u001b[0m Finished trial#143 with value: 0.501 with parameters: {'sigma': 4.416864759038908, 'lam': 0.0056343898000997044}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:15,658]\u001b[0m Finished trial#144 with value: 0.6515000000000001 with parameters: {'sigma': 4.944233935194756, 'lam': 0.0005279125036442475}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:16,931]\u001b[0m Finished trial#145 with value: 0.6519999999999999 with parameters: {'sigma': 4.062402873439734, 'lam': 0.0001811097684339791}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:18,289]\u001b[0m Finished trial#146 with value: 0.501 with parameters: {'sigma': 2.819801004325511, 'lam': 0.00040035229921252117}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:19,534]\u001b[0m Finished trial#147 with value: 0.501 with parameters: {'sigma': 3.5743624354722145, 'lam': 0.003870054186593707}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:20,763]\u001b[0m Finished trial#148 with value: 0.501 with parameters: {'sigma': 2.0965848050513083, 'lam': 1.4937123421588728e-06}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:22,097]\u001b[0m Finished trial#149 with value: 0.646 with parameters: {'sigma': 3.9688805283236226, 'lam': 0.00021110815247309318}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:23,338]\u001b[0m Finished trial#150 with value: 0.501 with parameters: {'sigma': 3.1354635756333717, 'lam': 0.007581238990690498}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:24,586]\u001b[0m Finished trial#151 with value: 0.628 with parameters: {'sigma': 4.968862584574385, 'lam': 0.003403562101567157}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:25,825]\u001b[0m Finished trial#152 with value: 0.6515 with parameters: {'sigma': 4.597624538322622, 'lam': 0.0002127741045096256}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:27,076]\u001b[0m Finished trial#153 with value: 0.501 with parameters: {'sigma': 4.246408003486049, 'lam': 0.005316045422640574}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:28,299]\u001b[0m Finished trial#154 with value: 0.6529999999999999 with parameters: {'sigma': 4.7121487876945505, 'lam': 8.292119210929019e-06}. Best is trial#128 with value: 0.653.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:29,529]\u001b[0m Finished trial#155 with value: 0.6535 with parameters: {'sigma': 4.655503881771646, 'lam': 6.441972948515395e-05}. Best is trial#155 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:30,733]\u001b[0m Finished trial#156 with value: 0.6519999999999999 with parameters: {'sigma': 4.481435709920606, 'lam': 0.00015236371337434284}. Best is trial#155 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:31,946]\u001b[0m Finished trial#157 with value: 0.603 with parameters: {'sigma': 4.63146591906773, 'lam': 0.0028474614821690433}. Best is trial#155 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:33,180]\u001b[0m Finished trial#158 with value: 0.501 with parameters: {'sigma': 3.755209742732212, 'lam': 0.005502022745861539}. Best is trial#155 with value: 0.6535.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:34,399]\u001b[0m Finished trial#159 with value: 0.6559999999999999 with parameters: {'sigma': 4.11199526782314, 'lam': 5.439181127097381e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:35,620]\u001b[0m Finished trial#160 with value: 0.654 with parameters: {'sigma': 4.123480638296328, 'lam': 8.509196946942703e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:36,826]\u001b[0m Finished trial#161 with value: 0.6545 with parameters: {'sigma': 4.072683557448175, 'lam': 1.9394891005086604e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:38,041]\u001b[0m Finished trial#162 with value: 0.501 with parameters: {'sigma': 3.489576952179292, 'lam': 0.00020425962972382903}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:39,267]\u001b[0m Finished trial#163 with value: 0.6519999999999999 with parameters: {'sigma': 4.290206584809202, 'lam': 7.790530381101673e-06}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:40,494]\u001b[0m Finished trial#164 with value: 0.501 with parameters: {'sigma': 4.025597317430126, 'lam': 0.002804671733231897}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:41,729]\u001b[0m Finished trial#165 with value: 0.501 with parameters: {'sigma': 2.8511005410128005, 'lam': 0.0022059265351432587}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:42,949]\u001b[0m Finished trial#166 with value: 0.501 with parameters: {'sigma': 4.160811879629893, 'lam': 0.0042448311633664125}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:44,191]\u001b[0m Finished trial#167 with value: 0.501 with parameters: {'sigma': 3.358645536218047, 'lam': 0.001722628530314651}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:45,436]\u001b[0m Finished trial#168 with value: 0.651 with parameters: {'sigma': 4.440447389290239, 'lam': 0.00020672432936399133}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:46,647]\u001b[0m Finished trial#169 with value: 0.639 with parameters: {'sigma': 3.912551921174649, 'lam': 0.00018840650689978106}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:47,859]\u001b[0m Finished trial#170 with value: 0.6535 with parameters: {'sigma': 4.628038294430284, 'lam': 9.354927764358521e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:49,194]\u001b[0m Finished trial#171 with value: 0.6525000000000001 with parameters: {'sigma': 4.785573538378496, 'lam': 0.00020986584605077458}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:50,417]\u001b[0m Finished trial#172 with value: 0.567 with parameters: {'sigma': 4.621209261356317, 'lam': 0.0035842964946114528}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:51,646]\u001b[0m Finished trial#173 with value: 0.653 with parameters: {'sigma': 4.800410812233281, 'lam': 9.51065515562998e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:52,852]\u001b[0m Finished trial#174 with value: 0.6435000000000001 with parameters: {'sigma': 4.763336013199431, 'lam': 0.0020925768362735713}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:54,072]\u001b[0m Finished trial#175 with value: 0.6319999999999999 with parameters: {'sigma': 17.796104717370138, 'lam': 0.006117314721370395}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:55,319]\u001b[0m Finished trial#176 with value: 0.501 with parameters: {'sigma': 3.558856882031824, 'lam': 0.07473201144991161}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:56,540]\u001b[0m Finished trial#177 with value: 0.653 with parameters: {'sigma': 4.797435386686213, 'lam': 9.467447492695312e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:57,768]\u001b[0m Finished trial#178 with value: 0.6100000000000001 with parameters: {'sigma': 4.953260541826884, 'lam': 0.004099617653631091}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:03:58,985]\u001b[0m Finished trial#179 with value: 0.6525000000000001 with parameters: {'sigma': 4.356439470048847, 'lam': 0.00014977127121053305}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:00,211]\u001b[0m Finished trial#180 with value: 0.5069999999999999 with parameters: {'sigma': 4.077495749281647, 'lam': 0.002022546794682584}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:01,408]\u001b[0m Finished trial#181 with value: 0.6105 with parameters: {'sigma': 4.323717043073246, 'lam': 0.0016119486035687713}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:02,622]\u001b[0m Finished trial#182 with value: 0.6125 with parameters: {'sigma': 4.8958389553562816, 'lam': 0.0036533563363297327}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:03,837]\u001b[0m Finished trial#183 with value: 0.5565 with parameters: {'sigma': 3.6578176067804486, 'lam': 0.00014767066979083502}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:05,062]\u001b[0m Finished trial#184 with value: 0.6465 with parameters: {'sigma': 5.3050434037011005, 'lam': 0.002394194208959648}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:06,292]\u001b[0m Finished trial#185 with value: 0.501 with parameters: {'sigma': 4.434917745334386, 'lam': 0.005101298966080667}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:07,512]\u001b[0m Finished trial#186 with value: 0.6539999999999999 with parameters: {'sigma': 4.902592376238977, 'lam': 0.00022460784460015025}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:08,734]\u001b[0m Finished trial#187 with value: 0.501 with parameters: {'sigma': 3.161300671637262, 'lam': 0.0003345364386372959}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:09,963]\u001b[0m Finished trial#188 with value: 0.6519999999999999 with parameters: {'sigma': 4.823700822576606, 'lam': 3.4700707715878485e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:11,182]\u001b[0m Finished trial#189 with value: 0.654 with parameters: {'sigma': 4.210169167675173, 'lam': 5.2696818127655545e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:12,408]\u001b[0m Finished trial#190 with value: 0.501 with parameters: {'sigma': 4.122420831827199, 'lam': 0.006549248417275733}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:13,631]\u001b[0m Finished trial#191 with value: 0.6535 with parameters: {'sigma': 4.6426292745128945, 'lam': 0.00012572692420630667}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:14,869]\u001b[0m Finished trial#192 with value: 0.5984999999999999 with parameters: {'sigma': 3.7426152383984377, 'lam': 0.00015306262777963712}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:16,101]\u001b[0m Finished trial#193 with value: 0.5765 with parameters: {'sigma': 4.593897552336999, 'lam': 0.003156786146304198}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:17,399]\u001b[0m Finished trial#194 with value: 0.501 with parameters: {'sigma': 0.10027438807691613, 'lam': 7.086723279082283e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:18,637]\u001b[0m Finished trial#195 with value: 0.529 with parameters: {'sigma': 4.22205489617365, 'lam': 0.00224431047982262}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:19,850]\u001b[0m Finished trial#196 with value: 0.654 with parameters: {'sigma': 4.531913332368194, 'lam': 7.708677830550666e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:21,072]\u001b[0m Finished trial#197 with value: 0.6185 with parameters: {'sigma': 3.7280257322257278, 'lam': 3.396425428588769e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:22,298]\u001b[0m Finished trial#198 with value: 0.5424999999999999 with parameters: {'sigma': 4.695242425496319, 'lam': 0.004382581060413847}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:23,525]\u001b[0m Finished trial#199 with value: 0.6455 with parameters: {'sigma': 5.408715085797027, 'lam': 0.002026390492046262}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:24,742]\u001b[0m Finished trial#200 with value: 0.6525 with parameters: {'sigma': 4.910999695182416, 'lam': 2.4331657716362067e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:25,959]\u001b[0m Finished trial#201 with value: 0.6420000000000001 with parameters: {'sigma': 4.943359242359523, 'lam': 0.002637001299243993}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:27,169]\u001b[0m Finished trial#202 with value: 0.653 with parameters: {'sigma': 4.7047678796722865, 'lam': 5.407935892175951e-05}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:28,390]\u001b[0m Finished trial#203 with value: 0.6174999999999999 with parameters: {'sigma': 4.494453618090223, 'lam': 0.0019180694665536515}. Best is trial#159 with value: 0.6559999999999999.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:29,632]\u001b[0m Finished trial#204 with value: 0.656 with parameters: {'sigma': 4.091509903462909, 'lam': 4.2150104838065036e-07}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:30,857]\u001b[0m Finished trial#205 with value: 0.501 with parameters: {'sigma': 3.9503194715095313, 'lam': 0.00431515312363626}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:32,070]\u001b[0m Finished trial#206 with value: 0.6509999999999999 with parameters: {'sigma': 5.230786801564802, 'lam': 0.00014694989210030395}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:33,280]\u001b[0m Finished trial#207 with value: 0.501 with parameters: {'sigma': 3.364180885425154, 'lam': 0.001987947850528517}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:34,515]\u001b[0m Finished trial#208 with value: 0.5119999999999999 with parameters: {'sigma': 4.563310291156958, 'lam': 0.004590174597943949}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:35,816]\u001b[0m Finished trial#209 with value: 0.501 with parameters: {'sigma': 5.667029163710739, 'lam': 0.029904792613885116}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:37,038]\u001b[0m Finished trial#210 with value: 0.6525 with parameters: {'sigma': 4.951185413722197, 'lam': 0.00016122103872323915}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:38,271]\u001b[0m Finished trial#211 with value: 0.5170000000000001 with parameters: {'sigma': 4.041553060029319, 'lam': 0.001620056697985167}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:39,492]\u001b[0m Finished trial#212 with value: 0.651 with parameters: {'sigma': 4.999466586596563, 'lam': 3.3173221158806115e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:40,718]\u001b[0m Finished trial#213 with value: 0.5745 with parameters: {'sigma': 4.332626222406255, 'lam': 0.002138018510164635}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:41,973]\u001b[0m Finished trial#214 with value: 0.6529999999999999 with parameters: {'sigma': 4.8805247481080265, 'lam': 0.00016464686172323737}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:43,865]\u001b[0m Finished trial#215 with value: 0.6475000000000001 with parameters: {'sigma': 5.352276415328593, 'lam': 8.561192414945042e-06}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:45,829]\u001b[0m Finished trial#216 with value: 0.6100000000000001 with parameters: {'sigma': 4.873979810153779, 'lam': 0.003772362078081773}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:47,032]\u001b[0m Finished trial#217 with value: 0.643 with parameters: {'sigma': 5.943947976378778, 'lam': 0.002157501439222483}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:48,244]\u001b[0m Finished trial#218 with value: 0.6355000000000001 with parameters: {'sigma': 5.184016518734218, 'lam': 0.0036076338563819305}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:49,443]\u001b[0m Finished trial#219 with value: 0.654 with parameters: {'sigma': 4.725626349536086, 'lam': 8.507944368569471e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:50,673]\u001b[0m Finished trial#220 with value: 0.6525000000000001 with parameters: {'sigma': 4.588010190041981, 'lam': 0.00013447909694543823}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:52,701]\u001b[0m Finished trial#221 with value: 0.6519999999999999 with parameters: {'sigma': 4.625830507958708, 'lam': 0.00023658182281883518}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:54,508]\u001b[0m Finished trial#222 with value: 0.6529999999999999 with parameters: {'sigma': 4.2090105407119855, 'lam': 2.8493424967884003e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:55,719]\u001b[0m Finished trial#223 with value: 0.501 with parameters: {'sigma': 3.7856432787711793, 'lam': 0.050936672809399855}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:56,933]\u001b[0m Finished trial#224 with value: 0.5275000000000001 with parameters: {'sigma': 4.152289948944481, 'lam': 0.001953707390438238}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:58,162]\u001b[0m Finished trial#225 with value: 0.593 with parameters: {'sigma': 4.359647706710115, 'lam': 0.0019476676014031737}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:04:59,408]\u001b[0m Finished trial#226 with value: 0.545 with parameters: {'sigma': 3.6080439390099786, 'lam': 9.949733041444617e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:00,659]\u001b[0m Finished trial#227 with value: 0.6525000000000001 with parameters: {'sigma': 4.6038716259337855, 'lam': 1.578993134336653e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:01,902]\u001b[0m Finished trial#228 with value: 0.501 with parameters: {'sigma': 4.046475220573682, 'lam': 0.005533434969380048}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:03,144]\u001b[0m Finished trial#229 with value: 0.647 with parameters: {'sigma': 5.534019607749664, 'lam': 1.5480833482638045e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:04,380]\u001b[0m Finished trial#230 with value: 0.577 with parameters: {'sigma': 4.657862293654729, 'lam': 0.0036062593741137817}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:05,606]\u001b[0m Finished trial#231 with value: 0.6519999999999999 with parameters: {'sigma': 4.362975879700542, 'lam': 0.00012917872300250726}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:07,880]\u001b[0m Finished trial#232 with value: 0.6420000000000001 with parameters: {'sigma': 4.6675650620246625, 'lam': 0.0019664056207669652}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:09,686]\u001b[0m Finished trial#233 with value: 0.653 with parameters: {'sigma': 5.112003965054635, 'lam': 8.670767997563845e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:10,922]\u001b[0m Finished trial#234 with value: 0.501 with parameters: {'sigma': 5.13481415520091, 'lam': 0.08658016609737516}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:12,129]\u001b[0m Finished trial#235 with value: 0.516 with parameters: {'sigma': 4.121313779321882, 'lam': 0.002000863930219018}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:13,362]\u001b[0m Finished trial#236 with value: 0.651 with parameters: {'sigma': 5.452997542064811, 'lam': 0.0001786382498389383}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:14,581]\u001b[0m Finished trial#237 with value: 0.654 with parameters: {'sigma': 4.615597546349835, 'lam': 0.000115715521590404}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:15,803]\u001b[0m Finished trial#238 with value: 0.501 with parameters: {'sigma': 3.3963364479271436, 'lam': 0.0035095078509374275}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:17,033]\u001b[0m Finished trial#239 with value: 0.501 with parameters: {'sigma': 5.20475760759897, 'lam': 0.025432371676829067}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:18,252]\u001b[0m Finished trial#240 with value: 0.6515000000000001 with parameters: {'sigma': 5.056271101747227, 'lam': 4.8693047840553286e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:19,513]\u001b[0m Finished trial#241 with value: 0.6525 with parameters: {'sigma': 4.438362445985108, 'lam': 0.00013471622899825263}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:20,714]\u001b[0m Finished trial#242 with value: 0.6435 with parameters: {'sigma': 4.739806754078129, 'lam': 0.0021305507731788297}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:23,247]\u001b[0m Finished trial#243 with value: 0.501 with parameters: {'sigma': 3.8978607634249234, 'lam': 0.0017075154466357958}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:24,768]\u001b[0m Finished trial#244 with value: 0.6519999999999999 with parameters: {'sigma': 4.240996474612109, 'lam': 8.130593973903786e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:25,995]\u001b[0m Finished trial#245 with value: 0.6519999999999999 with parameters: {'sigma': 4.51241668511142, 'lam': 0.00013918935061835579}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:27,224]\u001b[0m Finished trial#246 with value: 0.597 with parameters: {'sigma': 4.801568529588637, 'lam': 0.0036920005274284273}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:28,442]\u001b[0m Finished trial#247 with value: 0.501 with parameters: {'sigma': 3.7542185535338852, 'lam': 0.0017224600990769468}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:29,660]\u001b[0m Finished trial#248 with value: 0.5025 with parameters: {'sigma': 4.2454370050650185, 'lam': 0.0034124855629848283}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:30,873]\u001b[0m Finished trial#249 with value: 0.647 with parameters: {'sigma': 4.766226252172511, 'lam': 0.0017301166550943922}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:32,733]\u001b[0m Finished trial#250 with value: 0.6475000000000001 with parameters: {'sigma': 5.521877849937152, 'lam': 0.00010066810050682889}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:33,960]\u001b[0m Finished trial#251 with value: 0.596 with parameters: {'sigma': 5.121184452714801, 'lam': 0.00525325600156569}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:35,214]\u001b[0m Finished trial#252 with value: 0.649 with parameters: {'sigma': 3.9405318912215668, 'lam': 9.753852276160472e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:36,440]\u001b[0m Finished trial#253 with value: 0.516 with parameters: {'sigma': 4.338029509017809, 'lam': 0.0031425770452825344}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:37,663]\u001b[0m Finished trial#254 with value: 0.6364999999999998 with parameters: {'sigma': 4.528294116199291, 'lam': 0.0016423090158590218}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:38,867]\u001b[0m Finished trial#255 with value: 0.647 with parameters: {'sigma': 5.746730018628514, 'lam': 5.0626156411226215e-06}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:40,087]\u001b[0m Finished trial#256 with value: 0.5325 with parameters: {'sigma': 4.760669803926038, 'lam': 0.005077918982565603}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:41,310]\u001b[0m Finished trial#257 with value: 0.6200000000000001 with parameters: {'sigma': 3.74057212291883, 'lam': 4.7605316507178135e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:42,514]\u001b[0m Finished trial#258 with value: 0.6465 with parameters: {'sigma': 5.049719663580617, 'lam': 0.0019991502903552584}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:43,737]\u001b[0m Finished trial#259 with value: 0.501 with parameters: {'sigma': 3.078865939967736, 'lam': 0.0001401946205081375}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:44,950]\u001b[0m Finished trial#260 with value: 0.501 with parameters: {'sigma': 4.151266693645592, 'lam': 0.0035360625455140987}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:46,201]\u001b[0m Finished trial#261 with value: 0.501 with parameters: {'sigma': 4.647454394130481, 'lam': 0.007035858875398643}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:47,417]\u001b[0m Finished trial#262 with value: 0.6485000000000001 with parameters: {'sigma': 5.320901649651021, 'lam': 1.3894041352284403e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:48,637]\u001b[0m Finished trial#263 with value: 0.647 with parameters: {'sigma': 4.954047724499792, 'lam': 0.002054908313638955}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:49,851]\u001b[0m Finished trial#264 with value: 0.6305000000000001 with parameters: {'sigma': 11.825754297691926, 'lam': 0.004072893561514462}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:51,065]\u001b[0m Finished trial#265 with value: 0.6465 with parameters: {'sigma': 5.478235707800111, 'lam': 8.075932758426258e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:52,275]\u001b[0m Finished trial#266 with value: 0.5175 with parameters: {'sigma': 3.53730832482821, 'lam': 6.475168692202038e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:53,482]\u001b[0m Finished trial#267 with value: 0.5229999999999999 with parameters: {'sigma': 4.154012478687731, 'lam': 0.002007972148084248}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:54,697]\u001b[0m Finished trial#268 with value: 0.501 with parameters: {'sigma': 4.406985259218695, 'lam': 0.005416673022840369}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:55,919]\u001b[0m Finished trial#269 with value: 0.6460000000000001 with parameters: {'sigma': 5.990218490846378, 'lam': 6.029654615880771e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:57,155]\u001b[0m Finished trial#270 with value: 0.6359999999999999 with parameters: {'sigma': 5.032398331926137, 'lam': 0.0032419804892955153}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:58,379]\u001b[0m Finished trial#271 with value: 0.653 with parameters: {'sigma': 4.571709485446343, 'lam': 3.085798120488207e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:05:59,576]\u001b[0m Finished trial#272 with value: 0.501 with parameters: {'sigma': 3.870160685494535, 'lam': 0.0018088980155296906}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:00,788]\u001b[0m Finished trial#273 with value: 0.58 with parameters: {'sigma': 4.323845497761926, 'lam': 0.001942956753469199}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:01,998]\u001b[0m Finished trial#274 with value: 0.6519999999999999 with parameters: {'sigma': 4.682337539136737, 'lam': 1.790579491573217e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:03,219]\u001b[0m Finished trial#275 with value: 0.6475 with parameters: {'sigma': 5.231440029681838, 'lam': 1.6875673591440455e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:04,436]\u001b[0m Finished trial#276 with value: 0.501 with parameters: {'sigma': 3.2705442023091105, 'lam': 0.003551179654254173}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:05,665]\u001b[0m Finished trial#277 with value: 0.653 with parameters: {'sigma': 4.795111067840908, 'lam': 3.768669051072858e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:06,865]\u001b[0m Finished trial#278 with value: 0.514 with parameters: {'sigma': 4.795763004781488, 'lam': 0.006072460848905522}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:08,081]\u001b[0m Finished trial#279 with value: 0.501 with parameters: {'sigma': 3.8674610839046046, 'lam': 0.0017896463965432052}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:09,283]\u001b[0m Finished trial#280 with value: 0.6485000000000001 with parameters: {'sigma': 5.377238391056806, 'lam': 6.434512571274758e-05}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:10,482]\u001b[0m Finished trial#281 with value: 0.501 with parameters: {'sigma': 4.124887423533389, 'lam': 0.06339122431884074}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:11,668]\u001b[0m Finished trial#282 with value: 0.6455 with parameters: {'sigma': 5.688939465315661, 'lam': 0.004048317771282416}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:12,860]\u001b[0m Finished trial#283 with value: 0.501 with parameters: {'sigma': 3.541751506394532, 'lam': 0.002413472553549549}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:14,065]\u001b[0m Finished trial#284 with value: 0.648 with parameters: {'sigma': 4.800410970330277, 'lam': 0.0016867501260733743}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:15,261]\u001b[0m Finished trial#285 with value: 0.501 with parameters: {'sigma': 4.353067969970538, 'lam': 0.004880145496684931}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:16,474]\u001b[0m Finished trial#286 with value: 0.6455 with parameters: {'sigma': 5.299997240789917, 'lam': 0.001831412336490873}. Best is trial#204 with value: 0.656.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:17,698]\u001b[0m Finished trial#287 with value: 0.6585 with parameters: {'sigma': 4.095187492404232, 'lam': 0.00014355617684684455}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:18,937]\u001b[0m Finished trial#288 with value: 0.6529999999999999 with parameters: {'sigma': 4.233263044946065, 'lam': 2.3630983696169662e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:20,154]\u001b[0m Finished trial#289 with value: 0.501 with parameters: {'sigma': 3.669060545120196, 'lam': 0.007777253055364677}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:21,373]\u001b[0m Finished trial#290 with value: 0.501 with parameters: {'sigma': 3.948616833139309, 'lam': 0.0034931392447126383}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:22,594]\u001b[0m Finished trial#291 with value: 0.501 with parameters: {'sigma': 3.4677247343077697, 'lam': 0.002035364929045883}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:23,820]\u001b[0m Finished trial#292 with value: 0.656 with parameters: {'sigma': 4.020802669575087, 'lam': 1.047601558870349e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:25,045]\u001b[0m Finished trial#293 with value: 0.6319999999999999 with parameters: {'sigma': 9.861791228451763, 'lam': 0.00019773163091809073}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:26,265]\u001b[0m Finished trial#294 with value: 0.501 with parameters: {'sigma': 2.612652198287123, 'lam': 0.0439058104598203}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:27,470]\u001b[0m Finished trial#295 with value: 0.501 with parameters: {'sigma': 3.0726286064793698, 'lam': 6.151875497327926e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:28,679]\u001b[0m Finished trial#296 with value: 0.501 with parameters: {'sigma': 4.109080783134559, 'lam': 0.00524756944664791}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:29,919]\u001b[0m Finished trial#297 with value: 0.5595000000000001 with parameters: {'sigma': 4.559466931144674, 'lam': 0.003389215728164194}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:31,147]\u001b[0m Finished trial#298 with value: 0.6245 with parameters: {'sigma': 3.8082192490108713, 'lam': 0.00011949041821486493}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:32,356]\u001b[0m Finished trial#299 with value: 0.648 with parameters: {'sigma': 5.061534096951663, 'lam': 0.0018730311306269507}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:33,572]\u001b[0m Finished trial#300 with value: 0.6515 with parameters: {'sigma': 4.388911393729359, 'lam': 3.6970146983987746e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:34,798]\u001b[0m Finished trial#301 with value: 0.501 with parameters: {'sigma': 3.355098392007274, 'lam': 0.0037773818095473465}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:36,035]\u001b[0m Finished trial#302 with value: 0.6540000000000001 with parameters: {'sigma': 4.023116163428392, 'lam': 6.273147998472928e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:37,272]\u001b[0m Finished trial#303 with value: 0.501 with parameters: {'sigma': 3.881054890542496, 'lam': 0.006200052993236051}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:38,476]\u001b[0m Finished trial#304 with value: 0.6515000000000001 with parameters: {'sigma': 4.764502726176423, 'lam': 1.7404407596620407e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:39,688]\u001b[0m Finished trial#305 with value: 0.648 with parameters: {'sigma': 4.905099283334741, 'lam': 0.002094028219785534}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:40,934]\u001b[0m Finished trial#306 with value: 0.5970000000000001 with parameters: {'sigma': 3.6927595980292285, 'lam': 6.520182049093607e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:42,158]\u001b[0m Finished trial#307 with value: 0.501 with parameters: {'sigma': 2.9959225829039617, 'lam': 0.003748349986153308}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:43,386]\u001b[0m Finished trial#308 with value: 0.519 with parameters: {'sigma': 4.111489469290134, 'lam': 0.0019036147117507025}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:44,694]\u001b[0m Finished trial#309 with value: 0.6519999999999999 with parameters: {'sigma': 4.287966884872123, 'lam': 0.00013025391547062952}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:45,961]\u001b[0m Finished trial#310 with value: 0.526 with parameters: {'sigma': 4.696354945084944, 'lam': 0.004953365279231598}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:47,200]\u001b[0m Finished trial#311 with value: 0.502 with parameters: {'sigma': 3.4290359700434783, 'lam': 5.056247389254183e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:48,484]\u001b[0m Finished trial#312 with value: 0.501 with parameters: {'sigma': 3.9071909020520734, 'lam': 0.0020745442211031417}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:49,702]\u001b[0m Finished trial#313 with value: 0.515 with parameters: {'sigma': 4.361626334283542, 'lam': 0.0033089851242881978}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:50,928]\u001b[0m Finished trial#314 with value: 0.501 with parameters: {'sigma': 4.447481154721509, 'lam': 0.03745873474886438}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:52,290]\u001b[0m Finished trial#315 with value: 0.6555 with parameters: {'sigma': 4.024748436601316, 'lam': 9.623626644476276e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:53,520]\u001b[0m Finished trial#316 with value: 0.501 with parameters: {'sigma': 3.6177760841765743, 'lam': 0.0075667291217122795}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:54,811]\u001b[0m Finished trial#317 with value: 0.651 with parameters: {'sigma': 5.135505177634639, 'lam': 3.1651427473189854e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:56,044]\u001b[0m Finished trial#318 with value: 0.502 with parameters: {'sigma': 4.016814667415035, 'lam': 0.001996396856251196}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:57,281]\u001b[0m Finished trial#319 with value: 0.501 with parameters: {'sigma': 2.8314055148160397, 'lam': 6.623553156440087e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:58,492]\u001b[0m Finished trial#320 with value: 0.501 with parameters: {'sigma': 3.3170704594831513, 'lam': 0.004810023931932782}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:06:59,698]\u001b[0m Finished trial#321 with value: 0.646 with parameters: {'sigma': 5.500240040047972, 'lam': 0.0021049993936556708}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:00,932]\u001b[0m Finished trial#322 with value: 0.6465 with parameters: {'sigma': 5.851206430237136, 'lam': 7.491301497572027e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:02,154]\u001b[0m Finished trial#323 with value: 0.501 with parameters: {'sigma': 3.988488631063356, 'lam': 0.0036019491636313}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:03,382]\u001b[0m Finished trial#324 with value: 0.651 with parameters: {'sigma': 5.0491428551591575, 'lam': 1.0018667609797914e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:04,595]\u001b[0m Finished trial#325 with value: 0.629 with parameters: {'sigma': 4.594543788321413, 'lam': 0.002057150807384273}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:05,823]\u001b[0m Finished trial#326 with value: 0.501 with parameters: {'sigma': 4.234901003847633, 'lam': 0.005663097638639939}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:07,045]\u001b[0m Finished trial#327 with value: 0.6445000000000001 with parameters: {'sigma': 4.657572322058613, 'lam': 0.0017771276451441424}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:08,248]\u001b[0m Finished trial#328 with value: 0.5795 with parameters: {'sigma': 3.6620138960334456, 'lam': 8.017364833372393e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:09,464]\u001b[0m Finished trial#329 with value: 0.622 with parameters: {'sigma': 5.017468867742316, 'lam': 0.0037258967790555503}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:10,674]\u001b[0m Finished trial#330 with value: 0.624 with parameters: {'sigma': 4.532550204633416, 'lam': 0.001993127963097393}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:11,877]\u001b[0m Finished trial#331 with value: 0.6525 with parameters: {'sigma': 3.9210422551098887, 'lam': 5.039607933896885e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:13,092]\u001b[0m Finished trial#332 with value: 0.643 with parameters: {'sigma': 5.632724489238352, 'lam': 0.003455286148065229}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:14,320]\u001b[0m Finished trial#333 with value: 0.501 with parameters: {'sigma': 4.440557209286153, 'lam': 0.05543367650086932}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:15,547]\u001b[0m Finished trial#334 with value: 0.501 with parameters: {'sigma': 3.116042588048645, 'lam': 4.678794099034441e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:16,779]\u001b[0m Finished trial#335 with value: 0.501 with parameters: {'sigma': 4.083746361293301, 'lam': 0.006505777142396246}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:17,992]\u001b[0m Finished trial#336 with value: 0.6450000000000001 with parameters: {'sigma': 5.038438203437929, 'lam': 0.002149205083710941}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:19,221]\u001b[0m Finished trial#337 with value: 0.501 with parameters: {'sigma': 3.637673804269517, 'lam': 0.001616879567247429}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:20,430]\u001b[0m Finished trial#338 with value: 0.6244999999999999 with parameters: {'sigma': 5.319718458653442, 'lam': 0.004810660212647561}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:21,655]\u001b[0m Finished trial#339 with value: 0.501 with parameters: {'sigma': 4.162840227120073, 'lam': 0.07003909261194582}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:22,855]\u001b[0m Finished trial#340 with value: 0.6295 with parameters: {'sigma': 17.18325607469107, 'lam': 9.982342697594231e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:24,062]\u001b[0m Finished trial#341 with value: 0.6445000000000001 with parameters: {'sigma': 6.230212003275479, 'lam': 0.0034556466980148045}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:25,274]\u001b[0m Finished trial#342 with value: 0.503 with parameters: {'sigma': 3.461279638244376, 'lam': 6.317518280627547e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:26,515]\u001b[0m Finished trial#343 with value: 0.6535 with parameters: {'sigma': 4.844983659233866, 'lam': 7.55618142717944e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:27,731]\u001b[0m Finished trial#344 with value: 0.6420000000000001 with parameters: {'sigma': 4.71829347562794, 'lam': 0.0020229736752666217}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:28,947]\u001b[0m Finished trial#345 with value: 0.501 with parameters: {'sigma': 2.402234625034235, 'lam': 0.009418433630561232}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:30,164]\u001b[0m Finished trial#346 with value: 0.648 with parameters: {'sigma': 5.29897988224733, 'lam': 2.723883473654933e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:31,381]\u001b[0m Finished trial#347 with value: 0.6535 with parameters: {'sigma': 4.448807000464619, 'lam': 1.8715850191629335e-07}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:32,607]\u001b[0m Finished trial#348 with value: 0.651 with parameters: {'sigma': 4.397732578987054, 'lam': 8.286550609802403e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:33,828]\u001b[0m Finished trial#349 with value: 0.501 with parameters: {'sigma': 3.799787979546276, 'lam': 0.004696685480435585}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:35,049]\u001b[0m Finished trial#350 with value: 0.6245 with parameters: {'sigma': 4.864708498754708, 'lam': 0.0031053445328591387}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:36,291]\u001b[0m Finished trial#351 with value: 0.652 with parameters: {'sigma': 4.57411615707162, 'lam': 1.9411285387524747e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:37,502]\u001b[0m Finished trial#352 with value: 0.6425 with parameters: {'sigma': 5.779974458151824, 'lam': 0.0018952550527978214}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:38,741]\u001b[0m Finished trial#353 with value: 0.501 with parameters: {'sigma': 4.072202171196481, 'lam': 0.006902303056949422}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:39,962]\u001b[0m Finished trial#354 with value: 0.562 with parameters: {'sigma': 4.2706709395394205, 'lam': 0.0019982495970124995}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:41,176]\u001b[0m Finished trial#355 with value: 0.501 with parameters: {'sigma': 3.3045550124412193, 'lam': 4.1001984958354145e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:42,396]\u001b[0m Finished trial#356 with value: 0.6159999999999999 with parameters: {'sigma': 5.024288044565067, 'lam': 0.004086895309332651}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:43,596]\u001b[0m Finished trial#357 with value: 0.501 with parameters: {'sigma': 3.8254561379674077, 'lam': 0.0016953707040563493}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:44,816]\u001b[0m Finished trial#358 with value: 0.6519999999999999 with parameters: {'sigma': 4.399201809951462, 'lam': 7.253816950769824e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:46,030]\u001b[0m Finished trial#359 with value: 0.6164999999999999 with parameters: {'sigma': 5.382461861384735, 'lam': 0.005441907534539566}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:47,266]\u001b[0m Finished trial#360 with value: 0.6519999999999999 with parameters: {'sigma': 4.683076753432092, 'lam': 1.3716623282736406e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:48,491]\u001b[0m Finished trial#361 with value: 0.64 with parameters: {'sigma': 5.091842151348709, 'lam': 0.0031962536898488456}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:49,700]\u001b[0m Finished trial#362 with value: 0.502 with parameters: {'sigma': 3.9315482340268133, 'lam': 0.0016145548731911956}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:50,931]\u001b[0m Finished trial#363 with value: 0.5305 with parameters: {'sigma': 4.409859797704022, 'lam': 0.003150425410774013}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:52,160]\u001b[0m Finished trial#364 with value: 0.5265000000000001 with parameters: {'sigma': 3.5645218500098714, 'lam': 7.61967650590291e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:53,406]\u001b[0m Finished trial#365 with value: 0.6529999999999999 with parameters: {'sigma': 4.856079557151064, 'lam': 2.7736437515159647e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:54,622]\u001b[0m Finished trial#366 with value: 0.501 with parameters: {'sigma': 4.120490004084953, 'lam': 0.005300223923255709}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:55,847]\u001b[0m Finished trial#367 with value: 0.501 with parameters: {'sigma': 2.8225399105570492, 'lam': 0.0017962826290853892}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:57,088]\u001b[0m Finished trial#368 with value: 0.5365 with parameters: {'sigma': 4.517925097746706, 'lam': 0.00353302586764954}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:58,327]\u001b[0m Finished trial#369 with value: 0.501 with parameters: {'sigma': 3.7421216785413476, 'lam': 0.00176710233554989}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:07:59,545]\u001b[0m Finished trial#370 with value: 0.501 with parameters: {'sigma': 1.1798145490030518, 'lam': 0.00014246715092284206}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:00,751]\u001b[0m Finished trial#371 with value: 0.647 with parameters: {'sigma': 5.395167980455865, 'lam': 5.058239829633818e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:01,960]\u001b[0m Finished trial#372 with value: 0.501 with parameters: {'sigma': 3.165496246953505, 'lam': 5.390188592006013e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:03,188]\u001b[0m Finished trial#373 with value: 0.501 with parameters: {'sigma': 4.109136142606484, 'lam': 0.008212448933878031}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:04,401]\u001b[0m Finished trial#374 with value: 0.616 with parameters: {'sigma': 4.909575523117551, 'lam': 0.003643558456368889}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:05,632]\u001b[0m Finished trial#375 with value: 0.652 with parameters: {'sigma': 4.573057059724445, 'lam': 1.0447034366621789e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:06,838]\u001b[0m Finished trial#376 with value: 0.5389999999999999 with parameters: {'sigma': 4.210802634126075, 'lam': 0.0020171774610595375}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:08,069]\u001b[0m Finished trial#377 with value: 0.634 with parameters: {'sigma': 5.654525499646735, 'lam': 0.005079513681738483}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:09,312]\u001b[0m Finished trial#378 with value: 0.501 with parameters: {'sigma': 3.713270304073477, 'lam': 0.0019347216411136946}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:10,549]\u001b[0m Finished trial#379 with value: 0.617 with parameters: {'sigma': 4.951246077088908, 'lam': 0.003585472425712516}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:11,777]\u001b[0m Finished trial#380 with value: 0.654 with parameters: {'sigma': 4.495111077384079, 'lam': 2.901950404109104e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:13,013]\u001b[0m Finished trial#381 with value: 0.501 with parameters: {'sigma': 3.327601307898856, 'lam': 0.006795620995905776}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:14,237]\u001b[0m Finished trial#382 with value: 0.6445000000000001 with parameters: {'sigma': 5.172758369938558, 'lam': 0.0018053589061703804}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:15,464]\u001b[0m Finished trial#383 with value: 0.6245 with parameters: {'sigma': 4.458692774207803, 'lam': 0.001715241010737976}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:16,705]\u001b[0m Finished trial#384 with value: 0.501 with parameters: {'sigma': 3.996096963071245, 'lam': 0.03256806231832169}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:17,948]\u001b[0m Finished trial#385 with value: 0.6525000000000001 with parameters: {'sigma': 4.505854526056911, 'lam': 0.00010947204761610015}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:20,379]\u001b[0m Finished trial#386 with value: 0.501 with parameters: {'sigma': 3.5911601036424203, 'lam': 0.004346595424351184}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:23,380]\u001b[0m Finished trial#387 with value: 0.6525 with parameters: {'sigma': 4.293248917944919, 'lam': 0.00011806934611962222}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:27,092]\u001b[0m Finished trial#388 with value: 0.501 with parameters: {'sigma': 3.9286811263721635, 'lam': 0.001865854497354425}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:30,657]\u001b[0m Finished trial#389 with value: 0.6529999999999999 with parameters: {'sigma': 4.841417162468408, 'lam': 7.356957176112033e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:33,601]\u001b[0m Finished trial#390 with value: 0.584 with parameters: {'sigma': 4.645041284378889, 'lam': 0.0032672755377130204}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:37,718]\u001b[0m Finished trial#391 with value: 0.6360000000000001 with parameters: {'sigma': 8.979985718950648, 'lam': 1.8507164865597286e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:41,347]\u001b[0m Finished trial#392 with value: 0.501 with parameters: {'sigma': 3.9971853416728576, 'lam': 0.0061108372955634765}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:44,717]\u001b[0m Finished trial#393 with value: 0.6445000000000001 with parameters: {'sigma': 5.44932176422202, 'lam': 0.0017971278577392103}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:48,679]\u001b[0m Finished trial#394 with value: 0.502 with parameters: {'sigma': 6.158074227040315, 'lam': 0.020380044993257063}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:52,126]\u001b[0m Finished trial#395 with value: 0.631 with parameters: {'sigma': 5.193406483018512, 'lam': 0.003940204437662439}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:55,328]\u001b[0m Finished trial#396 with value: 0.5175 with parameters: {'sigma': 3.5049972086707544, 'lam': 2.060385290863302e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:08:58,766]\u001b[0m Finished trial#397 with value: 0.653 with parameters: {'sigma': 4.4410223619598215, 'lam': 2.640945559179368e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:02,561]\u001b[0m Finished trial#398 with value: 0.5235000000000001 with parameters: {'sigma': 4.186322164391617, 'lam': 0.0021561880068890074}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:06,131]\u001b[0m Finished trial#399 with value: 0.5015 with parameters: {'sigma': 4.5076712923410165, 'lam': 0.005372835716105207}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:09,495]\u001b[0m Finished trial#400 with value: 0.6515 with parameters: {'sigma': 5.025180307865386, 'lam': 8.765681499703663e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:13,201]\u001b[0m Finished trial#401 with value: 0.501 with parameters: {'sigma': 3.181668758782586, 'lam': 0.003301903572768531}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:16,937]\u001b[0m Finished trial#402 with value: 0.6529999999999999 with parameters: {'sigma': 4.804530534993772, 'lam': 7.278047587639438e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:20,009]\u001b[0m Finished trial#403 with value: 0.6465 with parameters: {'sigma': 5.68375231177637, 'lam': 2.7812562071718308e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:23,877]\u001b[0m Finished trial#404 with value: 0.501 with parameters: {'sigma': 3.8196196791187713, 'lam': 0.0017565633646876608}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:26,971]\u001b[0m Finished trial#405 with value: 0.501 with parameters: {'sigma': 4.140061814485305, 'lam': 0.0034353108447818387}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:30,877]\u001b[0m Finished trial#406 with value: 0.646 with parameters: {'sigma': 5.234461861598049, 'lam': 0.0017562606588957853}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:34,433]\u001b[0m Finished trial#407 with value: 0.6515 with parameters: {'sigma': 4.430810688655216, 'lam': 8.582470914966141e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:38,172]\u001b[0m Finished trial#408 with value: 0.501 with parameters: {'sigma': 3.6356323900380367, 'lam': 0.00514264846640834}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:41,653]\u001b[0m Finished trial#409 with value: 0.652 with parameters: {'sigma': 4.889536939032067, 'lam': 1.4533324744306803e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:45,477]\u001b[0m Finished trial#410 with value: 0.501 with parameters: {'sigma': 4.237484929816154, 'lam': 0.09665082813488836}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:48,788]\u001b[0m Finished trial#411 with value: 0.6315 with parameters: {'sigma': 13.956142559524704, 'lam': 0.007618450153312803}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:51,893]\u001b[0m Finished trial#412 with value: 0.6095 with parameters: {'sigma': 4.731941978208143, 'lam': 0.0031893959753819404}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:56,139]\u001b[0m Finished trial#413 with value: 0.6455 with parameters: {'sigma': 5.301850121321535, 'lam': 0.001873012675905821}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:09:59,999]\u001b[0m Finished trial#414 with value: 0.501 with parameters: {'sigma': 3.8483822220677495, 'lam': 0.02422271012510176}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:03,644]\u001b[0m Finished trial#415 with value: 0.6535 with parameters: {'sigma': 4.545510737009211, 'lam': 7.819903848937792e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:07,270]\u001b[0m Finished trial#416 with value: 0.501 with parameters: {'sigma': 2.937663020459226, 'lam': 1.8688564254114266e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:10,560]\u001b[0m Finished trial#417 with value: 0.501 with parameters: {'sigma': 3.467291594038061, 'lam': 0.048447961462751925}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:15,187]\u001b[0m Finished trial#418 with value: 0.58 with parameters: {'sigma': 4.300458362361149, 'lam': 0.0018695911220374163}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:18,477]\u001b[0m Finished trial#419 with value: 0.6325000000000001 with parameters: {'sigma': 10.888116391271744, 'lam': 0.0048655577475488305}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:22,649]\u001b[0m Finished trial#420 with value: 0.6525000000000001 with parameters: {'sigma': 4.53007883069072, 'lam': 9.085928394129408e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:26,703]\u001b[0m Finished trial#421 with value: 0.6559999999999999 with parameters: {'sigma': 4.00915398138244, 'lam': 2.3950867884140855e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:30,271]\u001b[0m Finished trial#422 with value: 0.501 with parameters: {'sigma': 3.838403889244078, 'lam': 0.003771837705174359}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:33,506]\u001b[0m Finished trial#423 with value: 0.501 with parameters: {'sigma': 3.269997886005043, 'lam': 0.0019154114770554796}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:37,492]\u001b[0m Finished trial#424 with value: 0.515 with parameters: {'sigma': 4.071273745213486, 'lam': 0.0018210576471232955}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:41,437]\u001b[0m Finished trial#425 with value: 0.501 with parameters: {'sigma': 3.7324181300128294, 'lam': 0.006554013958175918}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:45,212]\u001b[0m Finished trial#426 with value: 0.501 with parameters: {'sigma': 2.381685621305927, 'lam': 0.0035802480429165643}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:48,757]\u001b[0m Finished trial#427 with value: 0.559 with parameters: {'sigma': 4.18676990432898, 'lam': 0.0017010961213644916}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:52,093]\u001b[0m Finished trial#428 with value: 0.501 with parameters: {'sigma': 2.755713784172527, 'lam': 9.568781559068514e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:55,740]\u001b[0m Finished trial#429 with value: 0.501 with parameters: {'sigma': 3.4508036303635716, 'lam': 0.07766037800214347}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:10:59,991]\u001b[0m Finished trial#430 with value: 0.652 with parameters: {'sigma': 4.438633653911343, 'lam': 4.6331842756932566e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:04,044]\u001b[0m Finished trial#431 with value: 0.617 with parameters: {'sigma': 4.895286680473977, 'lam': 0.0033635742953748377}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:07,778]\u001b[0m Finished trial#432 with value: 0.501 with parameters: {'sigma': 3.990126746962948, 'lam': 0.00519231450884472}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:11,109]\u001b[0m Finished trial#433 with value: 0.6295 with parameters: {'sigma': 19.330808192150396, 'lam': 0.00014561587150611026}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:14,864]\u001b[0m Finished trial#434 with value: 0.501 with parameters: {'sigma': 3.7131933704325624, 'lam': 0.0016506404591319314}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:17,490]\u001b[0m Finished trial#435 with value: 0.6535 with parameters: {'sigma': 4.327891511424619, 'lam': 0.00012578817438430983}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:21,288]\u001b[0m Finished trial#436 with value: 0.6460000000000001 with parameters: {'sigma': 5.894164194696669, 'lam': 6.264797387199575e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:25,188]\u001b[0m Finished trial#437 with value: 0.501 with parameters: {'sigma': 3.075783038152152, 'lam': 0.0032210196625665306}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:29,227]\u001b[0m Finished trial#438 with value: 0.6559999999999999 with parameters: {'sigma': 4.0726716326584995, 'lam': 7.168211170927826e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:32,957]\u001b[0m Finished trial#439 with value: 0.501 with parameters: {'sigma': 3.5837851861002497, 'lam': 0.0019141551795748787}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:36,645]\u001b[0m Finished trial#440 with value: 0.501 with parameters: {'sigma': 3.9544095175657845, 'lam': 0.005259168399333747}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:40,571]\u001b[0m Finished trial#441 with value: 0.501 with parameters: {'sigma': 3.2993659308261325, 'lam': 0.00315714764236478}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:43,816]\u001b[0m Finished trial#442 with value: 0.6529999999999999 with parameters: {'sigma': 4.20560445987292, 'lam': 2.394875649706422e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:47,244]\u001b[0m Finished trial#443 with value: 0.501 with parameters: {'sigma': 4.10497839213403, 'lam': 0.02921541096797552}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:50,642]\u001b[0m Finished trial#444 with value: 0.5635000000000001 with parameters: {'sigma': 3.61385560674474, 'lam': 3.177105255621887e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:54,115]\u001b[0m Finished trial#445 with value: 0.6535 with parameters: {'sigma': 4.453152706397344, 'lam': 1.6967593481093407e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:11:57,019]\u001b[0m Finished trial#446 with value: 0.501 with parameters: {'sigma': 3.9346940681774014, 'lam': 0.00957219180937245}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:01,412]\u001b[0m Finished trial#447 with value: 0.618 with parameters: {'sigma': 4.450129592446982, 'lam': 0.00175805171428024}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:05,114]\u001b[0m Finished trial#448 with value: 0.501 with parameters: {'sigma': 3.184721497570946, 'lam': 0.006778019725694739}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:08,868]\u001b[0m Finished trial#449 with value: 0.6525000000000001 with parameters: {'sigma': 4.599384305855183, 'lam': 4.669832946227344e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:12,461]\u001b[0m Finished trial#450 with value: 0.501 with parameters: {'sigma': 4.265865860045272, 'lam': 0.08371298943141439}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:15,914]\u001b[0m Finished trial#451 with value: 0.638 with parameters: {'sigma': 3.809238313164718, 'lam': 3.9325333783225554e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:19,097]\u001b[0m Finished trial#452 with value: 0.5775 with parameters: {'sigma': 4.751350641055888, 'lam': 0.0038966395212765206}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:22,899]\u001b[0m Finished trial#453 with value: 0.6385 with parameters: {'sigma': 8.486590763623791, 'lam': 0.0019163227508205178}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:26,716]\u001b[0m Finished trial#454 with value: 0.6509999999999999 with parameters: {'sigma': 4.262635231568649, 'lam': 6.7270434889359506e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:31,208]\u001b[0m Finished trial#455 with value: 0.501 with parameters: {'sigma': 1.8052454113177898, 'lam': 0.004637394173093289}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:34,509]\u001b[0m Finished trial#456 with value: 0.501 with parameters: {'sigma': 3.4426179144747606, 'lam': 0.01652937801840422}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:38,108]\u001b[0m Finished trial#457 with value: 0.6465 with parameters: {'sigma': 4.800553534715748, 'lam': 0.0019060531399284959}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:41,533]\u001b[0m Finished trial#458 with value: 0.651 with parameters: {'sigma': 3.899173595605241, 'lam': 5.565927853548597e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:44,835]\u001b[0m Finished trial#459 with value: 0.5315 with parameters: {'sigma': 4.345265820847924, 'lam': 0.0027833398135199156}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:48,617]\u001b[0m Finished trial#460 with value: 0.6279999999999999 with parameters: {'sigma': 5.106672376053847, 'lam': 0.003739133379669837}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:51,591]\u001b[0m Finished trial#461 with value: 0.501 with parameters: {'sigma': 3.010121894318388, 'lam': 0.001977861564888584}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:55,506]\u001b[0m Finished trial#462 with value: 0.501 with parameters: {'sigma': 3.6485364876132103, 'lam': 0.0065965776551427735}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:12:59,228]\u001b[0m Finished trial#463 with value: 0.65 with parameters: {'sigma': 5.285196554136758, 'lam': 0.00010195472559451762}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:02,960]\u001b[0m Finished trial#464 with value: 0.5359999999999999 with parameters: {'sigma': 4.1433418919248, 'lam': 0.0017822475257650468}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:06,994]\u001b[0m Finished trial#465 with value: 0.654 with parameters: {'sigma': 4.440468648646904, 'lam': 8.831965234163617e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:11,016]\u001b[0m Finished trial#466 with value: 0.501 with parameters: {'sigma': 3.91129664093752, 'lam': 0.004640688039390028}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:14,520]\u001b[0m Finished trial#467 with value: 0.636 with parameters: {'sigma': 4.600589261187928, 'lam': 0.0019122334736771762}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:17,673]\u001b[0m Finished trial#468 with value: 0.502 with parameters: {'sigma': 3.457761066585173, 'lam': 8.472926427003727e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:22,176]\u001b[0m Finished trial#469 with value: 0.6555 with parameters: {'sigma': 4.15526413069893, 'lam': 1.4887392911308058e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:25,549]\u001b[0m Finished trial#470 with value: 0.501 with parameters: {'sigma': 2.6497852843149166, 'lam': 0.0034400213254772508}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:29,962]\u001b[0m Finished trial#471 with value: 0.5185 with parameters: {'sigma': 4.051729919859252, 'lam': 0.0016516709967532815}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:34,810]\u001b[0m Finished trial#472 with value: 0.5069999999999999 with parameters: {'sigma': 3.467413538876759, 'lam': 1.4145990809228196e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:39,017]\u001b[0m Finished trial#473 with value: 0.501 with parameters: {'sigma': 3.817221005976193, 'lam': 0.005239951446463918}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:42,821]\u001b[0m Finished trial#474 with value: 0.504 with parameters: {'sigma': 4.22162069409254, 'lam': 0.0029986125107403097}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:47,066]\u001b[0m Finished trial#475 with value: 0.501 with parameters: {'sigma': 3.1477705783961754, 'lam': 0.00010628779982594992}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:50,549]\u001b[0m Finished trial#476 with value: 0.501 with parameters: {'sigma': 4.485406819354196, 'lam': 0.008072074570413885}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:54,716]\u001b[0m Finished trial#477 with value: 0.621 with parameters: {'sigma': 3.7289021778993376, 'lam': 1.344940326452297e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:13:58,689]\u001b[0m Finished trial#478 with value: 0.653 with parameters: {'sigma': 4.1018053118933375, 'lam': 7.29296253348509e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:03,162]\u001b[0m Finished trial#479 with value: 0.501 with parameters: {'sigma': 0.3118179015524518, 'lam': 0.0019755259826140696}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:06,148]\u001b[0m Finished trial#480 with value: 0.6125 with parameters: {'sigma': 4.871970258029176, 'lam': 0.0035999661292892182}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:09,573]\u001b[0m Finished trial#481 with value: 0.501 with parameters: {'sigma': 4.579982233300125, 'lam': 0.04047862435628427}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:13,031]\u001b[0m Finished trial#482 with value: 0.652 with parameters: {'sigma': 4.325916504269882, 'lam': 3.1148422973311914e-06}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:16,786]\u001b[0m Finished trial#483 with value: 0.576 with parameters: {'sigma': 5.007281465519561, 'lam': 0.005427893584874538}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:20,176]\u001b[0m Finished trial#484 with value: 0.6044999999999999 with parameters: {'sigma': 3.6964110860658366, 'lam': 5.49058366356372e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:23,107]\u001b[0m Finished trial#485 with value: 0.6565 with parameters: {'sigma': 4.0625871670629765, 'lam': 3.2986072996549505e-05}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:26,639]\u001b[0m Finished trial#486 with value: 0.501 with parameters: {'sigma': 3.340107806680904, 'lam': 0.0018443019682981663}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:30,666]\u001b[0m Finished trial#487 with value: 0.501 with parameters: {'sigma': 3.9659771944601503, 'lam': 0.0033577414874898966}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:34,576]\u001b[0m Finished trial#488 with value: 0.501 with parameters: {'sigma': 3.1204741813370855, 'lam': 0.001788263028493317}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:38,282]\u001b[0m Finished trial#489 with value: 0.501 with parameters: {'sigma': 3.717448982559345, 'lam': 0.004424279590336546}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:42,316]\u001b[0m Finished trial#490 with value: 0.5335 with parameters: {'sigma': 4.212843154239021, 'lam': 0.0021203399033971016}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:46,332]\u001b[0m Finished trial#491 with value: 0.501 with parameters: {'sigma': 2.793475719029882, 'lam': 0.006171810064977694}. Best is trial#287 with value: 0.6585.\u001b[0m\n",
      "\u001b[32m[I 2020-05-29 01:14:50,520]\u001b[0m Finished trial#492 with value: 0.6519999999999999 with parameters: {'sigma': 4.001943241631724, 'lam': 0.0001039298389374625}. Best is trial#287 with value: 0.6585.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective_sgd(trial):\n",
    "#     c  = trial.suggest_loguniform('c', 1e-20, 30)\n",
    "    sigma  = trial.suggest_float('sigma', 1e-20, 20) # trial.suggest_float('sigma', 1e-5, 1e-3, log=True)\n",
    "#     kenel = trial.suggest_categorical('kenel', [rbf_kernel, quadratic_kernel])\n",
    "    lam = trial.suggest_float('lam', 1e-20, 1e-1)\n",
    "#     tol = trial.suggest_loguniform('tol', 1e-10, 1e-0)\n",
    "    \n",
    "    # ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "    # ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "    # ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "    # KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "    \n",
    "#     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "#               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM'} \n",
    "#     \n",
    "    kenel = rbf_kernel\n",
    "    models = {ksolveRR: 'k Ridge Reg'} \n",
    "      \n",
    "#     accuracy = []\n",
    "    for model in models:\n",
    "        accuracy = []\n",
    "        for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "            X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "            X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "            \n",
    "            \n",
    "#             ipdb.set_trace()\n",
    "            if models[model] == 'weigh Ridge Reg':\n",
    "                sample_weights = np.random.rand(len(y_train))\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "                \n",
    "            elif models[model] == 'k Logistic Ridge Reg':\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=100, tol = tol, kernel = kenel)\n",
    "            elif models[model] == 'k Ridge Reg':\n",
    "                model_curr = model(X_train, y_train, lam = lam, sigma = sigma, kernel = kenel)\n",
    "            else:\n",
    "                model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kenel)\n",
    "            \n",
    "            model_curr.fit()\n",
    "            accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "#             print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "        \n",
    "#         print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')\n",
    "\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(func=objective_sgd, n_trials=1500,show_progress_bar=True)\n",
    "\n",
    "\n",
    "trial = study.best_trial\n",
    "\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.657\n",
      "Best hyperparameters: {'sigma': 4.118308426567568, 'kenel': <function rbf_kernel at 0x7f21c88e3c80>, 'lam': 5.347111514994607e-09}\n",
      "time: 1.18 ms\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented data\n",
    "\n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-20, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-20, 1e-1)\n",
    "\n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Augmented data)\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: 0.6555\n",
    "    # Best hyperparameters: {'sigma': 4.065620491225982, 'lam': 0.013374107290659768}\n",
    "    # time: 49min 21s\n",
    "    #----\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.6575 # 0.6575000000000001\n",
    "    # Best hyperparameters: {'sigma': 4.119788517147901, 'lam': 1.2752298700618223e-14}, {'sigma': 4.063158315715049, 'lam': 8.30834772639223e-05}\n",
    "    # time: 32min 57s\n",
    "\n",
    "    \n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-3, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "\n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Non-Augmented data)\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: 0.6555\n",
    "    # Best hyperparameters: {'sigma': 4.069738272304652, 'lam': 0.053817561640154984}\n",
    "    # time: 48min 12s\n",
    "    #----\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.6575000000000001\n",
    "    # Best hyperparameters: {'sigma': 4.001185698777986, 'lam': 1.9770379950513775e-10}\n",
    "    # time: 29min 58s\n",
    "    \n",
    "\n",
    "\n",
    "# Original data\n",
    "\n",
    "# sigma  = trial.suggest_loguniform('sigma', 1e-3, 20)\n",
    "# lam = trial.suggest_loguniform('lam', 1e-15, 1e-0)\n",
    "  \n",
    "# models = {ksolveRR: 'k Ridge Reg'} (Non-Augmented data standardize)\n",
    "    # kenel = rbf_kernel\n",
    "    # Accuracy: 0.612\n",
    "    # Best hyperparameters: {'sigma': 2.8925324917718167, 'lam': 1.2575244169567934e-08}\n",
    "    # time: 28min 33s \n",
    "    #----\n",
    "    # kenel = quadratic_kernel\n",
    "    # Accuracy: EROOR LinearAlg\n",
    "    # Best hyperparameters: \n",
    "    # time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accurracy fold 0: 0.5975\n",
      "accurracy fold 1: 0.6625\n",
      "accurracy fold 2: 0.68\n",
      "accurracy fold 3: 0.6475\n",
      "accurracy fold 4: 0.7\n",
      "\n",
      "Average accuracy k Ridge Reg is : 0.6575\n",
      "\n",
      "time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "#     models = {ksolveRR : 'k Ridge Reg', ksolveRR_2: 'weigh Ridge Reg', \\\n",
    "#               ksolveLRR: 'k Logistic Ridge Reg', KernelSVM : 'Kernal SVM'\n",
    "\n",
    "# c  = \n",
    "sigma  = 4.119788517147901\n",
    "kenel = rbf_kernel\n",
    "lam = 1.2752298700618223e-14\n",
    "# tol = \n",
    "    \n",
    "#     ksolveRR (self, X, y, lam= 0.0001, sigma=0.5, kernel=rbf_kernel)\n",
    "#     ksolveRR_2 (self, X, y, lam= 0.0001, sigma=0.5, sample_weights = None, kernel = rbf_kernel\n",
    "#     ksolveLRR (self, X, y, lam = 0.1, sigma = 4, max_iter=100, tol=1e-5, kernel=rbf_kernel\n",
    "#     KernelSVM (self, X, y, C=0.1, lam = 0.1, sigma = 4, tol = 1e-1, kernel=rbf_kernel\n",
    "\n",
    "    \n",
    "models = {ksolveRR : 'k Ridge Reg'}\n",
    "\n",
    "for model in models:\n",
    "    accuracy = []\n",
    "    for i, (train_index, validate_index) in enumerate(kfold.split(X_cross)):\n",
    "\n",
    "        X_train, y_train = X_cross[train_index], y_cross[train_index]\n",
    "        X_valid, y_valid = X_cross[validate_index], y_cross[validate_index]\n",
    "\n",
    "        if models[model] == 'weigh Ridge Reg':\n",
    "            sample_weights = np.random.rand(len(y_train))\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, sample_weights = sample_weights, kernel = kenel)\n",
    "        elif models[model] == 'k Logistic Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, max_iter=500, tol = tol, kernel = kenel)\n",
    "        \n",
    "        elif models[model] == 'k Ridge Reg':\n",
    "            model_curr = model(X_train, y_train, lam = lam, sigma = sigma, kernel = kenel)\n",
    "        else:\n",
    "            model_curr = model(X_train, y_train, C=c, lam = lam, sigma = sigma, tol= tol, kernel = kenel)\n",
    "            \n",
    "        model_curr.fit()\n",
    "\n",
    "        accuracy.append(model_curr.Accuracy_check(X_valid, y_valid, threshold=0.5))\n",
    "        print(f'accurracy fold {i}: {accuracy[i]}')\n",
    "    \n",
    "    print(f'\\nAverage accuracy {models[model]} is : {np.mean(accuracy)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 525 µs\n"
     ]
    }
   ],
   "source": [
    "# 0.6535 = 0.68800\n",
    "# 0.657 = 0.69200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 881 µs\n"
     ]
    }
   ],
   "source": [
    "# # Cehckinf full model\n",
    "# model = ksolveRR(X_cross, y_cross, lam = lam, sigma = sigma, kernel = kenel)\n",
    "# # model = svm_primal_soft_to_qp(X_cross, y_cross, C=1)\n",
    "\n",
    "# model.fit()\n",
    "\n",
    "# model.Accuracy_check(X_cross, y_cross, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 393 ms\n"
     ]
    }
   ],
   "source": [
    "model = ksolveRR(X_cross, y_cross, lam = lam, sigma = sigma, kernel = kenel)\n",
    "model.fit()\n",
    "y_pred = model.predict(X_t_enc, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id\n",
       "0   0\n",
       "1   1\n",
       "2   2\n",
       "3   3\n",
       "4   4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.73 ms\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1000).reshape(-1, 1)\n",
    "sample = pd.DataFrame(data=X, columns=['Id'])\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.42 ms\n"
     ]
    }
   ],
   "source": [
    "sample['Bound'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  Bound\n",
       "995  995      0\n",
       "996  996      0\n",
       "997  997      1\n",
       "998  998      1\n",
       "999  999      1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.8 ms\n"
     ]
    }
   ],
   "source": [
    "sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.12 ms\n"
     ]
    }
   ],
   "source": [
    "sample.to_csv('./ksolveRR_6575_cv_rbf_kernel_sigma_4.119788517147901_lam_1.2752298700618223e-14.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
